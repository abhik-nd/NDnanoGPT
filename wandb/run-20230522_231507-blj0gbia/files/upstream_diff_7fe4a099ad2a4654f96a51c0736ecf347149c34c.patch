diff --git a/.gitignore b/.gitignore
index 70f21ff..244ae28 100644
--- a/.gitignore
+++ b/.gitignore
@@ -2,3 +2,4 @@
 .ipynb_checkpoints/
 __pycache__/
 *.pyc
+./data/
diff --git a/config/train_nd_accel.py b/config/train_nd_accel.py
new file mode 100644
index 0000000..5a0f5d9
--- /dev/null
+++ b/config/train_nd_accel.py
@@ -0,0 +1,37 @@
+# train a miniature character-level shakespeare model
+# good for debugging and playing on macbooks and such
+
+out_dir = 'out-nd-accel'
+eval_interval = 250 # keep frequent because we'll overfit
+eval_iters = 200
+log_interval = 10 # don't print too too often
+
+# we expect to overfit on this small dataset, so only save when val improves
+always_save_checkpoint = False
+
+wandb_log = True # override via command line if you like
+wandb_project = 'nd-accel'
+wandb_run_name = 'mini-gpt-2'
+
+dataset = 'nd_accel'
+gradient_accumulation_steps = 1
+batch_size = 32
+block_size = 2048 # context of up to 256 previous characters
+
+# baby GPT model :)
+n_layer = 6
+n_head = 6
+n_embd = 384
+dropout = 0.2
+
+learning_rate = 1e-4 # with baby networks can afford to go a bit higher
+max_iters = 5000
+lr_decay_iters = 5000 # make equal to max_iters usually
+min_lr = 1e-4 # learning_rate / 10 usually
+beta2 = 0.99 # make a bit bigger because number of tokens per iter is small
+
+warmup_iters = 100 # not super necessary potentially
+
+# on macbook also add
+# device = 'cpu'  # run on cpu only
+# compile = False # do not torch compile the model
diff --git a/config/train_nd_small.py b/config/train_nd_small.py
new file mode 100644
index 0000000..2f7cf3b
--- /dev/null
+++ b/config/train_nd_small.py
@@ -0,0 +1,37 @@
+# train a miniature character-level shakespeare model
+# good for debugging and playing on macbooks and such
+
+out_dir = 'out-nd-small'
+eval_interval = 250 # keep frequent because we'll overfit
+eval_iters = 200
+log_interval = 10 # don't print too too often
+
+# we expect to overfit on this small dataset, so only save when val improves
+always_save_checkpoint = False
+
+wandb_log = False # override via command line if you like
+wandb_project = 'nd-small'
+wandb_run_name = 'mini-gpt'
+
+dataset = 'nd_small'
+gradient_accumulation_steps = 1
+batch_size = 64
+block_size = 256 # context of up to 256 previous characters
+
+# baby GPT model :)
+n_layer = 6
+n_head = 6
+n_embd = 384
+dropout = 0.2
+
+learning_rate = 1e-3 # with baby networks can afford to go a bit higher
+max_iters = 5000
+lr_decay_iters = 5000 # make equal to max_iters usually
+min_lr = 1e-4 # learning_rate / 10 usually
+beta2 = 0.99 # make a bit bigger because number of tokens per iter is small
+
+warmup_iters = 100 # not super necessary potentially
+
+# on macbook also add
+# device = 'cpu'  # run on cpu only
+# compile = False # do not torch compile the model
diff --git a/config/train_shakespeare_char.py b/config/train_shakespeare_char.py
index 41c81df..13063a6 100644
--- a/config/train_shakespeare_char.py
+++ b/config/train_shakespeare_char.py
@@ -1,5 +1,7 @@
 # train a miniature character-level shakespeare model
 # good for debugging and playing on macbooks and such
+# python train.py config/train_shakespeare_char.py --dtype=float16
+# python sample.py --out_dir=out-shakespeare-char --dtype=float16 
 
 out_dir = 'out-shakespeare-char'
 eval_interval = 250 # keep frequent because we'll overfit
@@ -9,7 +11,7 @@ log_interval = 10 # don't print too too often
 # we expect to overfit on this small dataset, so only save when val improves
 always_save_checkpoint = False
 
-wandb_log = False # override via command line if you like
+wandb_log = True # override via command line if you like
 wandb_project = 'shakespeare-char'
 wandb_run_name = 'mini-gpt'
 
diff --git a/data b/data
new file mode 120000
index 0000000..921feaa
--- /dev/null
+++ b/data
@@ -0,0 +1 @@
+/data/driverGPT/data/
\ No newline at end of file
diff --git a/data/openwebtext/prepare.py b/data/openwebtext/prepare.py
deleted file mode 100644
index 8dc30e1..0000000
--- a/data/openwebtext/prepare.py
+++ /dev/null
@@ -1,74 +0,0 @@
-# saves the openwebtext dataset to a binary file for training. following was helpful:
-# https://github.com/HazyResearch/flash-attention/blob/main/training/src/datamodules/language_modeling_hf.py
-
-import os
-from tqdm import tqdm
-import numpy as np
-import tiktoken
-from datasets import load_dataset # huggingface datasets
-
-# number of workers in .map() call
-# good number to use is ~order number of cpu cores // 2
-num_proc = 8
-
-# takes 54GB in huggingface .cache dir, about 8M documents (8,013,769)
-dataset = load_dataset("openwebtext")
-
-# owt by default only contains the 'train' split, so create a test split
-split_dataset = dataset["train"].train_test_split(test_size=0.0005, seed=2357, shuffle=True)
-split_dataset['val'] = split_dataset.pop('test') # rename the test split to val
-
-# this results in:
-# >>> split_dataset
-# DatasetDict({
-#     train: Dataset({
-#         features: ['text'],
-#         num_rows: 8009762
-#     })
-#     val: Dataset({
-#         features: ['text'],
-#         num_rows: 4007
-#     })
-# })
-
-# we now want to tokenize the dataset. first define the encoding function (gpt2 bpe)
-enc = tiktoken.get_encoding("gpt2")
-def process(example):
-    ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens
-    ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe
-    # note: I think eot should be prepended not appended... hmm. it's called "eot" though...
-    out = {'ids': ids, 'len': len(ids)}
-    return out
-
-# tokenize the dataset
-tokenized = split_dataset.map(
-    process,
-    remove_columns=['text'],
-    desc="tokenizing the splits",
-    num_proc=num_proc,
-)
-
-# concatenate all the ids in each dataset into one large file we can use for training
-for split, dset in tokenized.items():
-    arr_len = np.sum(dset['len'])
-    filename = os.path.join(os.path.dirname(__file__), f'{split}.bin')
-    dtype = np.uint16 # (can do since enc.max_token_value == 50256 is < 2**16)
-    arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))
-    total_batches = 1024
-
-    idx = 0
-    for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):
-        # Batch together samples for faster write
-        batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')
-        arr_batch = np.concatenate(batch['ids'])
-        # Write into mmap
-        arr[idx : idx + len(arr_batch)] = arr_batch
-        idx += len(arr_batch)
-    arr.flush()
-
-# train.bin is ~17GB, val.bin ~8.5MB
-# train has ~9B tokens (9,035,582,198)
-# val has ~4M tokens (4,434,897)
-
-# to read the bin files later, e.g. with numpy:
-# m = np.memmap('train.bin', dtype=np.uint16, mode='r')
diff --git a/data/openwebtext/readme.md b/data/openwebtext/readme.md
deleted file mode 100644
index 95eb1bf..0000000
--- a/data/openwebtext/readme.md
+++ /dev/null
@@ -1,15 +0,0 @@
-
-## openwebtext dataset
-
-after running `prepare.py` (preprocess) we get:
-
-- train.bin is ~17GB, val.bin ~8.5MB
-- train has ~9B tokens (9,035,582,198)
-- val has ~4M tokens (4,434,897)
-
-this came from 8,013,769 documents in total.
-
-references:
-
-- OpenAI's WebText dataset is discussed in [GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
-- [OpenWebText](https://skylion007.github.io/OpenWebTextCorpus/) dataset
diff --git a/data/shakespeare/prepare.py b/data/shakespeare/prepare.py
deleted file mode 100644
index 71c88da..0000000
--- a/data/shakespeare/prepare.py
+++ /dev/null
@@ -1,33 +0,0 @@
-import os
-import requests
-import tiktoken
-import numpy as np
-
-# download the tiny shakespeare dataset
-input_file_path = os.path.join(os.path.dirname(__file__), 'input.txt')
-if not os.path.exists(input_file_path):
-    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'
-    with open(input_file_path, 'w') as f:
-        f.write(requests.get(data_url).text)
-
-with open(input_file_path, 'r') as f:
-    data = f.read()
-n = len(data)
-train_data = data[:int(n*0.9)]
-val_data = data[int(n*0.9):]
-
-# encode with tiktoken gpt2 bpe
-enc = tiktoken.get_encoding("gpt2")
-train_ids = enc.encode_ordinary(train_data)
-val_ids = enc.encode_ordinary(val_data)
-print(f"train has {len(train_ids):,} tokens")
-print(f"val has {len(val_ids):,} tokens")
-
-# export to bin files
-train_ids = np.array(train_ids, dtype=np.uint16)
-val_ids = np.array(val_ids, dtype=np.uint16)
-train_ids.tofile(os.path.join(os.path.dirname(__file__), 'train.bin'))
-val_ids.tofile(os.path.join(os.path.dirname(__file__), 'val.bin'))
-
-# train.bin has 301,966 tokens
-# val.bin has 36,059 tokens
diff --git a/data/shakespeare/readme.md b/data/shakespeare/readme.md
deleted file mode 100644
index 1e6c457..0000000
--- a/data/shakespeare/readme.md
+++ /dev/null
@@ -1,9 +0,0 @@
-
-# tiny shakespeare
-
-Tiny shakespeare, of the good old char-rnn fame :)
-
-After running `prepare.py`:
-
-- train.bin has 301,966 tokens
-- val.bin has 36,059 tokens
diff --git a/data/shakespeare_char/prepare.py b/data/shakespeare_char/prepare.py
deleted file mode 100644
index 9fd1621..0000000
--- a/data/shakespeare_char/prepare.py
+++ /dev/null
@@ -1,68 +0,0 @@
-"""
-Prepare the Shakespeare dataset for character-level language modeling.
-So instead of encoding with GPT-2 BPE tokens, we just map characters to ints.
-Will save train.bin, val.bin containing the ids, and meta.pkl containing the
-encoder and decoder and some other related info.
-"""
-import os
-import pickle
-import requests
-import numpy as np
-
-# download the tiny shakespeare dataset
-input_file_path = os.path.join(os.path.dirname(__file__), 'input.txt')
-if not os.path.exists(input_file_path):
-    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'
-    with open(input_file_path, 'w') as f:
-        f.write(requests.get(data_url).text)
-
-with open(input_file_path, 'r') as f:
-    data = f.read()
-print(f"length of dataset in characters: {len(data):,}")
-
-# get all the unique characters that occur in this text
-chars = sorted(list(set(data)))
-vocab_size = len(chars)
-print("all the unique characters:", ''.join(chars))
-print(f"vocab size: {vocab_size:,}")
-
-# create a mapping from characters to integers
-stoi = { ch:i for i,ch in enumerate(chars) }
-itos = { i:ch for i,ch in enumerate(chars) }
-def encode(s):
-    return [stoi[c] for c in s] # encoder: take a string, output a list of integers
-def decode(l):
-    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string
-
-# create the train and test splits
-n = len(data)
-train_data = data[:int(n*0.9)]
-val_data = data[int(n*0.9):]
-
-# encode both to integers
-train_ids = encode(train_data)
-val_ids = encode(val_data)
-print(f"train has {len(train_ids):,} tokens")
-print(f"val has {len(val_ids):,} tokens")
-
-# export to bin files
-train_ids = np.array(train_ids, dtype=np.uint16)
-val_ids = np.array(val_ids, dtype=np.uint16)
-train_ids.tofile(os.path.join(os.path.dirname(__file__), 'train.bin'))
-val_ids.tofile(os.path.join(os.path.dirname(__file__), 'val.bin'))
-
-# save the meta information as well, to help us encode/decode later
-meta = {
-    'vocab_size': vocab_size,
-    'itos': itos,
-    'stoi': stoi,
-}
-with open(os.path.join(os.path.dirname(__file__), 'meta.pkl'), 'wb') as f:
-    pickle.dump(meta, f)
-
-# length of dataset in characters:  1115394
-# all the unique characters:
-#  !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
-# vocab size: 65
-# train has 1003854 tokens
-# val has 111540 tokens
diff --git a/data/shakespeare_char/readme.md b/data/shakespeare_char/readme.md
deleted file mode 100644
index d597b79..0000000
--- a/data/shakespeare_char/readme.md
+++ /dev/null
@@ -1,9 +0,0 @@
-
-# tiny shakespeare, character-level
-
-Tiny shakespeare, of the good old char-rnn fame :) Treated on character-level.
-
-After running `prepare.py`:
-
-- train.bin has 1,003,854 tokens
-- val.bin has 111,540 tokens
diff --git a/out-nd-accel/ckpt.pt b/out-nd-accel/ckpt.pt
new file mode 100644
index 0000000..3c85377
Binary files /dev/null and b/out-nd-accel/ckpt.pt differ
diff --git a/out-nd-small/ckpt.pt b/out-nd-small/ckpt.pt
new file mode 100644
index 0000000..852a69a
Binary files /dev/null and b/out-nd-small/ckpt.pt differ
diff --git a/out-shakespeare-char/ckpt.pt b/out-shakespeare-char/ckpt.pt
new file mode 100644
index 0000000..5473e0d
Binary files /dev/null and b/out-shakespeare-char/ckpt.pt differ
diff --git a/out_metadata.json b/out_metadata.json
new file mode 100644
index 0000000..db01bf6
--- /dev/null
+++ b/out_metadata.json
@@ -0,0 +1,24 @@
+Overriding: out_dir = out-nd-small
+Overriding: dtype = float16
+number of parameters: 10.65M
+Loading meta from data/nd_small/meta.pkl...
+{},{"relSpeed":40.81491522612,"dist":67.89,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":943.67,"objectValueConf":0,"id":74,"delta_t":null,"height":145.27,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1696334604000,"yctr":718.12,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":118.33,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-4.00672636119638,"dist":67.89,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":490.12,"objectValueConf":0,"id":43,"delta_t":null,"height":43.08,"objectClass":11,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-3,"transformation":null,"pts":1724582469000,"yctr":710.2,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":46.56,"lanePosUsingLanes":-100,"inst_ttc":null},{"relSpeed":12.011544123861676,"dist":117.9,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":937.26,"objectValueConf":0,"id":74,"delta_t":null,"height":85.71,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1703096770000,"yctr":726.5,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":124.49,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-105.97939966685966,"dist":159.19,"aligned_scale_ratio_y":null,"startts":1683730937534,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":855.32,"objectValueConf":0,"id":24,"delta_t":null,"height":60.33,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1729012864000,"yctr":693.97,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":74.78,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-1.7193827009509885,"dist":50.06,"aligned_scale_ratio_y":null,"startts":1683730937534,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":961.35,"objectValueConf":0,"id":24,"delta_t":null,"height":63.83,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1729079423000,"yctr":709.76,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":68.13,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":16.946422707265291,"dist":64.59,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":998.96,"objectValueConf":0,"id":74,"delta_t":null,"height":104.18,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1729545779000,"yctr":711.5,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":118.92,"lanePosUsingLanes":0,"inst_ttc":null}]],[1683730930541,[{"relSpeed":7.9534473980657666,"dist":169.81,"aligned_scale_ratio_y":null,"startts":1683730931007,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1063.59,"objectValueConf":0,"id":56,"delta_t":null,"height":44.71,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.97,"lanePos":2,"transformation":null,"pts":1714522498000,"yctr":678.04,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":42.33,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":0,"dist":100.7,"aligned_scale_ratio_y":null,"startts":1683730898591,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.96,"objectSubClassConf":0,"xctr":936.44,"objectValueConf":0,"id":3,"delta_t":null,"height":67.45,"objectClass":102,"objectSubClass":-1,"objectValue":0.29,"detectionConf":1,"lanePos":-100,"transformation":null,"pts":1684442520000,"yctr":480.48,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":24.02,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730899057}]],[1683730899289,[{"relSpeed":2.53770308207632,"dist":135.21,"aligned_scale_ratio_y":null,"startts":1683730898591,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":1,"objectSubClassConf":0,"xctr":1068.62,"objectValueConf":0,"id":98,"delta_t":null,"height":46.2,"objectClass":102,"objectSubClass":-1,"objectValue":0.45,"detectionConf":1,"lanePos":-100,"transformation":null,"pts":1683243657000,"yctr":520.67,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":21.47,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730899289},{"relSpeed":0.221042005800905,"dist":62.37,"aligned_scale_ratio_y":null,"startts":1683730896494,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.98,"objectSubClassConf":0,"xctr":487.19,"objectValueConf":0,"id":54,"delta_t":null,"height":58.56,"objectC
+---------------
+{},{"relSpeed":5.4691224937265,"dist":32.39,"aligned_scale_ratio_y":null,"startts":1683730938229,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.53,"objectSubClassConf":0,"xctr":1758.3,"objectValueConf":0,"id":47,"delta_t":null,"height":44.37,"objectClass":102,"objectSubClass":-1,"objectValue":0.4,"detectionConf":0.97,"lanePos":-100,"transformation":null,"pts":1682577095000,"yctr":560.49,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":21.58,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730900227},{"relSpeed":24.545421466088375,"dist":36.67,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":980.99,"objectValueConf":0,"id":74,"delta_t":null,"height":48.53,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":0,"transformation":null,"pts":1705122661000,"yctr":694.86,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":49.91,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-10.40257806168326,"dist":73.05,"aligned_scale_ratio_y":null,"startts":1683730918179,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.99,"objectSubClassConf":0,"xctr":804.34,"objectValueConf":0,"id":94,"delta_t":null,"height":38.79,"objectClass":120,"objectSubClass":-1,"objectValue":0.44,"detectionConf":0.98,"lanePos":-100,"transformation":null,"pts":1701231345000,"yctr":514.03,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":21.12,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730918412},{"relSpeed":8.201136605271211,"dist":34.79,"aligned_scale_ratio_y":null,"startts":1683730902789,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":704.27,"objectValueConf":0,"id":72,"delta_t":null,"height":332.74,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1695168714000,"yctr":784.88,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":273.8,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":4.8355375493202,"dist":67.9,"aligned_scale_ratio_y":null,"startts":1683730918179,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.88,"objectSubClassConf":0,"xctr":862.27,"objectValueConf":0,"id":94,"delta_t":null,"height":47.66,"objectClass":104,"objectSubClass":-1,"objectValue":0.4,"detectionConf":1,"lanePos":-100,"transformation":null,"pts":1720585130000,"yctr":540.56,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":21.46,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730939863},{"relSpeed":41111059758245,"dist":69.31,"aligned_scale_ratio_y":null,"startts":1683730938465,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.75,"objectSubClassConf":0,"xctr":1564.92,"objectValueConf":0,"id":53,"delta_t":null,"height":201.97,"objectClass":103,"objectSubClass":-1,"objectValue":0.44,"detectionConf":0.99,"lanePos":-100,"transformation":null,"pts":1681877560000,"yctr":509.69,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":20.39,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730898825},{"relSpeed":0.2538027202340976,"dist":65.18,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":945.7,"objectValueConf":0,"id":74,"delta_t":null,"height":85.77,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1716154745000,"yctr":696.21,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":80.84,"lanePosUsingLanes":0,"inst_ttc":null}]],[1683730930772,[{"relSpeed":-0.256642420032215,"dist":160.27,"aligned_scale_ratio_y":null,"startts":1683730928210,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1237.4,"objectValueConf":0,"id":37,"delta_t":null,"height":62.82,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":3,"transformation":null,"pts":1719512479000,"yctr":678.43,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":84.52,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":-2.675951933532845,"dist":137.71,"aligned_scale_ratio_y":null,"startts":1683730897891,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1000.63,"objectValueConf":0,"id":74,"delta_t":null,"height":123.44,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1735541841000,"yctr":715.72,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":141.67,"lanePosUsingLanes":0,"inst_ttc":null}]],[1683730936130,[{"relSpeed":-26.258329583967197,"dist":82.72,"aligned_scale_ratio_y":null,"startts":1683730940098,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1
+---------------
+{},{"relSpeed":9.050294514179,"dist":52.11,"aligned_scale_ratio_y":null,"startts":1683730937534,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1001.12,"objectValueConf":0,"id":2,"delta_t":null,"height":45.93,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.94,"lanePos":2,"transformation":null,"pts":1699332601000,"yctr":678.53,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":52.52,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":-12.625855557086196,"dist":81.07,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1004.15,"objectValueConf":0,"id":74,"delta_t":null,"height":106.82,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1724582469000,"yctr":732.35,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":174.3,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-10.1704307775574826,"dist":121.99,"aligned_scale_ratio_y":null,"startts":1683730948293,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":715.53,"objectValueConf":0,"id":20,"delta_t":null,"height":82.57,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1728246030000,"yctr":715.49,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":118.84,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":8.70008898142,"dist":78.49,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":983.66,"objectValueConf":0,"id":74,"delta_t":null,"height":63.19,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1705661726000,"yctr":695.19,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":68.83,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-3.222081353212516,"dist":182.35,"aligned_scale_ratio_y":null,"startts":1683730918889,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":873.57,"objectValueConf":0,"id":99,"delta_t":null,"height":45.3,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1687240657000,"yctr":698.25,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":48.58,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":0.0296532179409017,"dist":62.7,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":984.49,"objectValueConf":0,"id":74,"delta_t":null,"height":133.58,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1732044169000,"yctr":722.99,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":126.4,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":0.1890771974502,"dist":105.04,"aligned_scale_ratio_y":null,"startts":1683730940098,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":892.62,"objectValueConf":0,"id":92,"delta_t":null,"height":43.08,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1706527786000,"yctr":684.1,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":44.59,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":0.9757719627327674,"dist":42.59,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1193.29,"objectValueConf":0,"id":47,"delta_t":null,"height":78.78,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":2,"transformation":null,"pts":1714522498000,"yctr":674.01,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":79.58,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":4.25124492895936,"dist":58.89,"aligned_scale_ratio_y":null,"startts":1683730929608,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1208.02,"objectValueConf":0,"id":17,"delta_t":null,"height":105.29,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":2,"transformation":null,"pts":1737540445000,"yctr":724.61,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":109.29,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":4.234023715493256,"dist":67.49,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":786.99,"objectValueConf":0,"id":18,"delta_t":null,"height":108.94,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformat
+---------------
+{},{"relSpeed":6.34992578106803,"dist":110.93,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":996.39,"objectValueConf":0,"id":74,"delta_t":null,"height":120.62,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1734442520000,"yctr":713.2,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":127.7,"lanePosUsingLanes":0,"inst_ttc":null}]],[1683730948293,[{"relSpeed":-1.938493526151685,"dist":88.46,"aligned_scale_ratio_y":null,"startts":1683730948759,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":778.41,"objectValueConf":0,"id":51,"delta_t":null,"height":82.59,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1690032139000,"yctr":714.01,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":108.12,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":7.0289116802512675,"dist":66.44,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":616.53,"objectValueConf":0,"id":43,"delta_t":null,"height":146.04,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1734908879000,"yctr":718.78,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":116.92,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-4.104993308769232,"dist":89.06,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":928.54,"objectValueConf":0,"id":18,"delta_t":null,"height":83.74,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1678379957000,"yctr":708.09,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":98.28,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-1.27388523859309,"dist":111.56,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":989.92,"objectValueConf":0,"id":74,"delta_t":null,"height":142.88,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1697733673000,"yctr":738.15,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":177.52,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-2.810377083434354,"dist":152.82,"aligned_scale_ratio_y":null,"startts":1683730901624,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1194.86,"objectValueConf":0,"id":34,"delta_t":null,"height":48.07,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.98,"lanePos":2,"transformation":null,"pts":1733649757000,"yctr":691.01,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":47.38,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":-8.471261778700661,"dist":139.22,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1583.82,"objectValueConf":0,"id":16,"delta_t":null,"height":182.4,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":2,"transformation":null,"pts":1735075485000,"yctr":729.9,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":110.7,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":-3.303326457004247,"dist":132.1,"aligned_scale_ratio_y":null,"startts":1683730940098,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1138.49,"objectValueConf":0,"id":67,"delta_t":null,"height":46.15,"objectClass":300,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.98,"lanePos":-100,"transformation":null,"pts":1703096770000,"yctr":527.69,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":29.47,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730920519},{"relSpeed":40.312285702264,"dist":165.96,"aligned_scale_ratio_y":null,"startts":1683730902789,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":789.7,"objectValueConf":0,"id":72,"delta_t":null,"height":148.88,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1677447176000,"yctr":705.59,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":101.11,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":23.25865958606125,"dist":69.09,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":980.92,"objectValueConf":0,"id":74,"delta_t":null,"height":115.62,"objectClass":1,"objectSubClass":-1,"objectValu
+---------------
+{},{"relSpeed":7.21505421441693,"dist":27.16,"aligned_scale_ratio_y":null,"startts":1683730928210,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1212.01,"objectValueConf":0,"id":37,"delta_t":null,"height":60.8,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.98,"lanePos":2,"transformation":null,"pts":1715282003000,"yctr":678.22,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":69.53,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":1.479919860036497,"dist":84.12,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":989.34,"objectValueConf":0,"id":74,"delta_t":null,"height":92.37,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1714755673000,"yctr":693.32,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":110.81,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":0,"dist":52.27,"aligned_scale_ratio_y":null,"startts":1683730918412,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.99,"objectSubClassConf":0,"xctr":1130.93,"objectValueConf":0,"id":17,"delta_t":null,"height":35.61,"objectClass":102,"objectSubClass":-1,"objectValue":0.4,"detectionConf":0.99,"lanePos":-100,"transformation":null,"pts":1724349291000,"yctr":564.32,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":19.3,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730937534},{"relSpeed":8.921032060925586,"dist":102.85,"aligned_scale_ratio_y":null,"startts":1683730937534,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":804.79,"objectValueConf":0,"id":24,"delta_t":null,"height":65.1,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1680711670000,"yctr":695.86,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":63.61,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":0.01843538959102758,"dist":69.43,"aligned_scale_ratio_y":null,"startts":1683730885967,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1181.2,"objectValueConf":0,"id":7,"delta_t":null,"height":149.56,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1717320607000,"yctr":693.37,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":100.38,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-14.44451502566,"dist":110.67,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1185.3,"objectValueConf":0,"id":67,"delta_t":null,"height":45.26,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.9,"lanePos":2,"transformation":null,"pts":1716154782000,"yctr":676.25,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":45.3,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":11.8312306081165497,"dist":163.28,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":984.93,"objectValueConf":0,"id":74,"delta_t":null,"height":111.8,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1726414510000,"yctr":720.87,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":124.71,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-1.106763990868821,"dist":120.49,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1307.16,"objectValueConf":0,"id":7,"delta_t":null,"height":55.13,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":3,"transformation":null,"pts":1718952880000,"yctr":672.22,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":44.39,"lanePosUsingLanes":3,"inst_ttc":null},{"relSpeed":7.975691228299388,"dist":64.67,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":987.75,"objectValueConf":0,"id":74,"delta_t":null,"height":75.99,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1718653785000,"yctr":691.72,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":82.8,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":20.44628576767243,"dist":182.44,"aligned_scale_ratio_y":null,"startts":1683730918889,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":889.09,"objectValueConf":0,"id":99,"delta_t":null,"height":45.99,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos"
+---------------
+{},{"relSpeed":2.049482773119736,"dist":66.52,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1002.54,"objectValueConf":0,"id":74,"delta_t":null,"height":113.55,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1692370579000,"yctr":711.3,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":127.7,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-2.902305519456053,"dist":36.38,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1810.44,"objectValueConf":0,"id":46,"delta_t":null,"height":232.85,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1700065454000,"yctr":740.16,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":265.4,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":4.64654122880167,"dist":30.36,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1754.7,"objectValueConf":0,"id":47,"delta_t":null,"height":66.27,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":2,"transformation":null,"pts":1704029482000,"yctr":685.52,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":79.44,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":4.2600653690852755,"dist":65.41,"aligned_scale_ratio_y":null,"startts":1683730917010,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.98,"objectSubClassConf":0,"xctr":612.54,"objectValueConf":0,"id":10,"delta_t":null,"height":35.53,"objectClass":101,"objectSubClass":-1,"objectValue":0.41,"detectionConf":1,"lanePos":-100,"transformation":null,"pts":1722217377000,"yctr":560.34,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":20.01,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730940098},{"relSpeed":-2.24256100045326,"dist":52.22,"aligned_scale_ratio_y":null,"startts":1683730938229,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.99,"objectSubClassConf":0,"xctr":1322.61,"objectValueConf":0,"id":54,"delta_t":null,"height":47.52,"objectClass":103,"objectSubClass":-1,"objectValue":0.46,"detectionConf":0.99,"lanePos":-100,"transformation":null,"pts":1723416578000,"yctr":533.26,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":16.34,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730938229},{"relSpeed":-263.2332910629199,"dist":281.93,"aligned_scale_ratio_y":null,"startts":1683730938229,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.97,"objectSubClassConf":0,"xctr":1205.67,"objectValueConf":0,"id":61,"delta_t":null,"height":43.04,"objectClass":103,"objectSubClass":-1,"objectValue":0.47,"detectionConf":0.97,"lanePos":-100,"transformation":null,"pts":1703096770000,"yctr":538.2,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":22.88,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730920047},{"relSpeed":-3.73581302984425,"dist":142.93,"aligned_scale_ratio_y":null,"startts":1683730918889,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":802.95,"objectValueConf":0,"id":94,"delta_t":null,"height":44.91,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1705428551000,"yctr":688.81,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":47.23,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-4.520006887761159,"dist":171.02,"aligned_scale_ratio_y":null,"startts":1683730916780,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.94,"objectSubClassConf":0,"xctr":965.24,"objectValueConf":0,"id":98,"delta_t":null,"height":36.17,"objectClass":102,"objectSubClass":-1,"objectValue":0.25,"detectionConf":0.99,"lanePos":-100,"transformation":null,"pts":1702863592000,"yctr":513.89,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":27.14,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730918412},{"relSpeed":-39.084012040855,"dist":53.03,"aligned_scale_ratio_y":null,"startts":1683730918179,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.98,"objectSubClassConf":0,"xctr":814.7,"objectValueConf":0,"id":94,"delta_t":null,"height":34.66,"objectClass":102,"objectSubClass":-1,"objectValue":0.4,"detectionConf":0.99,"lanePos":-100,"transformation":null,"pts":1721051486000,"yctr":558.46,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":19.4,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730939162},{"relSpeed":15.075966022008437,"dist":34.7,"aligned_scale_ratio_y":null,"startts":1683730937534,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr
+---------------
+{},{"relSpeed":-4.98283030845062,"dist":64.63,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":958.4,"objectValueConf":0,"id":74,"delta_t":null,"height":78.14,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1736337333000,"yctr":701.25,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":72.92,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":6.333963365716987,"dist":75.31,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":694.42,"objectValueConf":0,"id":18,"delta_t":null,"height":41.51,"objectClass":11,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-3,"transformation":null,"pts":1725048825000,"yctr":719.16,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":56.34,"lanePosUsingLanes":-100,"inst_ttc":null}]],[1683730943628,[{"relSpeed":6.186406386539902,"dist":159.12,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":309.12,"objectValueConf":0,"id":18,"delta_t":null,"height":225.52,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1698200029000,"yctr":772.56,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":211.36,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-2.6652659174610435,"dist":122.3,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":985.4,"objectValueConf":0,"id":74,"delta_t":null,"height":121.9,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1703096770000,"yctr":715.79,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":124.88,"lanePosUsingLanes":0,"inst_ttc":null}]],[1683730915552,[{"relSpeed":5.54852521329523,"dist":96.27,"aligned_scale_ratio_y":null,"startts":1683730902789,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":871.5,"objectValueConf":0,"id":81,"delta_t":null,"height":87.92,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.96,"lanePos":-2,"transformation":null,"pts":1695400189000,"yctr":694.69,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":74.51,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":9.394507820949469,"dist":52.57,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":604.77,"objectValueConf":0,"id":43,"delta_t":null,"height":55.14,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1720718308000,"yctr":698.94,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":47.6,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":11.96452554227504,"dist":122.08,"aligned_scale_ratio_y":null,"startts":1683730937534,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":804.45,"objectValueConf":0,"id":24,"delta_t":null,"height":50.4,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1685475557000,"yctr":690.15,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":53.81,"lanePosUsingLanes":-2,"inst_ttc":null}]],[1683730906519,[{"relSpeed":0,"dist":109.14,"aligned_scale_ratio_y":null,"startts":1683730892068,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":816.18,"objectValueConf":0,"id":73,"delta_t":null,"height":100.16,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1692603754000,"yctr":719.45,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":100.26,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-0.592260769252472,"dist":69.44,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":665.7,"objectValueConf":0,"id":43,"delta_t":null,"height":139.47,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1692137398000,"yctr":738.84,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":221.5,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":14.832717380297858,"dist":79.84,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":715.92,"objectValueConf":0,"id":43,"delta_t":null,"height":106.17,"objectClass":1,"objectSubClass":-1,"objectValue":
+---------------
+{},744.51,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":28.96,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730920047},{"relSpeed":30.3318426005003,"dist":29.23,"aligned_scale_ratio_y":null,"startts":1683730920047,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1517.69,"objectValueConf":0,"id":65,"delta_t":null,"height":67.27,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":0,"transformation":null,"pts":1736707732000,"yctr":693.31,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":63.39,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-1.663598448282514,"dist":150.78,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":848.62,"objectValueConf":0,"id":18,"delta_t":null,"height":109.62,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1694002823000,"yctr":713.5,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":272.55,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":3.254044342608399829,"dist":217.18,"aligned_scale_ratio_y":null,"startts":1683730909552,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":331.96,"objectValueConf":0,"id":51,"delta_t":null,"height":217.41,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1682110738000,"yctr":776.56,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":272.36,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":9.82119191260147,"dist":113.36,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":955.33,"objectValueConf":0,"id":74,"delta_t":null,"height":156.26,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1698666386000,"yctr":728.63,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":120.74,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":0,"dist":106.69,"aligned_scale_ratio_y":null,"startts":1683730900923,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.99,"objectSubClassConf":0,"xctr":1120.66,"objectValueConf":0,"id":35,"delta_t":null,"height":46.3,"objectClass":102,"objectSubClass":-1,"objectValue":0.44,"detectionConf":0.99,"lanePos":-100,"transformation":null,"pts":1703329948000,"yctr":546.83,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":18.24,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730919812},{"relSpeed":0,"dist":147.26,"aligned_scale_ratio_y":null,"startts":1683730918889,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":933.05,"objectValueConf":0,"id":99,"delta_t":null,"height":56.9,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":0,"transformation":null,"pts":1711424211000,"yctr":689.83,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":46.49,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":0.314304608425608,"dist":189.42,"aligned_scale_ratio_y":null,"startts":1683730929608,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1201.54,"objectValueConf":0,"id":14,"delta_t":null,"height":115.12,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":2,"transformation":null,"pts":1690738329000,"yctr":705.42,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":129.55,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":-2.582854955764481,"dist":127.72,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":986.92,"objectValueConf":0,"id":74,"delta_t":null,"height":79.51,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1702397236000,"yctr":696.42,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":70.11,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":-7.912129802571391,"dist":100.43,"aligned_scale_ratio_y":null,"startts":1683730918889,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":932.11,"objectValueConf":0,"id":99,"delta_t":null,"height":40.9,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":0,"transformation":null,"pts":1713629757000,"yctr":690.09,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":48.89,"lanePosUsingLanes":0,"inst_ttc":null},{"relSpeed":0.076547002924467,"dist":156.65,"aligned_scale_ratio_y":null,"startts":1683730918889,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":932.14,"objectValu
+---------------
+{},{"accelerometer":"  9.71  -0.12  -1.24   1683730909586"},{"accelerometer":"  9.74  0.29  -1.27   1683730909633"},{"accelerometer":"  9.88  0.02  -1.92   1683730909683"},{"accelerometer":"  9.72  0.31  -0.82   1683730909733"},{"accelerometer":"  9.62  0.19  -1.34   1683730909783"},{"accelerometer":"  9.7  0.38  -1.28   1683730909833"},{"accelerometer":"  9.88  0.44  -1.16   1683730909883"},{"accelerometer":"  10.09  0.09  -1.18   1683730909943"},{"accelerometer":"  10.04  0.93  -1.07   1683730909983"},{"accelerometer":"  10.01  0.12  -1.03   1683730910033"},{"accelerometer":"  10.28  0.22  -1.07   1683730910083"},{"accelerometer":"  10.14  0.06  -1.99   1683730910133"},{"accelerometer":"  10.17  0.29  -1.06   1683730910183"},{"accelerometer":"  10.26  0.12  -0.85   1683730910233"},{"accelerometer":"  9.15  0.38  -0.77   1683730910283"},{"accelerometer":"  9.63  0.32  -0.18   1683730910433"},{"accelerometer":"  9.62  0.52  -0.37   1683730910483"},{"accelerometer":"  9.44  1.23  -0.4   1683730910533"},{"accelerometer":"  9.83  -1.02  -0.33   1683730910583"},{"accelerometer":"  9.65  -0.56  -0.45   1683730910633"},{"accelerometer":"  8.47  -0.15  -0.52   1683730910683"},{"accelerometer":"  9.87  0.05  -0.68   1683730910733"},{"accelerometer":"  9.55  0.21  -0.93   1683730910783"},{"accelerometer":"  9.54  0.06  -0.52   1683730910840"},{"accelerometer":"  9.53  0.34  -0.41   1683730910883"},{"accelerometer":"  9.63  0.34  -0.46   1683730910933"},{"accelerometer":"  9.36  -0.29  -0.58   1683730910983"},{"accelerometer":"  9.4  -0.43  -0.57   1683730911033"},{"accelerometer":"  10.22  -0.12  -0.5   1683730911083"},{"accelerometer":"  10.48  -0.27  -0.01   1683730911133"},{"accelerometer":"  9.14  -0.17  -0.61   1683730911183"},{"accelerometer":"  9.97  -0.47  -0.27   1683730911233"},{"accelerometer":"  9.92  -0.66  -0.77   1683730911283"},{"accelerometer":"  9.78  -0.56  -0.85   1683730911333"},{"accelerometer":"  9.74  -0.93  -0.99   1683730911383"},{"accelerometer":"  9.79  -0.73  -0.67   1683730911433"},{"accelerometer":"  9.78  0.53  -0.48   1683730911483"},{"accelerometer":"  9.55  0.52  -1.32   1683730911533"},{"accelerometer":"  9.34  0.41  -1.11   1683730911583"},{"accelerometer":"  9.95  0.56  -1.52   1683730911633"},{"accelerometer":"  9.33  0.35  -1.81   1683730911683"},{"accelerometer":"  10.12  0.04  -0.27   1683730911733"},{"accelerometer":"  9.4  -0.22  -0.31   1683730911783"},{"accelerometer":"  9.57  -0.08  -0.04   1683730911847"},{"accelerometer":"  9.27  -0.22  -0.44   1683730911883"},{"accelerometer":"  9.55  0.26  -0.52   1683730911933"},{"accelerometer":"  9.76  0.42  -0.46   1683730911983"},{"accelerometer":"  9.58  0.12  -0.44   1683730912033"},{"accelerometer":"  9.93  0.47  -1.27   1683730912084"},{"accelerometer":"  9.8  0.44  -1.76   1683730912133"},{"accelerometer":"  9.97  0.6  -1.17   1683730912183"},{"accelerometer":"  9.89  -0.33  -1.13   1683730912233"},{"accelerometer":"  9.85  0.6  -1.6   1683730912283"},{"accelerometer":"  9.48  0.13  -1.39   1683730912334"},{"accelerometer":"  9.82  0.18  -1.32   1683730912383"},{"accelerometer":"  9.52  0.22  -1.54   1683730912433"},{"accelerometer":"  9.87  0.2  -1.8   1683730912483"},{"accelerometer":"  9.93  0.32  -1.81   1683730912533"},{"accelerometer":"  9.41  0.57  -1.78   1683730912584"},{"accelerometer":"  9.38  0.58  -1.32   1683730912633"},{"accelerometer":"  9.1  0.23  -1.87   1683730912683"},{"accelerometer":"  9.92  0.21  -0.74   1683730912734"},{"accelerometer":"  9.93  0.06  -0.85   1683730912783"},{"accelerometer":"  10.02  0.6  -1.04   1683730912840"},{"accelerometer":"  9.87  0.87  -1.43   1683730912890"},{"accelerometer":"  9.72  0.77  -1.05   1683730912933"},{"accelerometer":"  9.6  0.84  -1.26   1683730912983"},{"accelerometer":"  9.59  0.36  -1.02   1683730913033"},{"accelerometer":"  9.72  0.52  -1.12   1683730913083"},{"accelerometer":"  9.87  0.16  -0.71   1683730913133"},{"accelerometer":"  9.78  0.22  -1.35   1683730913184"},{"accelerometer":"  9.79  0.24  -0.6   1683730913234"},{"accelerometer":"  9.7  0.72  -0.51   1683730913283"},{"accelerometer":"  9.84  -1.37  -0.65   1683730913334"},{"accelerometer":"  9.83  0.22  -0.96   1683730913384"},{"accelerometer":"  9.86  0.05  -0.35   1683730913434"},{"accelerometer":"  9.06  -1.31  -0.33   1683730913483"},{"accelerometer":"  9.9  -1.25  -0.35   1683730913534"},{"accelerometer":"  9.73  -1.18  -0.66   1683730913584"},{"accelerometer":"  9.72  -0.34  -0.68   1683730913634"},{"accelerometer":"  9.82  -0.11  -0.69   1683730913684"},{"accelerometer":"  9.73  -0.02  -0.55   1683730913734"},{"accelerometer":"  10.43  0.05  -1.07   1683730913784"},{"accelerometer":"  10.89  -0.15  -1.14   1683730913840"},{"accelerometer":"  9.76  0.32  -1.02   1683730913883"},{"accelerometer":"  9.52  0.22  -1.16   1683730913934"},{"accelerometer":"  10.12  0.32  -1.67   1683730913984"},{"accelerometer":"  10.3  0.45  -1.37   1683730914033"},{"accelerometer":"  10.02  0.28  -0.69   1683730
+---------------
+{},{"accelerometer":"  9.97  0.5  -2.09   1683730945992"},{"accelerometer":"  9.52  0.16  -2.2   1683730946042"},{"accelerometer":"  9.59  0.17  -2.15   1683730946092"},{"accelerometer":"  9.98  0.12  -2.13   1683730946142"},{"accelerometer":"  9.32  0.02  -2.18   1683730946192"},{"accelerometer":"  9.69  -0.02  -2.27   1683730946242"},{"accelerometer":"  9.56  0.1  -2.15   1683730946293"},{"accelerometer":"  9.6  0.12  -2.29   1683730946342"},{"accelerometer":"  9.59  0.02  -2.43   1683730946393"},{"accelerometer":"  9.98  0.06  -2.07   1683730946443"},{"accelerometer":"  9.79  0.34  -2.72   1683730946492"},{"accelerometer":"  9.52  0.42  -2.56   1683730946543"},{"accelerometer":"  9.73  0.55  -2.47   1683730946592"},{"accelerometer":"  9.57  0.28  -2.01   1683730946643"},{"accelerometer":"  9.51  0.24  -2.4   1683730946693"},{"accelerometer":"  9.54  0.14  -2.87   1683730946743"},{"accelerometer":"  9.8  -0.01  -2.64   1683730946793"},{"accelerometer":"  9.77  -0.05  -2.09   1683730946846"},{"accelerometer":"  9.84  -0.29  -2.88   1683730946893"},{"accelerometer":"  9.73  -0.05  -2.11   1683730946942"},{"accelerometer":"  9.35  -0.22  -2.55   1683730946993"},{"accelerometer":"  9.5  -0.2  -1.22   1683730947042"},{"accelerometer":"  9.5  -0.06  -1.16   1683730947093"},{"accelerometer":"  9.72  -0.02  -1.18   1683730947142"},{"accelerometer":"  9.87  -0.02  -1.72   1683730947193"},{"accelerometer":"  9.6  -0.19  -1.62   1683730947242"},{"accelerometer":"  9.68  -0.19  -1.59   1683730947293"},{"accelerometer":"  9.65  -0.05  -1.1   1683730947342"},{"accelerometer":"  9.3  -0.08  -1.25   1683730947392"},{"accelerometer":"  9.59  -0.09  -1.82   1683730947442"},{"accelerometer":"  9.27  0.32  -1.59   1683730947493"},{"accelerometer":"  9.63  0.52  -1.73   1683730947542"},{"accelerometer":"  9.79  -0.02  -1.91   1683730947593"},{"accelerometer":"  9.73  0.14  -1.3   1683730947642"},{"accelerometer":"  9.62  0.17  -1.15   1683730947693"},{"accelerometer":"  9.75  0.13  -1.68   1683730947743"},{"accelerometer":"  9.81  0.35  -1.46   1683730947793"},{"accelerometer":"  9.53  0.26  -1.92   1683730947841"},{"accelerometer":"  9.89  0.14  -1.19   1683730947892"},{"accelerometer":"  9.54  0.38  -1.77   1683730947943"},{"accelerometer":"  9.48  0.25  -1.66   1683730947993"},{"accelerometer":"  9.34  0.13  -1.55   1683730948043"},{"accelerometer":"  9.86  0.22  -1.58   1683730948092"},{"accelerometer":"  9.67  0.51  -1.45   1683730948143"},{"accelerometer":"  9.79  0.24  -1.1   1683730948193"},{"accelerometer":"  9.73  0.25  -1.72   1683730948243"},{"accelerometer":"  9.72  0.01  -1.59   1683730948292"},{"accelerometer":"  9.87  0.23  -0.76   1683730948343"},{"accelerometer":"  9.84  0.43  -0.84   1683730948393"},{"accelerometer":"  9.5  -0.18  -0.7   1683730948443"},{"accelerometer":"  9.68  -0.45  0.61   1683730948493"},{"accelerometer":"  9.32  -0.04  0.84   1683730948543"},{"accelerometer":"  9.46  0.19  0.51   1683730948593"},{"accelerometer":"  9.35  0.02  0.42   1683730948643"},{"accelerometer":"  9.6  0.48  0.76   1683730948693"},{"accelerometer":"  9.67  0.79  0.69   1683730948743"},{"accelerometer":"  9.54  0.81  0.85   1683730948793"},{"accelerometer":"  9.82  0.85  0.14   1683730948842"},{"accelerometer":"  9.72  0.79  0.92   1683730948893"},{"accelerometer":"  9.6  0.53  -0.98   1683730948943"},{"accelerometer":"  9.96  0.19  -0.86   1683730948993"},{"accelerometer":"  9.83  0.15  -0.89   1683730949043"},{"accelerometer":"  9.8  0.27  -0.06   1683730949093"},{"accelerometer":"  9.3  0.09  -0.89   1683730949143"},{"accelerometer":"  9.13  0.12  0.43   1683730949193"},{"accelerometer":"  9.05  -0.29  0.47   1683730949243"},{"accelerometer":"  9.99  0.48  0.6   1683730949293"},{"accelerometer":"  9.92  0.81  0.05   1683730949343"},{"accelerometer":"  9.93  -0.28  0.87   1683730949393"},{"accelerometer":"  9.83  -0.09  0.52   1683730949443"},{"accelerometer":"  9.88  -0.24  0.13   1683730949494"},{"accelerometer":"  9.72  -1.09  1.35   1683730949543"},{"accelerometer":"  9.67  -0.19  0.72   1683730949592"},{"accelerometer":"  9.83  0.16  0.72   1683730949643"},{"accelerometer":"  9.63  0.06  0.35   1683730949693"},{"accelerometer":"  9.72  0.17  0.75   1683730949743"},{"accelerometer":"  9.59  -0.07  0.73   1683730949793"},{"accelerometer":"  9.74  -0.28  0.6   1683730949843"},{"gyro":"  0.69  -0.27  0.76   1683730949894"},{"gyro":"  0.73  -0.47  0.08   1683730949943"},{"gyro":"  0.78  -0.69  0.84   1683730949994"},{"gyro":"  0.76  0.49  0.85   1683730950041"},{"gyro":"  0.61  -0.32  1.12   1683730950093"},{"gyro":"  0.63  -0.87  1.23   1683730950143"},{"gyro":"  0.64  -0.69  0.14   1683730950193"},{"gyro":"  0.64  -0.06  0.96   1683730950243"},{"gyro":"  0.44  -1.37  1.02   1683730950294"},{"gyro":"  0.53  -1.24  0.47   1683730950343"},{"gyro":"  0.69  -1.56  1.46   1683730950393"},{"gyro":"  0.61  -2.52  1.18   1683730950443"},{"gyro":"  0.64  -2.73  0.08   1683730950494"},{"gyro":"  0.78  -2.6  0.03   168373095
+---------------
diff --git a/out_metadata_1.json b/out_metadata_1.json
new file mode 100644
index 0000000..ea59ad5
--- /dev/null
+++ b/out_metadata_1.json
@@ -0,0 +1,24 @@
+Overriding: out_dir = out-nd-small
+Overriding: dtype = float16
+number of parameters: 10.65M
+Loading meta from data/nd_small/meta.pkl...
+{"accelerometer":"  9.52  1.09  -1.46   1683730929588"},{"accelerometer":"  9.0  -0.28  -1.25   1683730929638"},{"accelerometer":"  9.94  0.02  -1.85   1683730929688"},{"accelerometer":"  9.61  0.27  -1.55   1683730929739"},{"accelerometer":"  9.86  0.02  -1.39   1683730929788"},{"accelerometer":"  9.87  0.28  -1.5   1683730929845"},{"accelerometer":"  9.64  0.23  -0.99   1683730929896"},{"accelerometer":"  9.73  0.11  -1.02   1683730929938"},{"accelerometer":"  9.89  0.32  -1.02   1683730929988"
+---------------
+{"relSpeed":11.9338299806244,"dist":119.38,"aligned_scale_ratio_y":null,"startts":1683730937534,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":800.1,"objectValueConf":0,"id":24,"delta_t":null,"height":46.02,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1691204685000,"yctr":698.79,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":47.91,"lanePosUsingLanes":-2,"i
+---------------
+{"accelerometer":"  9.47  0.22  -1.32   1683730911183"},{"accelerometer":"  9.77  0.17  -1.85   1683730911233"},{"accelerometer":"  9.72  0.18  -1.07   1683730911283"},{"accelerometer":"  9.22  0.04  -1.28   1683730911333"},{"accelerometer":"  9.33  0.15  -1.43   1683730911383"},{"accelerometer":"  9.25  0.06  -1.41   1683730911433"},{"accelerometer":"  9.32  0.02  -1.26   1683730911483"},{"accelerometer":"  9.13  0.03  -1.57   1683730911533"},{"accelerometer":"  9.31  0.31  -1.8   1683730911583"
+---------------
+{"accelerometer":"  9.3  0.31  -1.59   1683730948242"},{"accelerometer":"  9.59  0.9  -2.99   1683730948293"},{"accelerometer":"  9.33  0.39  -2.22   1683730948343"},{"accelerometer":"  9.71  0.7  -2.09   1683730948393"},{"accelerometer":"  9.79  0.82  -2.33   1683730948443"},{"accelerometer":"  9.79  -0.11  -2.09   1683730948493"},{"accelerometer":"  9.32  -0.29  -2.02   1683730948543"},{"accelerometer":"  9.1  -0.31  -2.09   1683730948593"},{"accelerometer":"  9.84  -0.08  -1.93   1683730948643
+---------------
+{"gyro":"  1.45  1.54  -0.75   1683730944642"},{"gyro":"  1.18  -2.65  1.82   1683730944692"},{"gyro":"  1.04  -2.67  0.29   1683730944742"},{"gyro":"  1.01  -2.01  1.5   1683730944792"},{"gyro":"  1.98  -0.55  1.02   1683730944842"},{"gyro":"  1.89  -0.06  0.52   1683730944892"},{"gyro":"  1.92  -1.76  1.46   1683730944942"},{"gyro":"  0.73  -1.94  1.71   1683730944992"},{"gyro":"  1.72  -1.45  -1.31   1683730945042"},{"gyro":"  1.82  -1.35  -0.72   1683730945092"},{"gyro":"  1.71  -2.81  -0.44 
+---------------
+{"accelerometer":"  9.81  0.22  -1.71   1683730950493"},{"accelerometer":"  8.76  0.4  -1.4   1683730950543"},{"accelerometer":"  9.52  0.26  -1.33   1683730950593"},{"accelerometer":"  9.71  0.09  -1.98   1683730950643"},{"accelerometer":"  9.68  -0.03  -0.62   1683730950693"},{"accelerometer":"  9.82  0.15  -0.79   1683730950743"},{"accelerometer":"  9.72  0.35  -0.91   1683730950793"},{"accelerometer":"  9.72  0.07  -1.19   1683730950843"},{"accelerometer":"  9.89  0.06  -1.93   1683730950893"
+---------------
+{"accelerometer":"  10.41  0.05  -1.29   1683730905232"},{"accelerometer":"  10.03  0.19  -1.32   1683730905282"},{"accelerometer":"  10.0  0.56  -0.67   1683730905332"},{"accelerometer":"  9.86  0.5  -0.04   1683730905382"},{"accelerometer":"  9.97  0.37  -0.41   1683730905432"},{"accelerometer":"  9.7  0.18  -0.58   1683730905482"},{"accelerometer":"  9.07  0.31  -0.9   1683730905532"},{"accelerometer":"  9.61  0.24  -0.52   1683730905582"},{"accelerometer":"  9.93  0.28  -0.66   1683730905632"
+---------------
+{"accelerometer":"  9.95  0.04  -1.12   1683730914384"},{"accelerometer":"  9.85  0.44  -1.13   1683730914434"},{"accelerometer":"  9.81  0.24  -1.17   1683730914484"},{"accelerometer":"  9.88  0.1  -1.32   1683730914534"},{"accelerometer":"  9.81  -0.17  -1.01   1683730914583"},{"accelerometer":"  9.81  -0.18  -1.4   1683730914634"},{"accelerometer":"  9.92  -0.13  -1.4   1683730914684"},{"accelerometer":"  9.74  -0.17  -1.21   1683730914734"},{"accelerometer":"  9.72  0.24  -1.87   168373091478
+---------------
+{"relSpeed":1.352932420015464,"dist":135.56,"aligned_scale_ratio_y":null,"startts":1683730901624,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1228.61,"objectValueConf":0,"id":34,"delta_t":null,"height":128.41,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":2,"transformation":null,"pts":1735208613000,"yctr":706.47,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":101.62,"lanePosUsingLanes":2,"i
+---------------
+{"relSpeed":0.53107102586604,"dist":120.01,"aligned_scale_ratio_y":null,"startts":1683730909552,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":846.32,"objectValueConf":0,"id":51,"delta_t":null,"height":62.46,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1733609129000,"yctr":695.62,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":66.02,"lanePosUsingLanes":-2,"
+---------------
diff --git a/out_metadata_onebracket.json b/out_metadata_onebracket.json
new file mode 100644
index 0000000..ed60bc5
--- /dev/null
+++ b/out_metadata_onebracket.json
@@ -0,0 +1,24 @@
+Overriding: out_dir = out-nd-small
+Overriding: dtype = float16
+number of parameters: 10.65M
+Loading meta from data/nd_small/meta.pkl...
+{"accelerometer":"  9.52  1.09  -1.46   1683730929588"},{"accelerometer":"  9.0  -0.28  -1.25   1683730929638"},{"accelerometer":"  9.94  0.02  -1.85   1683730929688"},{"accelerometer":"  9.61  0.27  -1.55   1683730929739"},{"accelerometer":"  9.86  0.02  -1.39   1683730929788"},{"accelerometer":"  9.87  0.28  -1.5   1683730929845"},{"accelerometer":"  9.64  0.23  -0.99   1683730929896"},{"accelerometer":"  9.73  0.11  -1.02   1683730929938"},{"accelerometer":"  9.89  0.32  -1.02   1683730929988"},{"accelerometer":"  9.74  0.32  -1.96   1683730930038"},{"accelerometer":"  9.77  0.38  -1.37   1683730930088"},{"accelerometer":"  9.85  0.33  -1.08   1683730930138"},{"accelerometer":"  9.77  0.52  -1.01   1683730930188"},{"accelerometer":"  9.82  0.33  -1.04   1683730930238"},{"accelerometer":"  9.72  0.02  -0.78   1683730930288"},{"accelerometer":"  9.77  0.37  -0.75   1683730930340"},{"accelerometer":"  9.87  0.22  -0.82   1683730930388"},{"accelerometer":"  9.9  0.2  -1.06   1683730930438"},{"accelerometer":"  9.88  0.26  -1.19   1683730930488"},{"accelerometer":"  9.97  1.01  -1.29   1683730930539"},{"accelerometer":"  9.81  0.48  -1.2   1683730930588"},{"accelerometer":"  9.83  0.28  -1.78   1683730930640"},{"accelerometer":"  9.84  0.61  -0.63   1683730930688"},{"accelerometer":"  9.82  0.02  0.1   1683730930740"},{"accelerometer":"  9.93  0.27  0.21   1683730930788"},{"accelerometer":"  9.84  0.03  0.57   1683730930841"},{"accelerometer":"  9.68  0.31  0.38   1683730930890"},{"accelerometer":"  9.52  -0.31  0.3   1683730930940"},{"accelerometer":"  9.98  0.22  0.27   1683730930988"},{"accelerometer":"  9.7  0.28  0.28   1683730930040"},{"accelerometer":"  9.51  0.0  0.09   1683730930090"},{"accelerometer":"  9.79  0.32  0.03   1683730930138"},{"accelerometer":"  9.55  0.13  0.49   1683730930188"},{"accelerometer":"  9.67  0.21  -0.6   1683730930240"},{"accelerometer":"  9.51  0.09  -0.67   1683730930288"},{"accelerometer":"  9.78  0.23  -1.05   1683730930338"},{"accelerometer":"  9.5  0.27  -0.68   1683730930388"},{"accelerometer":"  8.59  0.19  -0.99   1683730930438"},{"accelerometer":"  9.8  0.19  -0.97   1683730930488"},{"accelerometer":"  8.84  0.23  -0.9   1683730930539"},{"accelerometer":"  8.52  0.19  -0.96   1683730930588"},{"accelerometer":"  9.88  0.05  -0.98   1683730930638"},{"accelerometer":"  9.77  0.28  -1.48   1683730930688"},{"accelerometer":"  9.91  0.15  -1.11   1683730930738"},{"accelerometer":"  9.85  0.29  -1.6   1683730930788"},{"accelerometer":"  9.55  0.32  -1.19   1683730930851"},{"accelerometer":"  9.88  0.22  -1.34   1683730930888"},{"accelerometer":"  9.92  0.26  -1.33   1683730930940"},{"accelerometer":"  9.81  0.09  -1.98   1683730930988"},{"accelerometer":"  9.68  -0.03  -0.62   1683730931040"},{"accelerometer":"  9.82  0.15  -0.79   1683730931008"},{"accelerometer":"  9.4  0.36  -0.61   1683730931038"},{"accelerometer":"  9.67  0.08  -0.45   1683730931089"},{"accelerometer":"  9.14  0.16  -1.19   1683730931139"},{"accelerometer":"  9.49  0.19  -0.95   1683730931188"},{"accelerometer":"  9.53  0.19  -0.32   1683730931238"},{"accelerometer":"  9.39  0.26  -0.67   1683730931288"},{"accelerometer":"  9.46  0.54  -0.46   1683730931348"},{"accelerometer":"  9.71  0.41  -0.37   1683730931389"},{"accelerometer":"  9.86  0.22  -0.5   1683730931439"},{"accelerometer":"  9.78  0.12  -0.56   1683730931489"},{"accelerometer":"  10.24  -0.29  0.63   1683730931539"},{"accelerometer":"  10.07  -0.34  -0.18   1683730931588"},{"accelerometer":"  10.05  -0.65  -0.4   1683730931638"},{"accelerometer":"  10.49  -0.32  -0.79   1683730931688"},{"accelerometer":"  10.09  -0.34  0.76   1683730931739"},{"accelerometer":"  10.29  -0.03  0.02   1683730931788"},{"accelerometer":"  9.76  0.56  0.34   1683730931848"},{"accelerometer":"  9.66  -0.43  0.36   1683730931893"},{"accelerometer":"  9.74  0.29  0.62   1683730931939"},{"accelerometer":"  9.5  0.23  0.04   1683730931989"},{"accelerometer":"  9.77  0.09  0.27   1683730932040"},{"accelerometer":"  9.81  0.15  0.35   1683730932088"},{"accelerometer":"  9.62  -0.18  0.33   1683730932139"},{"accelerometer":"  9.98  0.39  0.23   1683730932189"},{"accelerometer":"  9.82  0.2  0.6   1683730932239"},{"accelerometer":"  9.76  0.15  0.3   1683730932289"},{"accelerometer":"  9.59  0.24  0.31   1683730932340"},{"accelerometer":"  9.88  0.57  0.27   1683730932388"},{"accelerometer":"  9.62  0.23  0.53   1683730932439"},{"accelerometer":"  9.6  0.2  0.02   1683730932488"},{"accelerometer":"  9.68  -0.08  0.06   1683730932539"},{"accelerometer":"  9.79  0.03  0.79   1683730932589"},{"accelerometer":"  9.35  -0.17  0.62   1683730932639"},{"accelerometer":"  9.55  -0.23  0.04   1683730932689"},{"accelerometer":"  9.5  -0.33  0.3   1683730932739"},{"accelerometer":"  9.72  -0.52  0.62   1683730932789"},{"accelerometer":"  9.71  -0.26  0.24   1683730932840"},{"accelerometer":"  9.86  -0.26  0.03   1683730932890"},{"accelerometer":"  8.92  0.35  0.25   1683730932938"
+---------------
+{"accelerometer":"  9.49  0.29  -2.0   1683730906032"},{"accelerometer":"  9.52  0.06  -2.34   1683730906082"},{"accelerometer":"  9.9  0.1  -2.27   1683730906132"},{"accelerometer":"  9.7  0.1  -1.38   1683730906182"},{"accelerometer":"  9.7  0.32  -1.49   1683730906232"},{"accelerometer":"  9.89  0.34  -1.94   1683730906282"},{"accelerometer":"  9.99  0.16  -0.49   1683730906332"},{"accelerometer":"  9.9  -0.06  -0.46   1683730906382"},{"accelerometer":"  9.93  0.23  -0.59   1683730906432"},{"accelerometer":"  9.7  0.15  -0.87   1683730906482"},{"accelerometer":"  9.57  -0.37  -0.95   1683730906532"},{"accelerometer":"  9.72  -0.03  -0.69   1683730906582"},{"accelerometer":"  9.98  -0.37  -0.98   1683730906632"},{"accelerometer":"  9.79  0.49  -0.38   1683730906682"},{"accelerometer":"  10.22  0.27  -0.79   1683730906732"},{"accelerometer":"  10.01  0.27  -0.17   1683730906782"},{"accelerometer":"  10.29  0.1  -0.5   1683730906840"},{"accelerometer":"  10.03  0.22  -0.73   1683730906888"},{"accelerometer":"  10.01  0.01  -0.18   1683730906932"},{"accelerometer":"  8.91  0.02  -0.59   1683730906982"},{"accelerometer":"  10.39  1.09  -0.7   1683730906032"},{"gyro":"  0.27  0.02  -1.44   1683730906082"},{"gyro":"  0.03  0.33  -0.6   1683730906132"},{"gyro":"  0.24  0.93  -0.75   1683730906182"},{"gyro":"  0.12  -0.12  -1.02   1683730906232"},{"gyro":"  0.08  -0.12  0.24   1683730906282"},{"gyro":"  0.06  -0.35  1.47   1683730906332"},{"gyro":"  0.08  0.4  1.89   1683730906382"},{"gyro":"  0.05  0.75  1.19   1683730906432"},{"gyro":"  0.14  0.43  0.92   1683730906483"},{"gyro":"  0.0  0.56  0.85   1683730906532"},{"gyro":"  0.02  -0.4  1.18   1683730906582"},{"gyro":"  0.06  -0.02  1.2   1683730906632"},{"gyro":"  0.12  -1.48  0.92   1683730906682"},{"gyro":"  0.34  -0.03  0.72   1683730906732"},{"gyro":"  0.24  -0.06  0.5   1683730906782"},{"gyro":"  0.32  -0.17  0.06   1683730906832"},{"gyro":"  0.43  -0.43  0.58   1683730906882"},{"gyro":"  0.56  -0.52  0.32   1683730906932"},{"gyro":"  0.63  -0.12  0.15   1683730906982"},{"gyro":"  0.69  -0.27  0.34   1683730907032"},{"gyro":"  0.72  -0.96  0.32   1683730907082"},{"gyro":"  0.69  -0.03  0.02   1683730907132"},{"gyro":"  0.64  -0.81  0.89   1683730907182"},{"gyro":"  0.53  -0.26  -0.76   1683730907232"},{"gyro":"  0.56  -0.96  -0.26   1683730907282"},{"gyro":"  0.52  -0.03  -0.24   1683730907332"},{"gyro":"  0.69  0.72  0.41   1683730907382"},{"gyro":"  0.69  0.79  -0.75   1683730907432"},{"gyro":"  0.66  0.47  0.02   1683730907482"},{"gyro":"  0.64  -0.15  -0.47   1683730907532"},{"gyro":"  0.47  1.02  0.85   1683730907582"},{"gyro":"  0.5  1.28  1.38   1683730907632"},{"gyro":"  0.55  1.24  0.95   1683730907682"},{"gyro":"  0.79  0.37  0.69   1683730907732"},{"gyro":"  0.66  0.14  0.24   1683730907783"},{"gyro":"  0.64  0.49  0.37   1683730907832"},{"gyro":"  0.69  0.69  0.41   1683730907882"},{"gyro":"  0.61  0.35  0.92   1683730907932"},{"gyro":"  0.79  0.38  0.27   1683730907982"},{"gyro":"  0.63  0.24  0.53   1683730908032"},{"gyro":"  0.69  0.85  0.35   1683730908082"},{"gyro":"  0.67  0.08  0.79   1683730908132"},{"gyro":"  0.61  0.99  0.5   1683730908182"},{"gyro":"  0.6  0.43  0.47   1683730908232"},{"gyro":"  0.67  0.98  0.82   1683730908282"},{"gyro":"  0.63  0.26  1.32   1683730908332"},{"gyro":"  0.76  0.95  0.67   1683730908383"},{"gyro":"  0.69  2.06  0.87   1683730908432"},{"gyro":"  0.67  1.69  0.35   1683730908482"},{"gyro":"  0.63  0.6  -0.27   1683730908532"},{"gyro":"  0.69  0.44  -0.18   1683730908583"},{"gyro":"  0.65  0.15  -0.14   1683730908632"},{"gyro":"  0.69  0.21  -0.67   1683730908683"},{"gyro":"  0.69  0.24  -1.09   1683730908733"},{"gyro":"  0.67  0.49  -1.8   1683730908783"},{"gyro":"  0.67  -1.6  -0.66   1683730908840"},{"gyro":"  0.69  -1.2  -0.02   1683730908883"},{"gyro":"  0.64  -0.96  -0.93   1683730908932"},{"gyro":"  0.67  -1.19  -0.76   1683730908982"},{"gyro":"  0.64  -1.19  0.75   1683730909043"},{"gyro":"  0.61  -0.26  0.37   1683730909090"},{"gyro":"  0.75  -0.12  0.64   1683730909140"},{"gyro":"  0.61  -2.11  0.6   1683730909181"},{"gyro":"  0.67  -2.41  1.12   1683730909232"},{"gyro":"  0.63  -0.52  1.35   1683730909282"},{"gyro":"  0.53  -3.14  0.82   1683730909333"},{"gyro":"  0.49  -3.63  0.67   1683730909383"},{"gyro":"  0.52  -3.94  1.56   1683730909433"},{"gyro":"  0.38  -4.17  0.27   1683730909483"},{"gyro":"  0.49  -4.14  1.53   1683730909532"},{"gyro":"  0.21  -6.56  1.25   1683730909582"},{"gyro":"  0.52  -4.24  2.99   1683730909633"},{"gyro":"  -0.02  -6.18  0.41   1683730909683"},{"gyro":"  -0.05  -1.93  0.38   1683730909733"},{"gyro":"  -0.06  -2.56  2.03   1683730909783"},{"gyro":"  -0.08  -1.39  1.95   1683730909842"},{"gyro":"  -0.05  -1.94  1.08   1683730909883"},{"gyro":"  -0.06  -2.93  0.64   1683730909932"},{"gyro":"  -0.18  -2.15  1.05   1683730909983"},{"gyro":"  -0.29  -2.72  0.92   1683730910033"},{"gyro":"  -0.27  0.27  1.13   1683730910083"},{"gyro":"  -0.12  0.15  0.37   1683730910
+---------------
+{"accelerometer":"  9.51  0.29  -2.12   1683730947092"},{"accelerometer":"  9.94  0.57  -2.32   1683730947142"},{"accelerometer":"  9.78  -0.16  -2.62   1683730947193"},{"accelerometer":"  9.5  -0.17  -2.08   1683730947243"},{"accelerometer":"  9.6  -0.03  -2.22   1683730947293"},{"accelerometer":"  9.69  -0.12  -2.56   1683730947343"},{"accelerometer":"  9.54  -0.15  -2.98   1683730947393"},{"accelerometer":"  9.93  0.29  -2.29   1683730947443"},{"accelerometer":"  9.64  -0.22  -2.02   1683730947493"},{"accelerometer":"  10.25  -0.02  -2.23   1683730947543"},{"accelerometer":"  9.95  0.68  -2.61   1683730947592"},{"accelerometer":"  9.77  -0.18  -2.69   1683730947643"},{"accelerometer":"  9.72  0.27  -2.04   1683730947693"},{"accelerometer":"  9.79  0.23  -2.56   1683730947743"},{"accelerometer":"  9.87  0.29  -2.49   1683730947793"},{"accelerometer":"  9.72  1.12  -2.39   1683730947844"},{"accelerometer":"  9.59  1.42  -2.17   1683730947892"},{"accelerometer":"  9.97  0.4  -2.07   1683730947942"},{"accelerometer":"  10.24  0.18  -2.31   1683730947993"},{"accelerometer":"  9.85  0.28  -2.03   1683730948043"},{"accelerometer":"  9.76  0.03  -1.11   1683730948092"},{"accelerometer":"  9.75  0.07  -1.32   1683730948143"},{"accelerometer":"  9.89  0.09  -1.13   1683730948193"},{"accelerometer":"  9.87  0.25  -1.02   1683730948243"},{"accelerometer":"  9.76  0.36  -1.9   1683730948292"},{"accelerometer":"  9.74  0.19  -1.49   1683730948343"},{"accelerometer":"  9.63  0.09  -0.07   1683730948393"},{"accelerometer":"  10.34  0.05  -1.44   1683730948443"},{"accelerometer":"  9.83  -0.21  -1.47   1683730948493"},{"accelerometer":"  9.73  0.26  -1.52   1683730948543"},{"accelerometer":"  9.41  0.04  -1.02   1683730948593"},{"accelerometer":"  10.15  0.02  -1.11   1683730948643"},{"accelerometer":"  9.74  0.23  -1.68   1683730948693"},{"accelerometer":"  9.79  0.07  -1.22   1683730948743"},{"accelerometer":"  9.61  0.18  -1.45   1683730948793"},{"accelerometer":"  9.68  0.05  -1.02   1683730948844"},{"accelerometer":"  10.28  0.46  -0.8   1683730948892"},{"accelerometer":"  9.97  0.37  -0.86   1683730948943"},{"accelerometer":"  9.59  -0.27  -1.15   1683730948993"},{"accelerometer":"  9.44  -0.36  -1.19   1683730949043"},{"accelerometer":"  9.25  0.18  -1.45   1683730949093"},{"accelerometer":"  9.38  0.13  -1.07   1683730949143"},{"accelerometer":"  9.51  0.08  -1.46   1683730949193"},{"accelerometer":"  9.25  0.15  -2.3   1683730949243"},{"accelerometer":"  9.94  0.11  -2.31   1683730949293"},{"accelerometer":"  9.88  0.15  -3.56   1683730949343"},{"accelerometer":"  9.89  0.26  -2.5   1683730949393"},{"accelerometer":"  9.82  0.14  -2.18   1683730949443"},{"accelerometer":"  9.88  0.12  -2.9   1683730949494"},{"accelerometer":"  9.95  -0.34  -2.77   1683730949543"},{"accelerometer":"  9.95  -0.48  -2.93   1683730949593"},{"accelerometer":"  9.7  -0.55  -2.01   1683730949643"},{"accelerometer":"  9.71  -0.43  -2.55   1683730949693"},{"accelerometer":"  9.73  0.02  -1.55   1683730949743"},{"accelerometer":"  9.83  0.1  -1.39   1683730949793"},{"accelerometer":"  9.88  -0.36  -1.19   1683730949842"},{"accelerometer":"  9.89  0.08  -2.37   1683730949893"},{"accelerometer":"  9.81  -0.19  -2.06   1683730949943"},{"accelerometer":"  9.92  0.02  -2.0   1683730949993"},{"accelerometer":"  9.65  0.24  -2.12   1683730940043"},{"accelerometer":"  10.37  0.3  -1.01   1683730940091"},{"accelerometer":"  10.52  0.39  -1.35   1683730940141"},{"accelerometer":"  10.22  0.02  -1.73   1683730940191"},{"accelerometer":"  9.57  -0.02  -1.32   1683730940241"},{"accelerometer":"  9.77  -0.32  -1.08   1683730940291"},{"accelerometer":"  9.8  -0.24  -2.07   1683730940341"},{"accelerometer":"  9.98  -0.03  -2.6   1683730940391"},{"accelerometer":"  9.63  -1.01  -2.19   1683730940441"},{"accelerometer":"  9.59  -1.17  -2.37   1683730940491"},{"accelerometer":"  9.92  -0.09  -2.09   1683730940541"},{"accelerometer":"  9.82  -0.01  -2.66   1683730940591"},{"accelerometer":"  9.58  -0.09  -2.32   1683730940641"},{"accelerometer":"  9.67  0.12  -2.02   1683730940691"},{"accelerometer":"  9.52  0.12  -2.15   1683730940741"},{"accelerometer":"  10.04  0.41  -2.29   1683730940791"},{"accelerometer":"  9.69  0.21  -1.22   1683730940841"},{"accelerometer":"  9.96  0.03  -1.18   1683730940892"},{"accelerometer":"  9.72  0.16  -1.27   1683730940941"},{"accelerometer":"  9.74  0.41  -1.27   1683730940991"},{"accelerometer":"  9.53  -0.39  -1.28   1683730941041"},{"accelerometer":"  9.74  0.41  -1.09   1683730941091"},{"accelerometer":"  9.79  -0.35  -1.19   1683730941141"},{"accelerometer":"  9.82  -0.39  -1.02   1683730941192"},{"accelerometer":"  9.93  -0.27  -1.79   1683730941241"},{"accelerometer":"  9.88  -0.25  -1.02   1683730941292"},{"accelerometer":"  9.89  -0.11  -1.3   1683730941341"},{"accelerometer":"  9.94  -0.27  -1.99   1683730941392"},{"accelerometer":"  9.37  -0.29  -1.92   1683730941441"},{"accelerometer":"  9.56  -0.15  -2.27   1683
+---------------
+{"gyro":"  -0.66  -0.0  -0.84   1683730902931"},{"gyro":"  -0.56  -0.02  -0.64   1683730902981"},{"gyro":"  -0.56  -0.09  -0.96   1683730903032"},{"gyro":"  -0.52  -0.67  0.69   1683730903082"},{"gyro":"  -0.56  -0.85  0.49   1683730903131"},{"gyro":"  -0.56  -0.69  0.66   1683730903182"},{"gyro":"  -0.56  -0.35  0.2   1683730903231"},{"gyro":"  -0.56  -0.06  1.32   1683730903282"},{"gyro":"  -0.56  -0.63  0.32   1683730903331"},{"gyro":"  -0.52  -0.69  1.31   1683730903380"},{"gyro":"  -0.47  0.17  1.18   1683730903432"},{"gyro":"  -0.53  -0.24  1.61   1683730903482"},{"gyro":"  -0.41  -0.15  0.46   1683730903539"},{"gyro":"  -0.38  -0.24  0.58   1683730903582"},{"gyro":"  -0.32  -0.12  0.92   1683730903631"},{"gyro":"  -0.43  0.82  1.63   1683730903681"},{"gyro":"  -0.46  -0.24  0.95   1683730903731"},{"gyro":"  -0.29  -1.37  0.44   1683730903782"},{"gyro":"  -0.56  -2.19  0.79   1683730903831"},{"gyro":"  -0.52  -1.15  0.43   1683730903881"},{"gyro":"  -0.24  0.53  0.38   1683730903931"},{"gyro":"  -0.56  0.96  1.04   1683730903981"},{"gyro":"  -0.66  0.12  0.37   1683730904031"},{"gyro":"  -0.64  2.15  0.11   1683730904082"},{"gyro":"  -0.67  1.04  0.35   1683730904132"},{"gyro":"  -0.72  2.05  0.66   1683730904181"},{"gyro":"  -0.66  0.52  0.72   1683730904232"},{"gyro":"  -0.41  1.02  0.46   1683730904281"},{"gyro":"  -0.53  0.08  0.98   1683730904332"},{"gyro":"  -0.49  -0.76  0.82   1683730904381"},{"gyro":"  -0.44  -0.2  1.07   1683730904432"},{"gyro":"  -0.49  -0.98  1.01   1683730904481"},{"gyro":"  0.52  -0.15  1.08   1683730904532"},{"gyro":"  0.52  -0.23  0.38   1683730904582"},{"gyro":"  0.52  -0.69  1.19   1683730904632"},{"gyro":"  0.56  -1.95  1.04   1683730904682"},{"gyro":"  0.56  -1.19  0.72   1683730904731"},{"gyro":"  0.52  -2.09  0.58   1683730904782"},{"gyro":"  0.52  -2.44  0.73   1683730904832"},{"gyro":"  0.78  -0.34  0.58   1683730904882"},{"gyro":"  0.75  -0.47  0.27   1683730904931"},{"gyro":"  0.53  -0.56  0.52   1683730904982"},{"gyro":"  0.32  -0.61  0.56   1683730905032"},{"gyro":"  0.31  -0.18  0.93   1683730905082"},{"gyro":"  0.52  -0.24  0.09   1683730905132"},{"gyro":"  0.64  0.81  1.43   1683730905182"},{"gyro":"  0.66  0.6  1.11   1683730905232"},{"gyro":"  0.56  0.53  1.02   1683730905282"},{"gyro":"  0.58  0.56  1.23   1683730905332"},{"gyro":"  0.52  -0.66  1.26   1683730905382"},{"gyro":"  0.69  -0.67  1.64   1683730905432"},{"gyro":"  0.66  -0.84  1.91   1683730905482"},{"gyro":"  0.78  1.19  1.21   1683730905532"},{"gyro":"  0.64  0.08  1.39   1683730905582"},{"gyro":"  0.61  -0.78  0.23   1683730905632"},{"gyro":"  0.77  -0.4  0.38   1683730905682"},{"gyro":"  0.79  -0.75  0.53   1683730905732"},{"gyro":"  0.7  -0.35  0.76   1683730905782"},{"gyro":"  0.79  -0.05  2.92   1683730905832"},{"gyro":"  0.7  -0.08  2.95   1683730905883"},{"gyro":"  0.72  -1.01  3.06   1683730905932"},{"gyro":"  0.79  -0.12  3.84   1683730905982"},{"gyro":"  0.89  -0.56  3.48   1683730906032"},{"gyro":"  0.87  -2.53  1.1   1683730906082"},{"gyro":"  0.82  -2.81  1.03   1683730906132"},{"gyro":"  0.73  -2.18  0.6   1683730906182"},{"gyro":"  0.84  -2.17  0.0   1683730906232"},{"gyro":"  0.63  -1.48  1.86   1683730906282"},{"gyro":"  0.66  -2.55  0.75   1683730906332"},{"gyro":"  0.69  -2.0  0.53   1683730906382"},{"gyro":"  0.67  -2.92  0.82   1683730906432"},{"gyro":"  0.78  -2.31  1.12   1683730906482"},{"gyro":"  0.79  -2.15  1.28   1683730906532"},{"gyro":"  0.72  -1.17  0.52   1683730906582"},{"gyro":"  0.72  -0.03  0.49   1683730906632"},{"gyro":"  0.78  -0.23  0.12   1683730906682"},{"gyro":"  0.78  -0.87  1.17   1683730906732"},{"gyro":"  0.73  -2.41  0.24   1683730906782"},{"gyro":"  0.69  -1.1  1.31   1683730906832"},{"gyro":"  0.69  -2.06  0.29   1683730906882"},{"gyro":"  0.63  -2.37  0.53   1683730906932"},{"gyro":"  0.75  -2.34  0.69   1683730906982"},{"gyro":"  0.69  -2.24  0.54   1683730907032"},{"gyro":"  0.61  -1.03  1.44   1683730907082"},{"gyro":"  0.67  -2.87  0.32   1683730907132"},{"gyro":"  0.56  -3.11  0.55   1683730907182"},{"gyro":"  0.63  -0.92  0.69   1683730907232"},{"gyro":"  0.64  -0.56  0.02   1683730907282"},{"gyro":"  0.64  -0.08  0.09   1683730907332"},{"gyro":"  0.63  0.96  0.19   1683730907382"},{"gyro":"  0.75  0.92  0.06   1683730907432"},{"gyro":"  0.72  0.24  -0.27   1683730907482"},{"gyro":"  0.78  -0.35  -0.47   1683730907532"},{"gyro":"  0.67  -0.34  0.24   1683730907582"},{"gyro":"  0.69  -0.09  -0.35   1683730907632"},{"gyro":"  0.79  -0.08  -0.18   1683730907682"},{"gyro":"  0.66  0.17  -0.14   1683730907732"},{"gyro":"  0.78  0.02  -0.98   1683730907782"},{"gyro":"  0.67  0.2  0.21   1683730907832"},{"gyro":"  0.63  -0.08  0.08   1683730907882"},{"gyro":"  0.64  -0.08  0.9   1683730907933"},{"gyro":"  0.69  -0.64  0.58   1683730907982"},{"gyro":"  0.69  -0.84  0.47   1683730908032"},{"gyro":"  0.64  -0.93  0.49   1683730908083"},{"gyro":"  0.67  -0.17  0.24   1683730908132"},{"gyro":"  0.64  -0.18  0.29   1683730908183"},{"gyro":"  0.69
+---------------
+{"gyro":"  0.92  1.05  1.41   1683730927487"},{"gyro":"  0.81  -0.46  0.64   1683730927537"},{"gyro":"  0.81  -0.61  0.64   1683730927587"},{"gyro":"  0.82  -0.02  0.55   1683730927637"},{"gyro":"  0.82  -0.41  0.66   1683730927688"},{"gyro":"  0.87  -0.98  1.03   1683730927738"},{"gyro":"  0.72  -1.13  1.31   1683730927787"},{"gyro":"  0.79  -0.08  1.62   1683730927840"},{"gyro":"  0.82  -0.02  1.41   1683730927890"},{"gyro":"  0.88  -0.29  0.24   1683730927950"},{"gyro":"  0.72  -0.64  0.62   1683730927987"},{"gyro":"  0.64  -1.56  0.49   1683730928038"},{"gyro":"  0.67  -2.12  0.82   1683730928088"},{"gyro":"  0.72  -0.09  1.54   1683730928138"},{"gyro":"  0.79  -0.61  2.76   1683730928188"},{"gyro":"  0.72  -0.03  1.52   1683730928238"},{"gyro":"  0.67  -0.27  0.96   1683730928288"},{"gyro":"  0.69  -0.52  1.36   1683730928338"},{"gyro":"  0.78  -0.27  1.09   1683730928388"},{"gyro":"  0.67  -0.56  1.08   1683730928438"},{"gyro":"  0.69  -0.21  1.11   1683730928488"},{"gyro":"  0.64  -0.58  0.37   1683730928537"},{"gyro":"  0.66  -0.27  0.32   1683730928587"},{"gyro":"  0.56  -0.37  0.02   1683730928638"},{"gyro":"  0.53  0.31  1.03   1683730928687"},{"gyro":"  0.47  -0.29  1.04   1683730928738"},{"gyro":"  0.49  -0.12  0.53   1683730928788"},{"gyro":"  0.23  -0.32  0.38   1683730928842"},{"gyro":"  0.46  -0.64  0.06   1683730928890"},{"gyro":"  0.52  -0.06  0.56   1683730928945"},{"gyro":"  0.55  -0.2  0.2   1683730928987"},{"gyro":"  0.69  -1.82  0.96   1683730929038"},{"gyro":"  0.64  -0.26  0.63   1683730929088"},{"gyro":"  0.69  -1.33  0.92   1683730929138"},{"gyro":"  0.64  -1.73  1.06   1683730929188"},{"gyro":"  0.69  -2.31  1.01   1683730929238"},{"gyro":"  0.52  -2.09  1.27   1683730929288"},{"gyro":"  0.66  -3.46  0.18   1683730929338"},{"gyro":"  0.67  -2.52  1.59   1683730929388"},{"gyro":"  0.87  -2.27  1.58   1683730929438"},{"gyro":"  0.72  -0.58  1.6   1683730929488"},{"gyro":"  0.78  0.49  1.02   1683730929538"},{"gyro":"  0.78  0.63  1.45   1683730929588"},{"gyro":"  0.76  0.61  1.96   1683730929638"},{"gyro":"  0.78  0.93  1.96   1683730929688"},{"gyro":"  0.82  0.34  1.22   1683730929738"},{"gyro":"  0.72  -0.93  1.61   1683730929788"},{"gyro":"  0.73  -0.26  0.66   1683730929842"},{"gyro":"  0.78  -0.69  0.21   1683730929890"},{"gyro":"  0.79  -1.32  0.69   1683730929942"},{"gyro":"  0.79  -2.32  0.37   1683730929988"},{"gyro":"  0.69  -2.37  1.02   1683730930038"},{"gyro":"  0.53  -2.06  0.21   1683730930088"},{"gyro":"  0.67  -2.18  0.38   1683730930138"},{"gyro":"  0.79  -2.53  0.75   1683730930188"},{"gyro":"  0.7  -2.02  1.33   1683730930248"},{"gyro":"  0.64  -2.46  0.92   1683730930288"},{"gyro":"  0.69  -1.22  0.66   1683730930340"},{"gyro":"  0.69  -2.6  0.79   1683730930388"},{"gyro":"  0.67  -1.04  0.03   1683730930440"},{"gyro":"  0.78  -3.21  1.5   1683730930490"},{"gyro":"  0.6  -3.82  6.09   1683730930538"},{"gyro":"  0.69  -3.14  3.01   1683730930589"},{"gyro":"  0.64  -4.06  3.09   1683730930638"},{"gyro":"  0.5  -4.81  1.14   1683730930689"},{"gyro":"  0.69  -5.53  1.92   1683730930740"},{"gyro":"  0.66  0.82  1.99   1683730930788"},{"gyro":"  0.78  0.12  1.4   1683730930841"},{"gyro":"  0.79  0.76  0.95   1683730930890"},{"gyro":"  0.76  0.78  0.56   1683730930940"},{"gyro":"  0.79  0.6  0.49   1683730930988"},{"gyro":"  0.56  0.56  0.69   1683730931048"},{"gyro":"  0.84  0.95  0.35   1683730931000"},{"gyro":"  0.78  0.12  0.43   1683730931038"},{"gyro":"  0.78  0.64  0.67   1683730931000"},{"gyro":"  0.89  0.76  0.56   1683730931038"},{"gyro":"  0.81  1.72  0.4   1683730931008"},{"gyro":"  0.87  2.4  0.89   1683730931038"},{"gyro":"  0.79  0.24  2.24   1683730931088"},{"gyro":"  0.67  -0.56  2.31   1683730931138"},{"gyro":"  0.73  -0.38  1.24   1683730931188"},{"gyro":"  0.69  -0.46  0.66   1683730931238"},{"gyro":"  0.63  -1.86  1.37   1683730931288"},{"gyro":"  0.69  -0.46  0.47   1683730931340"},{"gyro":"  0.69  -1.06  0.86   1683730931389"},{"gyro":"  0.55  -1.33  1.38   1683730931438"},{"gyro":"  0.64  -2.27  1.36   1683730931489"},{"gyro":"  0.78  -2.87  3.08   1683730931539"},{"gyro":"  0.69  -2.27  1.11   1683730931588"},{"gyro":"  0.82  -2.5  2.67   1683730931639"},{"gyro":"  0.5  -2.76  1.76   1683730931689"},{"gyro":"  0.47  -2.08  1.81   1683730931748"},{"gyro":"  0.56  -2.31  0.55   1683730931786"},{"gyro":"  0.53  -2.67  0.15   1683730931845"},{"gyro":"  0.69  -2.92  0.33   1683730931894"},{"gyro":"  0.73  -2.09  0.79   1683730931939"},{"gyro":"  0.76  -2.53  0.61   1683730931989"},{"gyro":"  0.69  -2.2  2.35   1683730932040"},{"gyro":"  0.69  -3.34  0.27   1683730932088"},{"gyro":"  0.47  -1.16  1.43   1683730932139"},{"gyro":"  0.58  0.38  1.22   1683730932189"},{"gyro":"  0.5  -2.37  0.12   1683730932238"},{"gyro":"  0.67  0.6  0.53   1683730932288"},{"gyro":"  0.69  -0.84  0.05   1683730932340"},{"gyro":"  0.72  -0.05  0.92   1683730932388"},{"gyro":"  0.5  -0.99  0.56   1683730932439"},{"gyro":"  0.56  0.02  -0.02   1683730932489"},{"gyro":"  0
+---------------
+{"gyro":"  0.12  0.41  0.15   1683730916685"},{"gyro":"  0.14  -0.12  -0.96   1683730916734"},{"gyro":"  0.15  -0.18  -0.47   1683730916785"},{"gyro":"  0.12  -0.06  0.56   1683730916835"},{"gyro":"  0.09  -1.69  0.76   1683730916897"},{"gyro":"  0.12  -1.97  0.32   1683730916935"},{"gyro":"  0.17  -0.12  0.79   1683730916984"},{"gyro":"  0.29  -0.92  0.58   1683730917034"},{"gyro":"  0.24  -1.33  1.18   1683730917084"},{"gyro":"  0.29  -1.73  1.47   1683730917134"},{"gyro":"  0.53  -0.66  0.09   1683730917184"},{"gyro":"  0.69  -1.1  1.05   1683730917234"},{"gyro":"  0.66  -1.12  0.6   1683730917284"},{"gyro":"  0.69  -2.93  -0.38   1683730917334"},{"gyro":"  0.69  -0.46  2.64   1683730917384"},{"gyro":"  0.69  -0.02  -0.03   1683730917434"},{"gyro":"  0.72  -0.99  0.26   1683730917484"},{"gyro":"  0.69  0.89  -0.27   1683730917534"},{"gyro":"  0.7  -0.09  0.29   1683730917585"},{"gyro":"  0.72  -1.1  0.06   1683730917634"},{"gyro":"  0.72  1.43  1.57   1683730917685"},{"gyro":"  0.76  0.18  1.0   1683730917734"},{"gyro":"  0.64  0.53  1.7   1683730917785"},{"gyro":"  0.67  -0.96  1.03   1683730917840"},{"gyro":"  0.67  0.2  1.73   1683730917890"},{"gyro":"  0.67  0.29  1.01   1683730917934"},{"gyro":"  0.69  0.29  1.54   1683730917984"},{"gyro":"  0.76  -0.08  1.29   1683730918035"},{"gyro":"  0.79  -0.35  1.2,  1683730918084"},{"gyro":"  0.87  -0.69  0.06   1683730918135"},{"gyro":"  0.79  -0.69  0.76   1683730918185"},{"gyro":"  0.76  -1.03  0.46   1683730918235"},{"gyro":"  0.73  -0.26  0.44   1683730918285"},{"gyro":"  0.95  -0.26  0.35   1683730918335"},{"gyro":"  0.84  -0.06  1.99   1683730918385"},{"gyro":"  0.81  0.95  1.04   1683730918435"},{"gyro":"  0.82  0.15  1.4   1683730918485"},{"gyro":"  0.92  0.09  1.56   1683730918535"},{"gyro":"  0.98  -0.49  0.55   1683730918585"},{"gyro":"  0.85  0.35  0.26   1683730918635"},{"gyro":"  0.72  -1.02  0.12   1683730918685"},{"gyro":"  0.73  -0.02  1.31   1683730918735"},{"gyro":"  0.73  -0.26  1.07   1683730918785"},{"gyro":"  0.79  0.37  1.44   1683730918840"},{"gyro":"  0.89  0.24  1.73   1683730918890"},{"gyro":"  0.72  -0.35  1.55   1683730918935"},{"gyro":"  0.69  -0.06  0.56   1683730918985"},{"gyro":"  0.49  -0.02  1.08   1683730919035"},{"gyro":"  0.29  -1.01  1.23   1683730919085"},{"gyro":"  0.49  -1.14  1.02   1683730919135"},{"gyro":"  0.56  -1.4  1.67   1683730919185"},{"gyro":"  0.52  -0.66  0.56   1683730919236"},{"gyro":"  0.52  -0.18  0.47   1683730919285"},{"gyro":"  0.5  -0.18  0.49   1683730919335"},{"gyro":"  0.5  -0.92  0.41   1683730919385"},{"gyro":"  0.34  -1.02  1.53   1683730919436"},{"gyro":"  0.49  -1.94  1.05   1683730919485"},{"gyro":"  0.52  -0.46  0.15   1683730919536"},{"gyro":"  0.56  -0.64  0.53   1683730919586"},{"gyro":"  0.55  -0.2  0.41   1683730919636"},{"gyro":"  0.52  -0.0  0.29   1683730919686"},{"gyro":"  0.58  -0.73  0.9   1683730919735"},{"gyro":"  0.56  -0.12  0.73   1683730919785"},{"gyro":"  0.69  -0.61  0.52   1683730919836"},{"gyro":"  0.66  0.44  0.93   1683730919890"},{"gyro":"  0.66  -0.2  0.26   1683730919935"},{"gyro":"  0.5  -0.78  0.66   1683730919985"},{"gyro":"  0.58  -0.23  0.76   1683730920035"},{"gyro":"  0.56  -0.15  0.78   1683730920085"},{"gyro":"  0.53  -0.27  0.92   1683730920135"},{"gyro":"  0.58  -1.14  0.89   1683730920185"},{"gyro":"  0.58  -1.86  0.15   1683730920236"},{"gyro":"  0.49  -1.27  1.26   1683730920285"},{"gyro":"  0.56  -0.26  1.46   1683730920335"},{"gyro":"  0.56  -0.95  1.37   1683730920385"},{"gyro":"  0.63  -0.08  0.05   1683730920436"},{"gyro":"  0.47  -0.82  0.43   1683730920485"},{"gyro":"  0.55  -0.56  0.43   1683730920535"},{"gyro":"  0.49  -0.72  0.72   1683730920585"},{"gyro":"  0.27  -0.49  0.76   1683730920636"},{"gyro":"  0.12  -0.03  0.96   1683730920685"},{"gyro":"  0.12  -1.3  0.08   1683730920736"},{"gyro":"  0.24  -2.24  -0.56   1683730920785"},{"gyro":"  0.21  -1.69  0.32   1683730920840"},{"gyro":"  0.34  0.27  0.43   1683730920890"},{"gyro":"  0.32  0.26  0.42   1683730920935"},{"gyro":"  0.43  -0.43  1.76   1683730920985"},{"gyro":"  0.53  -0.72  0.26   1683730921036"},{"gyro":"  0.53  -0.89  0.66   1683730921086"},{"gyro":"  0.53  0.53  1.97   1683730921136"},{"gyro":"  0.64  0.49  2.67   1683730921186"},{"gyro":"  0.69  1.95  1.08   1683730921236"},{"gyro":"  0.64  0.96  1.68   1683730921286"},{"gyro":"  0.79  0.0  0.79   1683730921336"},{"gyro":"  0.7  0.17  0.62   1683730921386"},{"gyro":"  0.89  0.78  0.14   1683730921436"},{"gyro":"  0.64  0.79  0.69   1683730921486"},{"gyro":"  0.72  -0.92  0.03   1683730921536"},{"gyro":"  0.76  -0.03  -0.49   1683730921586"},{"gyro":"  0.63  -0.41  -0.49   1683730921636"},{"gyro":"  0.69  -0.44  -0.31   1683730921686"},{"gyro":"  0.64  -0.11  0.55   1683730921736"},{"gyro":"  0.53  -0.12  1.42   1683730921786"},{"gyro":"  0.69  0.12  0.03   1683730921841"},{"gyro":"  0.6  0.5  0.47   1683730921890"},{"gyro":"  0.68  0.34  0.7   1683730921936"},{"gyro":"  1.67  0.98  1.69   1683730921986"},{"gyro":"  1.61
+---------------
+{"gyro":"  0.47  -1.11  0.45   1683730901380"},{"gyro":"  0.52  -0.17  1.72   1683730901430"},{"gyro":"  0.56  -0.84  0.49   1683730901480"},{"gyro":"  0.53  -0.7  0.5   1683730901530"},{"gyro":"  0.5  -0.52  0.56   1683730901580"},{"gyro":"  0.49  -1.73  0.05   1683730901630"},{"gyro":"  0.38  -1.09  0.84   1683730901680"},{"gyro":"  0.35  -0.75  -0.63   1683730901730"},{"gyro":"  0.32  -0.31  0.23   1683730901780"},{"gyro":"  0.31  -0.26  0.56   1683730901840"},{"gyro":"  0.44  -0.66  0.23   1683730901880"},{"gyro":"  0.37  -0.56  1.53   1683730902930"},{"gyro":"  0.26  -0.7  1.42   1683730902980"},{"gyro":"  0.27  -0.27  0.72   1683730903031"},{"gyro":"  0.06  0.76  0.06   1683730903081"},{"gyro":"  0.27  0.47  -0.32   1683730903130"},{"gyro":"  0.2  -0.66  -0.09   1683730903181"},{"gyro":"  0.29  -0.79  -0.49   1683730903231"},{"gyro":"  0.03  -0.12  0.02   1683730903282"},{"gyro":"  0.15  -1.22  1.12   1683730903332"},{"gyro":"  0.18  -4.15  1.97   1683730903381"},{"gyro":"  0.15  0.76  1.55   1683730903431"},{"gyro":"  0.15  -2.49  5.05   1683730903481"},{"gyro":"  0.96  -1.54  1.53   1683730903532"},{"gyro":"  0.08  -0.46  1.24   1683730903581"},{"gyro":"  0.15  -1.03  0.05   1683730903632"},{"gyro":"  0.27  -3.92  1.86   1683730903681"},{"gyro":"  0.18  -1.73  1.12   1683730903731"},{"gyro":"  0.08  -2.35  1.27   1683730903781"},{"gyro":"  0.14  -0.17  0.02   1683730903832"},{"gyro":"  -0.12  -0.06  1.83   1683730903881"},{"gyro":"  -0.17  -0.05  0.56   1683730903932"},{"gyro":"  -0.18  -0.12  1.08   1683730903982"},{"gyro":"  -0.26  -0.06  1.49   1683730904032"},{"gyro":"  -0.23  -0.65  0.95   1683730904082"},{"gyro":"  -0.29  -0.15  0.76   1683730904131"},{"gyro":"  -0.26  -0.09  -0.37   1683730904181"},{"gyro":"  -0.23  -0.47  -0.53   1683730904232"},{"gyro":"  -0.03  -0.89  -0.29   1683730904282"},{"gyro":"  -0.02  -0.24  -0.46   1683730904332"},{"gyro":"  0.12  -0.63  0.82   1683730904382"},{"gyro":"  0.21  -0.78  0.08   1683730904432"},{"gyro":"  0.35  -0.41  -0.72   1683730904481"},{"gyro":"  0.37  -0.05  -2.21   1683730904532"},{"gyro":"  0.35  -0.06  -1.74   1683730904581"},{"gyro":"  0.47  -0.08  -1.28   1683730904632"},{"gyro":"  0.4  -0.08  -0.12   1683730904682"},{"gyro":"  0.52  -0.05  -0.14   1683730904732"},{"gyro":"  0.56  -0.05  0.49   1683730904782"},{"gyro":"  0.56  0.63  0.72   1683730904832"},{"gyro":"  0.69  -0.27  0.82   1683730904882"},{"gyro":"  0.67  -0.26  0.03   1683730904931"},{"gyro":"  0.67  -2.2  0.15   1683730904981"},{"gyro":"  0.52  -1.08  0.05   1683730905032"},{"gyro":"  0.56  -0.0  0.41   1683730905082"},{"gyro":"  0.58  0.32  0.44   1683730905132"},{"gyro":"  0.79  0.37  2.27   1683730905182"},{"gyro":"  0.78  0.56  3.52   1683730905232"},{"gyro":"  0.78  0.52  7.56   1683730905282"},{"gyro":"  0.89  -0.82  1.32   1683730905332"},{"gyro":"  0.75  -0.15  1.55   1683730905382"},{"gyro":"  0.63  -0.43  0.5   1683730905432"},{"gyro":"  0.72  -0.24  0.06   1683730905482"},{"gyro":"  0.79  0.11  0.24   1683730905532"},{"gyro":"  0.69  0.63  0.08   1683730905582"},{"gyro":"  0.64  0.47  0.89   1683730905632"},{"gyro":"  0.72  0.61  0.84   1683730905682"},{"gyro":"  0.78  0.09  0.7   1683730905732"},{"gyro":"  0.78  0.78  0.46   1683730905782"},{"gyro":"  0.78  0.75  0.29   1683730905832"},{"gyro":"  0.68  -0.24  0.85   1683730905882"},{"gyro":"  0.69  -0.03  0.66   1683730905932"},{"gyro":"  0.69  -0.35  0.11   1683730905982"},{"gyro":"  0.72  -0.29  1.04   1683730906032"},{"gyro":"  0.79  -0.55  0.08   1683730906082"},{"gyro":"  0.61  0.56  1.46   1683730906132"},{"gyro":"  0.69  0.89  0.98   1683730906182"},{"gyro":"  0.69  0.37  0.17   1683730906232"},{"gyro":"  0.69  0.44  0.41   1683730906282"},{"gyro":"  0.7  -0.93  0.39   1683730906332"},{"gyro":"  0.69  -0.78  0.15   1683730906382"},{"gyro":"  0.6  -0.2  0.46   1683730906432"},{"gyro":"  0.6  -0.24  0.5   1683730906482"},{"gyro":"  0.63  0.99  0.15   1683730906532"},{"gyro":"  0.56  0.58  1.35   1683730906582"},{"gyro":"  0.46  0.23  1.12   1683730906632"},{"gyro":"  0.34  0.85  1.91   1683730906682"},{"gyro":"  0.46  1.62  1.73   1683730906732"},{"gyro":"  0.29  1.08  0.92   1683730906782"},{"gyro":"  0.49  0.69  0.72   1683730906832"},{"gyro":"  0.56  0.37  0.73   1683730906882"},{"gyro":"  0.52  0.78  0.96   1683730906932"},{"gyro":"  0.52  -0.85  0.46   1683730906982"},{"gyro":"  0.43  0.66  0.41   1683730907032"},{"gyro":"  0.49  -0.26  0.53   1683730907082"},{"gyro":"  0.47  -0.82  -0.5   1683730907132"},{"gyro":"  0.26  0.09  -0.98   1683730907182"},{"gyro":"  0.21  -0.56  -0.84   1683730907232"},{"gyro":"  0.26  -0.12  -0.35   1683730907282"},{"gyro":"  0.27  -0.57  -0.03   1683730907332"},{"gyro":"  0.27  -0.29  0.69   1683730907382"},{"gyro":"  0.32  -0.29  0.96   1683730907432"},{"gyro":"  0.43  -1.14  0.66   1683730907482"},{"gyro":"  0.43  -1.91  0.56   1683730907532"},{"gyro":"  0.52  -1.64  0.92   1683730907582"},{"gyro":"  0.52  -2.34  0.35   1683730907632"},{"gyro":"  0.58  0.63  0.34   168373
+---------------
+{"gyro":"  0.26  -0.52  0.56   1683730908582"},{"gyro":"  0.2  0.58  1.61   1683730908632"},{"gyro":"  0.38  -0.52  0.85   1683730908683"},{"gyro":"  0.55  -0.09  0.32   1683730908733"},{"gyro":"  0.52  -0.32  1.04   1683730908783"},{"gyro":"  0.49  -0.72  0.55   1683730908832"},{"gyro":"  0.53  -0.49  0.92   1683730908889"},{"gyro":"  0.52  -0.87  0.35   1683730908932"},{"gyro":"  0.56  -0.5  0.76   1683730908982"},{"gyro":"  0.55  -0.69  1.25   1683730909042"},{"gyro":"  0.69  -0.69  1.24   1683730909093"},{"gyro":"  0.55  -0.61  0.43   1683730909132"},{"gyro":"  0.6  -0.4  1.75   1683730909181"},{"gyro":"  0.75  -0.55  0.66   1683730909232"},{"gyro":"  0.64  -0.27  0.32   1683730909283"},{"gyro":"  0.52  -0.82  0.56   1683730909332"},{"gyro":"  0.56  -1.62  0.38   1683730909383"},{"gyro":"  0.69  -0.15  1.49   1683730909433"},{"gyro":"  0.67  -0.26  1.93   1683730909483"},{"gyro":"  0.55  -0.32  1.46   1683730909533"},{"gyro":"  0.64  -0.85  0.27   1683730909583"},{"gyro":"  0.69  -0.18  0.42   1683730909633"},{"gyro":"  0.64  0.12  0.28   1683730909683"},{"gyro":"  0.69  0.52  0.27   1683730909733"},{"gyro":"  0.69  -0.05  0.21   1683730909783"},{"gyro":"  0.5  -0.41  0.92   1683730909833"},{"gyro":"  0.52  -0.47  0.47   1683730909883"},{"gyro":"  0.64  -1.19  0.96   1683730909932"},{"gyro":"  0.79  -1.44  0.93   1683730909983"},{"gyro":"  0.82  -0.32  -0.24   1683730910033"},{"gyro":"  0.89  -1.73  0.26   1683730910083"},{"gyro":"  0.89  -1.32  0.96   1683730910133"},{"gyro":"  0.69  -3.15  0.85   1683730910183"},{"gyro":"  0.7  -1.64  1.32   1683730910233"},{"gyro":"  0.67  -1.07  1.03   1683730910283"},{"gyro":"  0.66  -5.92  1.99   1683730910333"},{"gyro":"  0.79  -1.91  -0.14   1683730910383"},{"gyro":"  0.49  -2.96  -0.46   1683730910433"},{"gyro":"  0.53  -1.13  -0.43   1683730910483"},{"gyro":"  0.69  -0.85  0.95   1683730910533"},{"gyro":"  0.64  -2.37  0.44   1683730910583"},{"gyro":"  0.79  -1.42  0.75   1683730910633"},{"gyro":"  0.56  -2.15  0.7   1683730910683"},{"gyro":"  0.56  -1.16  0.08   1683730910733"},{"gyro":"  0.49  -0.08  1.77   1683730910783"},{"gyro":"  0.49  -1.83  0.72   1683730910840"},{"gyro":"  0.43  -0.15  0.75   1683730910883"},{"gyro":"  0.5  -0.66  0.41   1683730910933"},{"gyro":"  0.56  -0.46  0.63   1683730910983"},{"gyro":"  0.69  0.18  0.87   1683730911033"},{"gyro":"  0.73  0.15  0.19   1683730911083"},{"gyro":"  0.62  -0.02  0.9   1683730911133"},{"gyro":"  0.64  -1.69  0.86   1683730911183"},{"gyro":"  0.63  -1.3  0.55   1683730911233"},{"gyro":"  0.69  -3.86  0.03   1683730911283"},{"gyro":"  0.72  -2.67  -0.46   1683730911333"},{"gyro":"  0.67  -2.04  0.56   1683730911383"},{"gyro":"  0.66  -2.23  0.77   1683730911433"},{"gyro":"  0.82  -1.29  0.58   1683730911483"},{"gyro":"  0.69  -2.92  0.78   1683730911533"},{"gyro":"  0.63  -1.82  2.14   1683730911583"},{"gyro":"  0.64  -2.05  1.98   1683730911633"},{"gyro":"  0.84  -1.38  1.62   1683730911684"},{"gyro":"  0.72  -3.67  0.65   1683730911733"},{"gyro":"  0.79  -1.24  0.56   1683730911783"},{"gyro":"  0.84  -2.11  0.43   1683730911835"},{"gyro":"  0.87  -2.81  0.18   1683730911883"},{"gyro":"  0.84  0.47  -0.61   1683730911933"},{"gyro":"  0.87  0.79  -1.41   1683730911983"},{"gyro":"  0.78  -2.84  -0.49   1683730912033"},{"gyro":"  0.78  -0.61  -1.24   1683730912083"},{"gyro":"  0.78  -2.56  -0.58   1683730912133"},{"gyro":"  0.84  -2.97  0.52   1683730912183"},{"gyro":"  0.82  -2.66  0.64   1683730912233"},{"gyro":"  0.84  -1.4  1.49   1683730912283"},{"gyro":"  0.66  -0.08  0.08   1683730912333"},{"gyro":"  0.6  -1.1  0.09   1683730912383"},{"gyro":"  0.69  -1.61  0.72   1683730912433"},{"gyro":"  0.56  -0.79  0.27   1683730912483"},{"gyro":"  0.69  -0.61  1.42   1683730912533"},{"gyro":"  0.82  -0.52  1.11   1683730912583"},{"gyro":"  0.61  -2.58  0.98   1683730912633"},{"gyro":"  0.78  -0.56  1.18   1683730912683"},{"gyro":"  0.73  -0.56  1.11   1683730912734"},{"gyro":"  0.64  1.69  2.27   1683730912783"},{"gyro":"  0.63  0.02  1.45   1683730912840"},{"gyro":"  0.69  -0.49  0.49   1683730912883"},{"gyro":"  0.69  0.82  0.27   1683730912934"},{"gyro":"  0.69  1.24  1.19   1683730912983"},{"gyro":"  0.69  0.89  1.02   1683730913033"},{"gyro":"  0.6  0.68  0.69   1683730913084"},{"gyro":"  0.67  0.12  0.5   1683730913134"},{"gyro":"  0.79  0.27  0.89   1683730913183"},{"gyro":"  0.69  -0.11  0.69   1683730913235"},{"gyro":"  0.72  0.49  0.5   1683730913283"},{"gyro":"  0.61  -0.24  0.32   1683730913334"},{"gyro":"  0.69  0.05  0.26   1683730913384"},{"gyro":"  0.69  0.32  0.79   1683730913434"},{"gyro":"  0.72  0.69  1.09   1683730913484"},{"gyro":"  0.72  0.49  0.42   1683730913534"},{"gyro":"  0.6  -0.14  1.05   1683730913584"},{"gyro":"  0.69  -0.56  1.09   1683730913634"},{"gyro":"  0.67  -0.55  0.66   1683730913684"},{"gyro":"  0.69  -0.52  0.23   1683730913734"},{"gyro":"  0.69  -0.12  0.92   1683730913784"},{"gyro":"  0.69  -1.19  0.23   1683730913840"},{"gyro":"  0.67  -1.02  0.73   1683730913890"}
+---------------
+{"relSpeed":2.29230058227109,"dist":136.35,"aligned_scale_ratio_y":null,"startts":1683730943159,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":630.03,"objectValueConf":0,"id":18,"delta_t":null,"height":148.11,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1686507801000,"yctr":729.68,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":111.46,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-1.012899159424763,"dist":58.69,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":648.68,"objectValueConf":0,"id":43,"delta_t":null,"height":120.7,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1712423895000,"yctr":719.98,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":121.9,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":13.29890683336621,"dist":83.23,"aligned_scale_ratio_y":null,"startts":1683730885035,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":985.42,"objectValueConf":0,"id":74,"delta_t":null,"height":82.23,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":0,"transformation":null,"pts":1694702358000,"yctr":715.47,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":92.04,"lanePosUsingLanes":0,"inst_ttc":null}]],[1683730901624,[{"relSpeed":0,"dist":92.13,"aligned_scale_ratio_y":null,"startts":1683730902789,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1103.4,"objectValueConf":0,"id":72,"delta_t":null,"height":265.92,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":2,"transformation":null,"pts":1686547160000,"yctr":678.93,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":227.79,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":3.8299906550159462,"dist":78.01,"aligned_scale_ratio_y":null,"startts":1683730896033,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":771.96,"objectValueConf":0,"id":73,"delta_t":null,"height":125.98,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":1,"lanePos":-2,"transformation":null,"pts":1733443238000,"yctr":720.78,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":121.71,"lanePosUsingLanes":-2,"inst_ttc":null}]],[1683730956684,[{"relSpeed":-2.29212411602937,"dist":76.14,"aligned_scale_ratio_y":null,"startts":1683730955288,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":746.62,"objectValueConf":0,"id":2,"delta_t":null,"height":70.62,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1734142773000,"yctr":700.71,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":88.8,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-7.20508225831066,"dist":83.53,"aligned_scale_ratio_y":null,"startts":1683730909552,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":893.28,"objectValueConf":0,"id":51,"delta_t":null,"height":43.14,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":-2,"transformation":null,"pts":1696101426000,"yctr":692.67,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":49.02,"lanePosUsingLanes":-2,"inst_ttc":null},{"relSpeed":-0.3629361659327975,"dist":151.29,"aligned_scale_ratio_y":null,"startts":1683730901869,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1162.29,"objectValueConf":0,"id":47,"delta_t":null,"height":46.56,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"detectionConf":0.99,"lanePos":2,"transformation":null,"pts":1719052823000,"yctr":663.3,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":46.83,"lanePosUsingLanes":2,"inst_ttc":null},{"relSpeed":0,"dist":111.04,"aligned_scale_ratio_y":null,"startts":1683730897427,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0.98,"objectSubClassConf":0,"xctr":1183.99,"objectValueConf":0,"id":5,"delta_t":null,"height":32.9,"objectClass":102,"objectSubClass":-1,"objectValue":0.4,"detectionConf":0.99,"lanePos":-100,"transformation":null,"pts":1682810273000,"yctr":514.69,"aligned_scale_ratio":null,"raw_scale_ratio":null,"width":22.1,"lanePosUsingLanes":-100,"inst_ttc":null,"ts":1683730898825},{"relSpeed":7.0813298057170158,"dist":50.85,"aligned_scale_ratio_y":null,"startts":1683730885967,"aligned_rotation_angle":null,"aligned_scale_ratio_x":null,"objectClassConf":0,"objectSubClassConf":0,"xctr":1280.62,"objectValueConf":0,"id":7,"delta_t":null,"height":108.6,"objectClass":1,"objectSubClass":-1,"objectValue":-1,"det
+---------------
+{"gyro":"  0.63  -0.11  0.03   1683730906432"},{"gyro":"  0.69  -0.18  0.47   1683730906482"},{"gyro":"  0.67  -0.43  0.75   1683730906532"},{"gyro":"  0.69  -0.56  0.58   1683730906582"},{"gyro":"  0.69  -0.96  0.43   1683730906632"},{"gyro":"  0.72  -0.69  1.79   1683730906682"},{"gyro":"  0.69  0.41  1.43   1683730906732"},{"gyro":"  0.69  0.53  0.73   1683730906782"},{"gyro":"  0.69  0.27  -0.98   1683730906832"},{"gyro":"  0.66  0.37  -0.56   1683730906883"},{"gyro":"  0.64  -0.06  -0.69   1683730906932"},{"gyro":"  0.7  -0.82  -0.64   1683730906982"},{"gyro":"  0.72  1.06  1.42   1683730907032"},{"gyro":"  0.76  0.2  0.46   1683730907082"},{"gyro":"  0.67  0.84  0.23   1683730907132"},{"gyro":"  0.69  0.69  0.35   1683730907182"},{"gyro":"  0.79  0.56  0.46   1683730907232"},{"gyro":"  0.79  0.24  0.47   1683730907283"},{"gyro":"  0.78  0.41  1.65   1683730907332"},{"gyro":"  0.78  0.15  0.73   1683730907382"},{"gyro":"  0.64  -0.69  0.32   1683730907432"},{"gyro":"  0.61  -0.74  0.89   1683730907482"},{"gyro":"  0.63  -1.0  -0.15   1683730907532"},{"gyro":"  0.63  0.64  -0.66   1683730907582"},{"gyro":"  0.69  -0.32  -0.49   1683730907632"},{"gyro":"  0.69  -0.02  0.12   1683730907682"},{"gyro":"  0.69  -0.12  0.69   1683730907732"},{"gyro":"  0.69  -0.12  0.78   1683730907782"},{"gyro":"  0.34  -0.44  0.98   1683730907832"},{"gyro":"  0.34  -0.35  1.33   1683730907881"},{"gyro":"  0.43  -0.37  1.22   1683730907932"},{"gyro":"  0.32  -0.29  0.34   1683730907983"},{"gyro":"  0.38  -0.93  1.32   1683730908032"},{"gyro":"  0.32  -0.18  0.98   1683730908082"},{"gyro":"  0.32  -0.85  1.46   1683730908132"},{"gyro":"  0.35  0.08  1.41   1683730908182"},{"gyro":"  0.37  0.35  0.27   1683730908232"},{"gyro":"  0.47  0.81  0.49   1683730908282"},{"gyro":"  0.43  -0.69  0.29   1683730908332"},{"gyro":"  0.52  -0.52  1.78   1683730908383"},{"gyro":"  0.5  -0.12  1.08   1683730908432"},{"gyro":"  0.55  -0.41  0.6   1683730908482"},{"gyro":"  0.56  -0.89  0.49   1683730908532"},{"gyro":"  0.55  -0.21  0.53   1683730908582"},{"gyro":"  0.58  -0.58  0.35   1683730908633"},{"gyro":"  0.56  -0.75  0.53   1683730908683"},{"gyro":"  0.53  -0.12  0.96   1683730908733"},{"gyro":"  0.69  -0.2  0.5   1683730908783"},{"gyro":"  0.72  -0.64  1.24   1683730908840"},{"gyro":"  0.79  -0.72  0.55   1683730908883"},{"gyro":"  0.85  -0.29  0.24   1683730908932"},{"gyro":"  0.82  -1.82  0.27   1683730908983"},{"gyro":"  0.56  -1.15  0.82   1683730909043"},{"gyro":"  0.52  -0.49  0.56   1683730909092"},{"gyro":"  0.52  -0.53  0.93   1683730909143"},{"gyro":"  0.55  -0.72  0.52   1683730909183"},{"gyro":"  0.53  -0.92  0.56   1683730909233"},{"gyro":"  0.56  -0.64  0.29   1683730909283"},{"gyro":"  0.56  -1.34  0.2   1683730909333"},{"gyro":"  0.53  -0.82  1.07   1683730909383"},{"gyro":"  0.58  -0.61  0.14   1683730909433"},{"gyro":"  0.52  -0.03  0.35   1683730909483"},{"gyro":"  0.56  -0.31  0.58   1683730909532"},{"gyro":"  0.5  0.11  0.11   1683730909583"},{"gyro":"  0.69  -0.56  -0.24   1683730909632"},{"gyro":"  0.69  -0.27  0.35   1683730909683"},{"gyro":"  0.64  -0.4  0.38   1683730909733"},{"gyro":"  0.73  -0.82  0.56   1683730909783"},{"gyro":"  0.87  -0.18  0.72   1683730909833"},{"gyro":"  0.78  -0.08  0.72   1683730909883"},{"gyro":"  0.58  -0.56  1.31   1683730909932"},{"gyro":"  0.64  -0.24  2.47   1683730909983"},{"gyro":"  0.56  -0.18  1.65   1683730910033"},{"gyro":"  0.78  -0.87  0.15   1683730910084"},{"gyro":"  0.72  -1.69  0.49   1683730910133"},{"gyro":"  0.67  -1.91  0.09   1683730910183"},{"gyro":"  0.69  -0.4  1.27   1683730910233"},{"gyro":"  0.69  -0.46  0.92   1683730910283"},{"gyro":"  0.69  -0.47  1.34   1683730910333"},{"gyro":"  0.64  0.39  0.21   1683730910383"},{"gyro":"  0.64  0.92  0.21   1683730910433"},{"gyro":"  0.7  0.49  0.27   1683730910483"},{"gyro":"  0.79  0.96  0.93   1683730910533"},{"gyro":"  0.67  -0.56  1.15   1683730910583"},{"gyro":"  0.69  -2.18  1.26   1683730910633"},{"gyro":"  0.64  -0.72  0.55   1683730910683"},{"gyro":"  0.69  1.79  1.17   1683730910733"},{"gyro":"  0.61  2.95  3.96   1683730910783"},{"gyro":"  0.75  2.37  3.37   1683730910843"},{"gyro":"  0.63  1.77  2.23   1683730910883"},{"gyro":"  0.53  1.75  3.48   1683730910933"},{"gyro":"  0.52  3.02  0.89   1683730910983"},{"gyro":"  0.63  4.64  1.22   1683730911033"},{"gyro":"  0.69  4.64  0.85   1683730911183"},{"gyro":"  0.72  2.06  0.66   1683730911233"},{"gyro":"  0.76  2.23  0.24   1683730911283"},{"gyro":"  0.78  2.06  0.22   1683730911333"},{"gyro":"  0.61  2.2  0.66   1683730911383"},{"gyro":"  0.67  1.22  0.49   1683730911433"},{"gyro":"  0.73  0.08  0.32   1683730911483"},{"gyro":"  0.78  1.88  0.47   1683730911533"},{"gyro":"  0.69  3.34  0.35   1683730911583"},{"gyro":"  0.64  3.27  0.67   1683730911633"},{"gyro":"  0.69  2.49  1.6   1683730911683"},{"gyro":"  -0.69  0.92  1.63   1683730911733"},{"gyro":"  0.64  2.41  1.69   1683730911783"},{"gyro":"  0.69  2.05  1.29   1683730911840"},{"gyro":"  0.56  2.
+---------------
diff --git a/out_metadata_prompt500.json b/out_metadata_prompt500.json
new file mode 100644
index 0000000..3106bad
--- /dev/null
+++ b/out_metadata_prompt500.json
@@ -0,0 +1,24 @@
+Overriding: out_dir = out-nd-small
+Overriding: dtype = float16
+number of parameters: 10.65M
+Loading meta from data/nd_small/meta.pkl...
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.52  -0.02  -2.37   1683730896832"},{"accelerometer":"  9.79  -0.35  -2.74   1683730896887"},{"accelerometer":"  9.85  -0.46  -2.36   1683730896932"},{"accelerometer":"  9.99  -0.23  -2.46   1683730896979"},{"accelerometer":"  9.6  -0.12  -2.49   1683730897029"},{"accelerometer":"  9.26  -0.02  -2.49   1683730897084"},{"accelerometer":"  9.53  -0.19  -2.87   1683730897129"},{"accelerometer":"  9.85  -0.22  -2.02   1683730897179"},{"accelerometer":"  9.78  0.22  -2.38   168373
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.83  0.02  -2.69   1683730896830"},{"accelerometer":"  9.79  0.05  -2.22   1683730896887"},{"accelerometer":"  9.79  -0.35  -2.27   1683730896979"},{"accelerometer":"  9.75  0.04  -2.27   1683730896029"},{"accelerometer":"  9.93  0.2  -2.22   1683730896084"},{"accelerometer":"  9.5  0.27  -2.37   1683730896129"},{"accelerometer":"  9.36  0.29  -2.27   1683730896179"},{"accelerometer":"  9.42  0.02  -2.23   1683730896229"},{"accelerometer":"  9.22  0.25  -2.12   1683730896279"
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.69  0.02  -2.32   1683730896830"},{"accelerometer":"  9.77  0.17  -2.25   1683730896889"},{"accelerometer":"  9.72  0.18  -2.02   1683730896930"},{"accelerometer":"  9.72  0.04  -2.28   1683730896979"},{"accelerometer":"  9.79  0.15  -2.43   1683730897029"},{"accelerometer":"  9.79  0.06  -2.41   1683730897029"},{"accelerometer":"  9.32  0.02  -2.26   1683730897080"},{"accelerometer":"  9.13  0.03  -2.57   1683730897129"},{"accelerometer":"  9.31  0.31  -2.8   1683730897179"
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.7  -0.14  -2.03   1683730896829"},{"accelerometer":"  9.77  -0.19  -2.08   1683730896880"},{"accelerometer":"  9.7  -0.05  -2.27   1683730896929"},{"accelerometer":"  9.98  -0.28  -2.02   1683730896979"},{"accelerometer":"  9.78  0.55  -2.46   1683730897029"},{"accelerometer":"  9.73  0.19  -2.49   1683730897079"},{"accelerometer":"  9.75  0.2  -2.02   1683730897129"},{"accelerometer":"  9.99  0.27  -2.19   1683730897179"},{"accelerometer":"  9.74  0.05  -2.32   168373089722
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.78  -0.09  -2.04   1683730896830"},{"accelerometer":"  9.57  -0.1  -2.28   1683730896889"},{"accelerometer":"  9.74  0.11  -2.9   1683730896929"},{"accelerometer":"  9.52  0.37  -2.34   1683730896979"},{"accelerometer":"  9.15  0.24  -2.25   1683730897029"},{"accelerometer":"  9.6  0.36  -2.24   1683730897080"},{"accelerometer":"  9.95  0.37  -2.19   1683730897129"},{"accelerometer":"  9.92  0.38  -2.31   1683730897179"},{"accelerometer":"  9.83  0.29  -2.34   1683730897229"
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.81  0.22  -2.31   1683730896830"},{"accelerometer":"  9.76  0.0  -2.4   1683730896879"},{"accelerometer":"  9.52  0.26  -2.33   1683730896929"},{"accelerometer":"  9.72  0.09  -2.38   1683730896979"},{"accelerometer":"  9.68  -0.03  -2.22   1683730897029"},{"accelerometer":"  9.72  0.15  -2.19   1683730897080"},{"accelerometer":"  9.72  0.05  -2.11   1683730897129"},{"accelerometer":"  9.72  0.07  -2.19   1683730897179"},{"accelerometer":"  9.49  0.06  -2.93   1683730897229"
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.54  -0.09  -2.29   1683730896830"},{"accelerometer":"  10.03  -0.05  -2.25   1683730896889"},{"accelerometer":"  9.9  -0.01  -2.17   1683730896929"},{"accelerometer":"  9.7  -0.02  -2.67   1683730896979"},{"accelerometer":"  9.67  -0.01  -2.05   1683730897029"},{"accelerometer":"  9.72  0.24  -2.17   1683730897083"},{"accelerometer":"  9.77  0.22  -2.19   1683730897129"},{"accelerometer":"  9.58  0.01  -2.35   1683730897179"},{"accelerometer":"  9.74  0.34  -2.18   168373089
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.95  0.04  -2.12   1683730896830"},{"accelerometer":"  9.85  0.44  -2.13   1683730896897"},{"accelerometer":"  9.71  0.24  -2.17   1683730896930"},{"accelerometer":"  9.88  0.12  -2.29   1683730896980"},{"accelerometer":"  9.82  0.17  -2.01   1683730897029"},{"accelerometer":"  9.81  0.28  -2.2   1683730897080"},{"accelerometer":"  9.83  0.16  -2.34   1683730897129"},{"accelerometer":"  9.57  0.09  -2.14   1683730897179"},{"accelerometer":"  9.61  0.07  -2.9   1683730897229"}
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.81  -0.18  -2.04   1683730896830"},{"accelerometer":"  9.7  -0.1,0,false]],[1683730896894,[0,"1.0.4.0",74,4.11,0,0,false]],[1683730897129,[0,"1.0.4.0",74,4.04,0,0,false]],[1683730897356,[0,"1.0.4.0",74,4.22,0,0,false]],[1683730897474,[0,"1.0.4.0",74,4.12,0,0,false]],[1683730897734,[0,"1.0.4.0",74,4.21,0,0,false]],[1683730897995,[0,"1.0.4.0",74,4.11,0,0,false]],[1683730898227,[0,"1.0.4.0",74,4.21,0,0,false]],[1683730898465,[0,"1.0.4.0",74,4.36,0,0,false]],[1683730898691,[0,"1
+---------------
+{"ProcessOBDDataFromDevice":false,"sensorMetaData":[{"accelerometer":"  9.5  0.42  -2.23   1683730896429"},{"accelerometer":"  9.55  0.2  -2.29   1683730896479"},{"accelerometer":"  9.72  -0.01  -2.07   1683730896530"},{"accelerometer":"  9.81  0.02  -2.15   1683730896580"},{"accelerometer":"  9.71  0.2  -2.19   1683730896629"},{"accelerometer":"  9.58  0.53  -2.02   1683730896679"},{"accelerometer":"  9.63  0.25  -2.19   1683730896730"},{"accelerometer":"  9.69  -0.01  -2.29   1683730896779"},{"accelerometer":"  9.5  0.48  -2.08   1683730896830"},{"accelerometer":"  9.42  -0.02  -2.56   1683730896887"},{"accelerometer":"  9.91  -0.03  -2.36   1683730896929"},{"accelerometer":"  9.75  0.28  -2.31   1683730896979"},{"accelerometer":"  9.75  0.13  -2.3   1683730897029"},{"accelerometer":"  9.72  0.15  -2.62   1683730897079"},{"accelerometer":"  9.78  0.46  -2.27   1683730897129"},{"accelerometer":"  9.86  0.12  -2.03   1683730897179"},{"accelerometer":"  9.92  0.24  -2.57   1683730897229
+---------------
diff --git a/sample.py b/sample.py
index 670759b..f5f6466 100644
--- a/sample.py
+++ b/sample.py
@@ -11,7 +11,7 @@ from model import GPTConfig, GPT
 # -----------------------------------------------------------------------------
 init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')
 out_dir = 'out' # ignored if init_from is not 'resume'
-start = "\n" # or "<|endoftext|>" or etc. Can also specify a file, use as: "FILE:prompt.txt"
+start = "FILE:data/nd_accel/prompt_accel.txt" #"{"#"\n" # or "<|endoftext|>" or etc. Can also specify a file, use as: "FILE:prompt.txt"
 num_samples = 10 # number of samples to draw
 max_new_tokens = 500 # number of tokens generated in each sample
 temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions
diff --git a/wandb/debug-cli.ubuntu.log b/wandb/debug-cli.ubuntu.log
new file mode 100644
index 0000000..e69de29
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
new file mode 120000
index 0000000..38dff48
--- /dev/null
+++ b/wandb/debug-internal.log
@@ -0,0 +1 @@
+run-20230522_231507-blj0gbia/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
new file mode 120000
index 0000000..259cad8
--- /dev/null
+++ b/wandb/debug.log
@@ -0,0 +1 @@
+run-20230522_231507-blj0gbia/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
new file mode 120000
index 0000000..56d21fe
--- /dev/null
+++ b/wandb/latest-run
@@ -0,0 +1 @@
+run-20230522_231507-blj0gbia
\ No newline at end of file
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/code/train.py b/wandb/run-20230518_192958-edbxtn7u/files/code/train.py
new file mode 100644
index 0000000..a0cd539
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/code/train.py
@@ -0,0 +1,331 @@
+"""
+This training script can be run both on a single gpu in debug mode,
+and also in a larger training run with distributed data parallel (ddp).
+
+To run on a single GPU, example:
+$ python train.py --batch_size=32 --compile=False
+
+To run with DDP on 4 gpus on 1 node, example:
+$ torchrun --standalone --nproc_per_node=4 train.py
+
+To run with DDP on 4 gpus across 2 nodes, example:
+- Run on the first (master) node with example IP 123.456.123.456:
+$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
+- Run on the worker node:
+$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py
+(If your cluster does not have Infiniband interconnect prepend NCCL_IB_DISABLE=1)
+"""
+
+import os
+import time
+import math
+import pickle
+from contextlib import nullcontext
+
+import numpy as np
+import torch
+from torch.nn.parallel import DistributedDataParallel as DDP
+from torch.distributed import init_process_group, destroy_process_group
+
+from model import GPTConfig, GPT
+
+# -----------------------------------------------------------------------------
+# default config values designed to train a gpt2 (124M) on OpenWebText
+# I/O
+out_dir = 'out'
+eval_interval = 2000
+log_interval = 1
+eval_iters = 200
+eval_only = False # if True, script exits right after the first eval
+always_save_checkpoint = True # if True, always save a checkpoint after each eval
+init_from = 'scratch' # 'scratch' or 'resume' or 'gpt2*'
+# wandb logging
+wandb_log = False # disabled by default
+wandb_project = 'owt'
+wandb_run_name = 'gpt2' # 'run' + str(time.time())
+# data
+dataset = 'openwebtext'
+gradient_accumulation_steps = 5 * 8 # used to simulate larger batch sizes
+batch_size = 12 # if gradient_accumulation_steps > 1, this is the micro-batch size
+block_size = 1024
+# model
+n_layer = 12
+n_head = 12
+n_embd = 768
+dropout = 0.0 # for pretraining 0 is good, for finetuning try 0.1+
+bias = False # do we use bias inside LayerNorm and Linear layers?
+# adamw optimizer
+learning_rate = 6e-4 # max learning rate
+max_iters = 600000 # total number of training iterations
+weight_decay = 1e-1
+beta1 = 0.9
+beta2 = 0.95
+grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0
+# learning rate decay settings
+decay_lr = True # whether to decay the learning rate
+warmup_iters = 2000 # how many steps to warm up for
+lr_decay_iters = 600000 # should be ~= max_iters per Chinchilla
+min_lr = 6e-5 # minimum learning rate, should be ~= learning_rate/10 per Chinchilla
+# DDP settings
+backend = 'nccl' # 'nccl', 'gloo', etc.
+# system
+device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks
+dtype = 'bfloat16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler
+compile = True # use PyTorch 2.0 to compile the model to be faster
+# -----------------------------------------------------------------------------
+config_keys = [k for k,v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))]
+exec(open('configurator.py').read()) # overrides from command line or config file
+config = {k: globals()[k] for k in config_keys} # will be useful for logging
+# -----------------------------------------------------------------------------
+
+# various inits, derived attributes, I/O setup
+ddp = int(os.environ.get('RANK', -1)) != -1 # is this a ddp run?
+if ddp:
+    init_process_group(backend=backend)
+    ddp_rank = int(os.environ['RANK'])
+    ddp_local_rank = int(os.environ['LOCAL_RANK'])
+    ddp_world_size = int(os.environ['WORLD_SIZE'])
+    device = f'cuda:{ddp_local_rank}'
+    torch.cuda.set_device(device)
+    master_process = ddp_rank == 0 # this process will do logging, checkpointing etc.
+    seed_offset = ddp_rank # each process gets a different seed
+    assert gradient_accumulation_steps % torch.cuda.device_count() == 0
+    gradient_accumulation_steps //= torch.cuda.device_count()
+else:
+    # if not ddp, we are running on a single gpu, and one process
+    master_process = True
+    seed_offset = 0
+    ddp_world_size = 1
+tokens_per_iter = gradient_accumulation_steps * ddp_world_size * batch_size * block_size
+print(f"tokens per iteration will be: {tokens_per_iter:,}")
+
+if master_process:
+    os.makedirs(out_dir, exist_ok=True)
+torch.manual_seed(1337 + seed_offset)
+torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul
+torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn
+device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast
+# note: float16 data type will automatically use a GradScaler
+ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]
+ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)
+
+# poor man's data loader
+data_dir = os.path.join('data', dataset)
+train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')
+val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')
+def get_batch(split):
+    data = train_data if split == 'train' else val_data
+    ix = torch.randint(len(data) - block_size, (batch_size,))
+    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])
+    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])
+    if device_type == 'cuda':
+        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)
+        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)
+    else:
+        x, y = x.to(device), y.to(device)
+    return x, y
+
+# init these up here, can override if init_from='resume' (i.e. from a checkpoint)
+iter_num = 0
+best_val_loss = 1e9
+
+# attempt to derive vocab_size from the dataset
+meta_path = os.path.join(data_dir, 'meta.pkl')
+meta_vocab_size = None
+if os.path.exists(meta_path):
+    with open(meta_path, 'rb') as f:
+        meta = pickle.load(f)
+    meta_vocab_size = meta['vocab_size']
+    print(f"found vocab_size = {meta_vocab_size} (inside {meta_path})")
+
+# model init
+model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,
+                  bias=bias, vocab_size=None, dropout=dropout) # start with model_args from command line
+if init_from == 'scratch':
+    # init a new model from scratch
+    print("Initializing a new model from scratch")
+    # determine the vocab size we'll use for from-scratch training
+    if meta_vocab_size is None:
+        print("defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)")
+    model_args['vocab_size'] = meta_vocab_size if meta_vocab_size is not None else 50304
+    gptconf = GPTConfig(**model_args)
+    model = GPT(gptconf)
+elif init_from == 'resume':
+    print(f"Resuming training from {out_dir}")
+    # resume training from a checkpoint.
+    ckpt_path = os.path.join(out_dir, 'ckpt.pt')
+    checkpoint = torch.load(ckpt_path, map_location=device)
+    checkpoint_model_args = checkpoint['model_args']
+    # force these config attributes to be equal otherwise we can't even resume training
+    # the rest of the attributes (e.g. dropout) can stay as desired from command line
+    for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:
+        model_args[k] = checkpoint_model_args[k]
+    # create the model
+    gptconf = GPTConfig(**model_args)
+    model = GPT(gptconf)
+    state_dict = checkpoint['model']
+    # fix the keys of the state dictionary :(
+    # honestly no idea how checkpoints sometimes get this prefix, have to debug more
+    unwanted_prefix = '_orig_mod.'
+    for k,v in list(state_dict.items()):
+        if k.startswith(unwanted_prefix):
+            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)
+    model.load_state_dict(state_dict)
+    iter_num = checkpoint['iter_num']
+    best_val_loss = checkpoint['best_val_loss']
+elif init_from.startswith('gpt2'):
+    print(f"Initializing from OpenAI GPT-2 weights: {init_from}")
+    # initialize from OpenAI GPT-2 weights
+    override_args = dict(dropout=dropout)
+    model = GPT.from_pretrained(init_from, override_args)
+    # read off the created config params, so we can store them into checkpoint correctly
+    for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:
+        model_args[k] = getattr(model.config, k)
+# crop down the model block size if desired, using model surgery
+if block_size < model.config.block_size:
+    model.crop_block_size(block_size)
+    model_args['block_size'] = block_size # so that the checkpoint will have the right value
+model.to(device)
+
+# initialize a GradScaler. If enabled=False scaler is a no-op
+scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
+
+# optimizer
+optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)
+if init_from == 'resume':
+    optimizer.load_state_dict(checkpoint['optimizer'])
+checkpoint = None # free up memory
+
+# compile the model
+if compile:
+    print("compiling the model... (takes a ~minute)")
+    unoptimized_model = model
+    model = torch.compile(model) # requires PyTorch 2.0
+
+# wrap model into DDP container
+if ddp:
+    model = DDP(model, device_ids=[ddp_local_rank])
+
+# helps estimate an arbitrarily accurate loss over either split using many batches
+@torch.no_grad()
+def estimate_loss():
+    out = {}
+    model.eval()
+    for split in ['train', 'val']:
+        losses = torch.zeros(eval_iters)
+        for k in range(eval_iters):
+            X, Y = get_batch(split)
+            with ctx:
+                logits, loss = model(X, Y)
+            losses[k] = loss.item()
+        out[split] = losses.mean()
+    model.train()
+    return out
+
+# learning rate decay scheduler (cosine with warmup)
+def get_lr(it):
+    # 1) linear warmup for warmup_iters steps
+    if it < warmup_iters:
+        return learning_rate * it / warmup_iters
+    # 2) if it > lr_decay_iters, return min learning rate
+    if it > lr_decay_iters:
+        return min_lr
+    # 3) in between, use cosine decay down to min learning rate
+    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)
+    assert 0 <= decay_ratio <= 1
+    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1
+    return min_lr + coeff * (learning_rate - min_lr)
+
+# logging
+if wandb_log and master_process:
+    import wandb
+    wandb.init(project=wandb_project, name=wandb_run_name, config=config)
+
+# training loop
+X, Y = get_batch('train') # fetch the very first batch
+t0 = time.time()
+local_iter_num = 0 # number of iterations in the lifetime of this process
+raw_model = model.module if ddp else model # unwrap DDP container if needed
+running_mfu = -1.0
+while True:
+
+    # determine and set the learning rate for this iteration
+    lr = get_lr(iter_num) if decay_lr else learning_rate
+    for param_group in optimizer.param_groups:
+        param_group['lr'] = lr
+
+    # evaluate the loss on train/val sets and write checkpoints
+    if iter_num % eval_interval == 0 and master_process:
+        losses = estimate_loss()
+        print(f"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")
+        if wandb_log:
+            wandb.log({
+                "iter": iter_num,
+                "train/loss": losses['train'],
+                "val/loss": losses['val'],
+                "lr": lr,
+                "mfu": running_mfu*100, # convert to percentage
+            })
+        if losses['val'] < best_val_loss or always_save_checkpoint:
+            best_val_loss = losses['val']
+            if iter_num > 0:
+                checkpoint = {
+                    'model': raw_model.state_dict(),
+                    'optimizer': optimizer.state_dict(),
+                    'model_args': model_args,
+                    'iter_num': iter_num,
+                    'best_val_loss': best_val_loss,
+                    'config': config,
+                }
+                print(f"saving checkpoint to {out_dir}")
+                torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))
+    if iter_num == 0 and eval_only:
+        break
+
+    # forward backward update, with optional gradient accumulation to simulate larger batch size
+    # and using the GradScaler if data type is float16
+    for micro_step in range(gradient_accumulation_steps):
+        if ddp:
+            # in DDP training we only need to sync gradients at the last micro step.
+            # the official way to do this is with model.no_sync() context manager, but
+            # I really dislike that this bloats the code and forces us to repeat code
+            # looking at the source of that context manager, it just toggles this variable
+            model.require_backward_grad_sync = (micro_step == gradient_accumulation_steps - 1)
+        with ctx:
+            logits, loss = model(X, Y)
+            loss = loss / gradient_accumulation_steps # scale the loss to account for gradient accumulation
+        # immediately async prefetch next batch while model is doing the forward pass on the GPU
+        X, Y = get_batch('train')
+        # backward pass, with gradient scaling if training in fp16
+        scaler.scale(loss).backward()
+    # clip the gradient
+    if grad_clip != 0.0:
+        scaler.unscale_(optimizer)
+        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
+    # step the optimizer and scaler if training in fp16
+    scaler.step(optimizer)
+    scaler.update()
+    # flush the gradients as soon as we can, no need for this memory anymore
+    optimizer.zero_grad(set_to_none=True)
+
+    # timing and logging
+    t1 = time.time()
+    dt = t1 - t0
+    t0 = t1
+    if iter_num % log_interval == 0 and master_process:
+        # get loss as float. note: this is a CPU-GPU sync point
+        # scale up to undo the division above, approximating the true total loss (exact would have been a sum)
+        lossf = loss.item() * gradient_accumulation_steps
+        if local_iter_num >= 5: # let the training loop settle a bit
+            mfu = raw_model.estimate_mfu(batch_size * gradient_accumulation_steps, dt)
+            running_mfu = mfu if running_mfu == -1.0 else 0.9*running_mfu + 0.1*mfu
+        print(f"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, mfu {running_mfu*100:.2f}%")
+    iter_num += 1
+    local_iter_num += 1
+
+    # termination conditions
+    if iter_num > max_iters:
+        break
+
+if ddp:
+    destroy_process_group()
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/conda-environment.yaml b/wandb/run-20230518_192958-edbxtn7u/files/conda-environment.yaml
new file mode 100644
index 0000000..ea6d977
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/conda-environment.yaml
@@ -0,0 +1,135 @@
+name: gpt
+channels:
+  - conda-forge
+  - defaults
+dependencies:
+  - _libgcc_mutex=0.1=conda_forge
+  - _openmp_mutex=4.5=2_gnu
+  - asttokens=2.2.1=pyhd8ed1ab_0
+  - backcall=0.2.0=pyh9f0ad1d_0
+  - backports=1.0=pyhd8ed1ab_3
+  - backports.functools_lru_cache=1.6.4=pyhd8ed1ab_0
+  - bzip2=1.0.8=h7f98852_4
+  - ca-certificates=2023.5.7=hbcca054_0
+  - debugpy=1.6.7=py39h227be39_0
+  - decorator=5.1.1=pyhd8ed1ab_0
+  - executing=1.2.0=pyhd8ed1ab_0
+  - importlib-metadata=6.6.0=pyha770c72_0
+  - importlib_metadata=6.6.0=hd8ed1ab_0
+  - ipykernel=6.14.0=py39hef51801_0
+  - ipython=8.4.0=py39hf3d152e_0
+  - jedi=0.18.2=pyhd8ed1ab_0
+  - jupyter_client=8.2.0=pyhd8ed1ab_0
+  - jupyter_core=5.3.0=py39hf3d152e_0
+  - ld_impl_linux-64=2.40=h41732ed_0
+  - libffi=3.4.2=h7f98852_5
+  - libgcc-ng=12.2.0=h65d4601_19
+  - libgomp=12.2.0=h65d4601_19
+  - libnsl=2.0.0=h7f98852_0
+  - libsodium=1.0.18=h36c2ea0_1
+  - libsqlite=3.41.2=h2797004_1
+  - libstdcxx-ng=12.2.0=h46fd767_19
+  - libuuid=2.38.1=h0b41bf4_0
+  - libzlib=1.2.13=h166bdaf_4
+  - matplotlib-inline=0.1.6=pyhd8ed1ab_0
+  - ncurses=6.3=h27087fc_1
+  - nest-asyncio=1.5.6=pyhd8ed1ab_0
+  - openssl=3.1.0=hd590300_3
+  - packaging=23.1=pyhd8ed1ab_0
+  - parso=0.8.3=pyhd8ed1ab_0
+  - pexpect=4.8.0=pyh1a96a4e_2
+  - pickleshare=0.7.5=py_1003
+  - pip=23.1.2=pyhd8ed1ab_0
+  - platformdirs=3.5.1=pyhd8ed1ab_0
+  - prompt-toolkit=3.0.38=pyha770c72_0
+  - psutil=5.9.5=py39h72bdee0_0
+  - ptyprocess=0.7.0=pyhd3deb0d_0
+  - pure_eval=0.2.2=pyhd8ed1ab_0
+  - pygments=2.15.1=pyhd8ed1ab_0
+  - python=3.9.16=h2782a2a_0_cpython
+  - python-dateutil=2.8.2=pyhd8ed1ab_0
+  - python_abi=3.9=3_cp39
+  - pyzmq=25.0.2=py39h0be026e_0
+  - readline=8.2=h8228510_1
+  - setuptools=67.7.2=pyhd8ed1ab_0
+  - six=1.16.0=pyh6c4a22f_0
+  - stack_data=0.6.2=pyhd8ed1ab_0
+  - tk=8.6.12=h27826a3_0
+  - tornado=6.3=py39h72bdee0_0
+  - traitlets=5.9.0=pyhd8ed1ab_0
+  - typing-extensions=4.5.0=hd8ed1ab_0
+  - typing_extensions=4.5.0=pyha770c72_0
+  - wcwidth=0.2.6=pyhd8ed1ab_0
+  - wheel=0.40.0=pyhd8ed1ab_0
+  - xz=5.2.6=h166bdaf_0
+  - zeromq=4.3.4=h9c3ff4c_1
+  - zipp=3.15.0=pyhd8ed1ab_0
+  - pip:
+    - appdirs==1.4.4
+    - boto==2.49.0
+    - boto3==1.26.133
+    - botocore==1.29.133
+    - certifi==2023.5.7
+    - charset-normalizer==3.1.0
+    - click==8.1.3
+    - cmake==3.26.3
+    - contourpy==1.0.7
+    - cycler==0.11.0
+    - dnspython==2.3.0
+    - docker-pycreds==0.4.0
+    - filelock==3.12.0
+    - fonttools==4.39.4
+    - gitdb==4.0.10
+    - gitpython==3.1.31
+    - greenlet==2.0.2
+    - idna==3.4
+    - importlib-resources==5.12.0
+    - influxdb-client==1.36.1
+    - jinja2==3.1.2
+    - jmespath==1.0.1
+    - kiwisolver==1.4.4
+    - lit==16.0.3
+    - markupsafe==2.1.2
+    - matplotlib==3.7.1
+    - mpmath==1.3.0
+    - networkx==3.1
+    - numpy==1.24.3
+    - nvidia-cublas-cu11==11.10.3.66
+    - nvidia-cuda-cupti-cu11==11.7.101
+    - nvidia-cuda-nvrtc-cu11==11.7.99
+    - nvidia-cuda-runtime-cu11==11.7.99
+    - nvidia-cudnn-cu11==8.5.0.96
+    - nvidia-cufft-cu11==10.9.0.58
+    - nvidia-curand-cu11==10.2.10.91
+    - nvidia-cusolver-cu11==11.4.0.1
+    - nvidia-cusparse-cu11==11.7.4.91
+    - nvidia-nccl-cu11==2.14.3
+    - nvidia-nvtx-cu11==11.7.91
+    - pandas==2.0.1
+    - pathtools==0.1.2
+    - pillow==9.5.0
+    - protobuf==4.23.0
+    - psycopg2-binary==2.9.6
+    - pymongo==4.3.3
+    - pyparsing==3.0.9
+    - pytz==2023.3
+    - pyyaml==6.0
+    - reactivex==4.0.4
+    - regex==2023.5.5
+    - requests==2.30.0
+    - s3transfer==0.6.1
+    - sentry-sdk==1.22.2
+    - setproctitle==1.3.2
+    - smmap==5.0.0
+    - sqlalchemy==2.0.13
+    - sympy==1.12
+    - tiktoken==0.4.0
+    - torch==2.0.1
+    - torchaudio==2.0.2
+    - torchvision==0.15.2
+    - tqdm==4.65.0
+    - triton==2.0.0
+    - tzdata==2023.3
+    - urllib3==1.26.15
+    - wandb==0.15.2
+prefix: /home/ubuntu/anaconda3/envs/gpt
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/config.yaml b/wandb/run-20230518_192958-edbxtn7u/files/config.yaml
new file mode 100644
index 0000000..64d614b
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/config.yaml
@@ -0,0 +1,126 @@
+wandb_version: 1
+
+out_dir:
+  desc: null
+  value: out-shakespeare-char
+eval_interval:
+  desc: null
+  value: 250
+log_interval:
+  desc: null
+  value: 10
+eval_iters:
+  desc: null
+  value: 200
+eval_only:
+  desc: null
+  value: false
+always_save_checkpoint:
+  desc: null
+  value: false
+init_from:
+  desc: null
+  value: scratch
+wandb_log:
+  desc: null
+  value: true
+wandb_project:
+  desc: null
+  value: shakespeare-char
+wandb_run_name:
+  desc: null
+  value: mini-gpt
+dataset:
+  desc: null
+  value: shakespeare_char
+gradient_accumulation_steps:
+  desc: null
+  value: 1
+batch_size:
+  desc: null
+  value: 64
+block_size:
+  desc: null
+  value: 256
+n_layer:
+  desc: null
+  value: 6
+n_head:
+  desc: null
+  value: 6
+n_embd:
+  desc: null
+  value: 384
+dropout:
+  desc: null
+  value: 0.2
+bias:
+  desc: null
+  value: false
+learning_rate:
+  desc: null
+  value: 0.001
+max_iters:
+  desc: null
+  value: 5000
+weight_decay:
+  desc: null
+  value: 0.1
+beta1:
+  desc: null
+  value: 0.9
+beta2:
+  desc: null
+  value: 0.99
+grad_clip:
+  desc: null
+  value: 1.0
+decay_lr:
+  desc: null
+  value: true
+warmup_iters:
+  desc: null
+  value: 100
+lr_decay_iters:
+  desc: null
+  value: 5000
+min_lr:
+  desc: null
+  value: 0.0001
+backend:
+  desc: null
+  value: nccl
+device:
+  desc: null
+  value: cuda
+dtype:
+  desc: null
+  value: float16
+compile:
+  desc: null
+  value: true
+_wandb:
+  desc: null
+  value:
+    code_path: code/train.py
+    python_version: 3.9.16
+    cli_version: 0.15.2
+    framework: torch
+    is_jupyter_run: false
+    is_kaggle_kernel: false
+    start_time: 1684438198.918533
+    t:
+      1:
+      - 1
+      - 55
+      2:
+      - 1
+      - 55
+      3:
+      - 13
+      - 16
+      - 23
+      4: 3.9.16
+      5: 0.15.2
+      8:
+      - 5
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/diff.patch b/wandb/run-20230518_192958-edbxtn7u/files/diff.patch
new file mode 100644
index 0000000..61ce84a
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/diff.patch
@@ -0,0 +1,26 @@
+diff --git a/config/train_shakespeare_char.py b/config/train_shakespeare_char.py
+index 41c81df..8be79b6 100644
+--- a/config/train_shakespeare_char.py
++++ b/config/train_shakespeare_char.py
+@@ -9,7 +9,7 @@ log_interval = 10 # don't print too too often
+ # we expect to overfit on this small dataset, so only save when val improves
+ always_save_checkpoint = False
+ 
+-wandb_log = False # override via command line if you like
++wandb_log = True # override via command line if you like
+ wandb_project = 'shakespeare-char'
+ wandb_run_name = 'mini-gpt'
+ 
+diff --git a/sample.py b/sample.py
+index 670759b..65a5888 100644
+--- a/sample.py
++++ b/sample.py
+@@ -11,7 +11,7 @@ from model import GPTConfig, GPT
+ # -----------------------------------------------------------------------------
+ init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')
+ out_dir = 'out' # ignored if init_from is not 'resume'
+-start = "\n" # or "<|endoftext|>" or etc. Can also specify a file, use as: "FILE:prompt.txt"
++start = "FILE:data/nd_small/prompt.txt" #"{"#"\n" # or "<|endoftext|>" or etc. Can also specify a file, use as: "FILE:prompt.txt"
+ num_samples = 10 # number of samples to draw
+ max_new_tokens = 500 # number of tokens generated in each sample
+ temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/output.log b/wandb/run-20230518_192958-edbxtn7u/files/output.log
new file mode 100644
index 0000000..bd226c6
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/output.log
@@ -0,0 +1,542 @@
+
+step 0: train loss 4.2874, val loss 4.2823
+[2023-05-18 19:30:26,254] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:26,801] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:27,636] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:27,932] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:28,332] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:28,629] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:29,029] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:29,325] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:29,894] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:30,191] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:30,590] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-18 19:30:30,886] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+iter 0: loss 4.2649, time 29992.73ms, mfu -100.00%
+iter 10: loss 3.2438, time 109.47ms, mfu 3.40%
+iter 20: loss 2.7898, time 109.89ms, mfu 3.40%
+iter 30: loss 2.6383, time 110.88ms, mfu 3.40%
+iter 40: loss 2.5763, time 110.71ms, mfu 3.40%
+iter 50: loss 2.5261, time 110.63ms, mfu 3.39%
+iter 60: loss 2.5136, time 110.33ms, mfu 3.39%
+iter 70: loss 2.4922, time 110.68ms, mfu 3.39%
+iter 80: loss 2.4932, time 110.33ms, mfu 3.39%
+iter 90: loss 2.4696, time 111.46ms, mfu 3.38%
+iter 100: loss 2.4524, time 109.82ms, mfu 3.38%
+iter 110: loss 2.4545, time 110.19ms, mfu 3.38%
+iter 120: loss 2.4226, time 111.09ms, mfu 3.38%
+iter 130: loss 2.4059, time 110.50ms, mfu 3.38%
+iter 140: loss 2.3932, time 110.97ms, mfu 3.38%
+iter 150: loss 2.4086, time 114.22ms, mfu 3.37%
+iter 160: loss 2.3653, time 110.63ms, mfu 3.37%
+iter 170: loss 2.3319, time 111.03ms, mfu 3.37%
+iter 180: loss 2.3027, time 109.77ms, mfu 3.37%
+iter 190: loss 2.2395, time 111.45ms, mfu 3.37%
+iter 200: loss 2.2080, time 110.26ms, mfu 3.37%
+iter 210: loss 2.1239, time 111.88ms, mfu 3.36%
+iter 220: loss 2.1337, time 112.21ms, mfu 3.36%
+iter 230: loss 2.0726, time 112.01ms, mfu 3.36%
+iter 240: loss 2.0728, time 112.00ms, mfu 3.35%
+step 250: train loss 1.9617, val loss 2.0626
+saving checkpoint to out-shakespeare-char
+iter 250: loss 2.0269, time 14101.03ms, mfu 3.02%
+iter 260: loss 1.9739, time 112.04ms, mfu 3.05%
+iter 270: loss 1.9756, time 112.06ms, mfu 3.08%
+iter 280: loss 1.9810, time 111.91ms, mfu 3.10%
+iter 290: loss 1.9211, time 111.45ms, mfu 3.13%
+iter 300: loss 1.9047, time 111.65ms, mfu 3.15%
+iter 310: loss 1.8702, time 110.84ms, mfu 3.17%
+iter 320: loss 1.8554, time 114.01ms, mfu 3.18%
+iter 330: loss 1.8166, time 111.52ms, mfu 3.20%
+iter 340: loss 1.7835, time 112.26ms, mfu 3.21%
+iter 350: loss 1.8240, time 111.95ms, mfu 3.22%
+iter 360: loss 1.7727, time 112.81ms, mfu 3.23%
+iter 370: loss 1.7427, time 111.52ms, mfu 3.24%
+iter 380: loss 1.7297, time 113.80ms, mfu 3.24%
+iter 390: loss 1.7358, time 112.46ms, mfu 3.25%
+iter 400: loss 1.7634, time 113.70ms, mfu 3.25%
+iter 410: loss 1.6962, time 112.95ms, mfu 3.26%
+iter 420: loss 1.7066, time 113.76ms, mfu 3.26%
+iter 430: loss 1.6841, time 113.13ms, mfu 3.26%
+iter 440: loss 1.6463, time 112.24ms, mfu 3.27%
+iter 450: loss 1.6518, time 114.59ms, mfu 3.27%
+iter 460: loss 1.5964, time 114.78ms, mfu 3.26%
+iter 470: loss 1.6596, time 115.01ms, mfu 3.26%
+iter 480: loss 1.6250, time 113.48ms, mfu 3.26%
+iter 490: loss 1.6047, time 113.89ms, mfu 3.27%
+step 500: train loss 1.5320, val loss 1.7376
+saving checkpoint to out-shakespeare-char
+iter 500: loss 1.6036, time 11442.02ms, mfu 2.94%
+iter 510: loss 1.6118, time 113.44ms, mfu 2.98%
+iter 520: loss 1.5995, time 114.29ms, mfu 3.00%
+iter 530: loss 1.5608, time 113.94ms, mfu 3.03%
+iter 540: loss 1.6197, time 116.03ms, mfu 3.05%
+iter 550: loss 1.5665, time 113.69ms, mfu 3.07%
+iter 560: loss 1.5724, time 115.11ms, mfu 3.09%
+iter 570: loss 1.5784, time 113.40ms, mfu 3.11%
+iter 580: loss 1.5392, time 115.41ms, mfu 3.12%
+iter 590: loss 1.5042, time 115.55ms, mfu 3.13%
+iter 600: loss 1.5235, time 115.85ms, mfu 3.14%
+iter 610: loss 1.5488, time 115.65ms, mfu 3.15%
+iter 620: loss 1.5305, time 116.81ms, mfu 3.15%
+iter 630: loss 1.5144, time 116.58ms, mfu 3.16%
+iter 640: loss 1.4758, time 114.38ms, mfu 3.17%
+iter 650: loss 1.5089, time 116.36ms, mfu 3.17%
+iter 660: loss 1.5117, time 115.66ms, mfu 3.18%
+iter 670: loss 1.4419, time 115.34ms, mfu 3.18%
+iter 680: loss 1.5172, time 114.95ms, mfu 3.19%
+iter 690: loss 1.4691, time 117.18ms, mfu 3.19%
+iter 700: loss 1.4832, time 115.80ms, mfu 3.19%
+iter 710: loss 1.4598, time 115.03ms, mfu 3.19%
+iter 720: loss 1.4497, time 116.09ms, mfu 3.20%
+iter 730: loss 1.4210, time 114.86ms, mfu 3.20%
+iter 740: loss 1.4289, time 117.11ms, mfu 3.20%
+step 750: train loss 1.3649, val loss 1.5938
+saving checkpoint to out-shakespeare-char
+iter 750: loss 1.4318, time 11727.39ms, mfu 2.88%
+iter 760: loss 1.4451, time 118.28ms, mfu 2.91%
+iter 770: loss 1.4361, time 117.73ms, mfu 2.93%
+iter 780: loss 1.4205, time 117.10ms, mfu 2.96%
+iter 790: loss 1.4194, time 115.01ms, mfu 2.99%
+iter 800: loss 1.4317, time 118.64ms, mfu 3.00%
+iter 810: loss 1.4077, time 115.91ms, mfu 3.02%
+iter 820: loss 1.4145, time 117.51ms, mfu 3.04%
+iter 830: loss 1.3942, time 118.19ms, mfu 3.05%
+iter 840: loss 1.4187, time 118.84ms, mfu 3.06%
+iter 850: loss 1.3976, time 116.72ms, mfu 3.07%
+iter 860: loss 1.3955, time 116.98ms, mfu 3.08%
+iter 870: loss 1.4028, time 117.81ms, mfu 3.09%
+iter 880: loss 1.3720, time 118.85ms, mfu 3.10%
+iter 890: loss 1.3934, time 117.54ms, mfu 3.10%
+iter 900: loss 1.3732, time 117.92ms, mfu 3.11%
+iter 910: loss 1.3249, time 117.48ms, mfu 3.12%
+iter 920: loss 1.3641, time 117.50ms, mfu 3.12%
+iter 930: loss 1.3632, time 118.16ms, mfu 3.12%
+iter 940: loss 1.3463, time 117.57ms, mfu 3.13%
+iter 950: loss 1.3571, time 117.09ms, mfu 3.13%
+iter 960: loss 1.3658, time 117.39ms, mfu 3.14%
+iter 970: loss 1.3642, time 118.60ms, mfu 3.14%
+iter 980: loss 1.3620, time 117.38ms, mfu 3.14%
+iter 990: loss 1.3408, time 118.16ms, mfu 3.14%
+step 1000: train loss 1.2747, val loss 1.5291
+saving checkpoint to out-shakespeare-char
+iter 1000: loss 1.3380, time 11908.71ms, mfu 2.83%
+iter 1010: loss 1.3440, time 118.92ms, mfu 2.86%
+iter 1020: loss 1.3147, time 118.52ms, mfu 2.89%
+iter 1030: loss 1.3429, time 117.50ms, mfu 2.92%
+iter 1040: loss 1.3572, time 118.69ms, mfu 2.94%
+iter 1050: loss 1.2933, time 119.12ms, mfu 2.96%
+iter 1060: loss 1.3498, time 118.20ms, mfu 2.98%
+iter 1070: loss 1.3338, time 118.13ms, mfu 3.00%
+iter 1080: loss 1.3394, time 117.97ms, mfu 3.01%
+iter 1090: loss 1.3523, time 118.72ms, mfu 3.03%
+iter 1100: loss 1.3170, time 117.46ms, mfu 3.04%
+iter 1110: loss 1.3003, time 119.34ms, mfu 3.05%
+iter 1120: loss 1.3106, time 120.23ms, mfu 3.05%
+iter 1130: loss 1.3056, time 119.51ms, mfu 3.06%
+iter 1140: loss 1.3111, time 117.30ms, mfu 3.07%
+iter 1150: loss 1.3145, time 118.93ms, mfu 3.08%
+iter 1160: loss 1.3264, time 121.27ms, mfu 3.08%
+iter 1170: loss 1.3033, time 117.77ms, mfu 3.09%
+iter 1180: loss 1.3207, time 118.38ms, mfu 3.09%
+iter 1190: loss 1.2758, time 121.15ms, mfu 3.09%
+iter 1200: loss 1.2979, time 120.06ms, mfu 3.09%
+iter 1210: loss 1.2748, time 120.10ms, mfu 3.09%
+iter 1220: loss 1.3085, time 120.10ms, mfu 3.09%
+iter 1230: loss 1.2953, time 121.04ms, mfu 3.09%
+iter 1240: loss 1.3011, time 119.20ms, mfu 3.10%
+step 1250: train loss 1.2096, val loss 1.5029
+saving checkpoint to out-shakespeare-char
+iter 1250: loss 1.2764, time 11929.43ms, mfu 2.79%
+iter 1260: loss 1.2909, time 120.39ms, mfu 2.82%
+iter 1270: loss 1.2677, time 121.70ms, mfu 2.84%
+iter 1280: loss 1.2635, time 118.97ms, mfu 2.87%
+iter 1290: loss 1.2902, time 119.04ms, mfu 2.90%
+iter 1300: loss 1.3066, time 119.42ms, mfu 2.92%
+iter 1310: loss 1.2388, time 118.59ms, mfu 2.94%
+iter 1320: loss 1.3099, time 122.07ms, mfu 2.95%
+iter 1330: loss 1.2699, time 121.88ms, mfu 2.96%
+iter 1340: loss 1.2982, time 121.31ms, mfu 2.97%
+iter 1350: loss 1.2562, time 120.26ms, mfu 2.99%
+iter 1360: loss 1.2774, time 120.80ms, mfu 3.00%
+iter 1370: loss 1.2605, time 118.34ms, mfu 3.01%
+iter 1380: loss 1.2713, time 120.05ms, mfu 3.02%
+iter 1390: loss 1.2582, time 119.47ms, mfu 3.03%
+iter 1400: loss 1.2624, time 122.09ms, mfu 3.03%
+iter 1410: loss 1.2539, time 120.90ms, mfu 3.04%
+iter 1420: loss 1.2748, time 119.72ms, mfu 3.05%
+iter 1430: loss 1.2462, time 119.48ms, mfu 3.05%
+iter 1440: loss 1.2658, time 120.81ms, mfu 3.06%
+iter 1450: loss 1.2326, time 121.80ms, mfu 3.06%
+iter 1460: loss 1.2493, time 120.78ms, mfu 3.06%
+iter 1470: loss 1.2229, time 120.07ms, mfu 3.06%
+iter 1480: loss 1.2154, time 121.20ms, mfu 3.06%
+iter 1490: loss 1.2435, time 120.56ms, mfu 3.07%
+step 1500: train loss 1.1570, val loss 1.4835
+saving checkpoint to out-shakespeare-char
+iter 1500: loss 1.1941, time 11973.64ms, mfu 2.76%
+iter 1510: loss 1.2462, time 118.72ms, mfu 2.80%
+iter 1520: loss 1.2291, time 117.92ms, mfu 2.84%
+iter 1530: loss 1.2550, time 118.71ms, mfu 2.87%
+iter 1540: loss 1.1968, time 119.31ms, mfu 2.89%
+iter 1550: loss 1.2333, time 119.03ms, mfu 2.92%
+iter 1560: loss 1.2110, time 119.21ms, mfu 2.94%
+iter 1570: loss 1.2332, time 117.77ms, mfu 2.96%
+iter 1580: loss 1.2087, time 119.36ms, mfu 2.98%
+iter 1590: loss 1.1950, time 118.29ms, mfu 2.99%
+iter 1600: loss 1.2010, time 119.88ms, mfu 3.01%
+iter 1610: loss 1.2358, time 118.67ms, mfu 3.02%
+iter 1620: loss 1.1864, time 118.36ms, mfu 3.03%
+iter 1630: loss 1.2088, time 118.83ms, mfu 3.04%
+iter 1640: loss 1.2106, time 118.12ms, mfu 3.05%
+iter 1650: loss 1.1869, time 117.45ms, mfu 3.07%
+iter 1660: loss 1.2190, time 118.51ms, mfu 3.07%
+iter 1670: loss 1.2000, time 117.44ms, mfu 3.08%
+iter 1680: loss 1.2054, time 118.74ms, mfu 3.09%
+iter 1690: loss 1.2070, time 119.57ms, mfu 3.09%
+iter 1700: loss 1.1919, time 117.52ms, mfu 3.10%
+iter 1710: loss 1.1856, time 118.02ms, mfu 3.11%
+iter 1720: loss 1.1817, time 118.54ms, mfu 3.11%
+iter 1730: loss 1.2041, time 118.29ms, mfu 3.11%
+iter 1740: loss 1.1745, time 118.91ms, mfu 3.12%
+step 1750: train loss 1.1043, val loss 1.4646
+saving checkpoint to out-shakespeare-char
+iter 1750: loss 1.1854, time 11844.26ms, mfu 2.81%
+iter 1760: loss 1.1959, time 118.27ms, mfu 2.84%
+iter 1770: loss 1.2047, time 117.44ms, mfu 2.87%
+iter 1780: loss 1.1986, time 118.72ms, mfu 2.90%
+iter 1790: loss 1.1942, time 117.55ms, mfu 2.93%
+iter 1800: loss 1.1834, time 118.22ms, mfu 2.95%
+iter 1810: loss 1.1633, time 118.94ms, mfu 2.97%
+iter 1820: loss 1.1692, time 120.04ms, mfu 2.98%
+iter 1830: loss 1.1819, time 117.84ms, mfu 3.00%
+iter 1840: loss 1.1637, time 117.33ms, mfu 3.02%
+iter 1850: loss 1.1658, time 120.20ms, mfu 3.03%
+iter 1860: loss 1.1779, time 119.87ms, mfu 3.03%
+iter 1870: loss 1.1432, time 117.89ms, mfu 3.05%
+iter 1880: loss 1.1848, time 118.74ms, mfu 3.06%
+iter 1890: loss 1.1845, time 117.41ms, mfu 3.07%
+iter 1900: loss 1.1346, time 117.55ms, mfu 3.08%
+iter 1910: loss 1.1722, time 119.11ms, mfu 3.08%
+iter 1920: loss 1.1768, time 117.89ms, mfu 3.09%
+iter 1930: loss 1.1476, time 119.21ms, mfu 3.09%
+iter 1940: loss 1.1301, time 117.53ms, mfu 3.10%
+iter 1950: loss 1.1465, time 118.53ms, mfu 3.11%
+iter 1960: loss 1.1619, time 118.05ms, mfu 3.11%
+iter 1970: loss 1.1610, time 117.78ms, mfu 3.12%
+iter 1980: loss 1.1534, time 119.37ms, mfu 3.12%
+iter 1990: loss 1.1566, time 119.87ms, mfu 3.12%
+step 2000: train loss 1.0597, val loss 1.4743
+iter 2000: loss 1.1444, time 11532.39ms, mfu 2.81%
+iter 2010: loss 1.1310, time 121.03ms, mfu 2.83%
+iter 2020: loss 1.1253, time 118.40ms, mfu 2.87%
+iter 2030: loss 1.1565, time 118.00ms, mfu 2.90%
+iter 2040: loss 1.1401, time 118.78ms, mfu 2.92%
+iter 2050: loss 1.1237, time 118.13ms, mfu 2.94%
+iter 2060: loss 1.1076, time 117.61ms, mfu 2.97%
+iter 2070: loss 1.1312, time 119.93ms, mfu 2.98%
+iter 2080: loss 1.1247, time 117.27ms, mfu 3.00%
+iter 2090: loss 1.1367, time 117.13ms, mfu 3.02%
+iter 2100: loss 1.1421, time 117.67ms, mfu 3.03%
+iter 2110: loss 1.1376, time 118.02ms, mfu 3.04%
+iter 2120: loss 1.1276, time 117.71ms, mfu 3.06%
+iter 2130: loss 1.1409, time 119.95ms, mfu 3.06%
+iter 2140: loss 1.1410, time 117.60ms, mfu 3.07%
+iter 2150: loss 1.1270, time 118.32ms, mfu 3.08%
+iter 2160: loss 1.1524, time 117.56ms, mfu 3.09%
+iter 2170: loss 1.1346, time 117.90ms, mfu 3.10%
+iter 2180: loss 1.1142, time 115.81ms, mfu 3.11%
+iter 2190: loss 1.1101, time 117.92ms, mfu 3.11%
+iter 2200: loss 1.1214, time 118.72ms, mfu 3.12%
+iter 2210: loss 1.1200, time 116.98ms, mfu 3.12%
+iter 2220: loss 1.1166, time 119.37ms, mfu 3.12%
+iter 2230: loss 1.1292, time 117.51ms, mfu 3.13%
+iter 2240: loss 1.1279, time 118.76ms, mfu 3.13%
+step 2250: train loss 1.0139, val loss 1.4880
+iter 2250: loss 1.1119, time 11530.82ms, mfu 2.82%
+iter 2260: loss 1.1061, time 117.72ms, mfu 2.85%
+iter 2270: loss 1.1379, time 117.55ms, mfu 2.89%
+iter 2280: loss 1.1058, time 119.10ms, mfu 2.91%
+iter 2290: loss 1.1526, time 117.81ms, mfu 2.93%
+iter 2300: loss 1.1258, time 117.94ms, mfu 2.96%
+iter 2310: loss 1.0962, time 118.58ms, mfu 2.98%
+iter 2320: loss 1.1032, time 118.38ms, mfu 2.99%
+iter 2330: loss 1.0978, time 118.62ms, mfu 3.01%
+iter 2340: loss 1.1211, time 118.21ms, mfu 3.02%
+iter 2350: loss 1.1095, time 119.35ms, mfu 3.03%
+iter 2360: loss 1.1095, time 117.93ms, mfu 3.05%
+iter 2370: loss 1.0946, time 119.60ms, mfu 3.05%
+iter 2380: loss 1.0946, time 119.25ms, mfu 3.06%
+iter 2390: loss 1.0835, time 118.49ms, mfu 3.07%
+iter 2400: loss 1.0815, time 119.13ms, mfu 3.07%
+iter 2410: loss 1.0765, time 121.47ms, mfu 3.07%
+iter 2420: loss 1.0773, time 117.92ms, mfu 3.08%
+iter 2430: loss 1.0573, time 117.31ms, mfu 3.09%
+iter 2440: loss 1.0581, time 117.09ms, mfu 3.10%
+iter 2450: loss 1.0757, time 117.15ms, mfu 3.11%
+iter 2460: loss 1.0864, time 118.75ms, mfu 3.11%
+iter 2470: loss 1.0990, time 118.33ms, mfu 3.12%
+iter 2480: loss 1.0786, time 117.75ms, mfu 3.12%
+iter 2490: loss 1.0594, time 116.41ms, mfu 3.13%
+step 2500: train loss 0.9635, val loss 1.4973
+iter 2500: loss 1.0878, time 11531.38ms, mfu 2.82%
+iter 2510: loss 1.0775, time 117.75ms, mfu 2.85%
+iter 2520: loss 1.0508, time 118.08ms, mfu 2.88%
+iter 2530: loss 1.0606, time 117.15ms, mfu 2.91%
+iter 2540: loss 1.0602, time 118.92ms, mfu 2.94%
+iter 2550: loss 1.0749, time 118.17ms, mfu 2.96%
+iter 2560: loss 1.0625, time 116.87ms, mfu 2.98%
+iter 2570: loss 1.0872, time 119.07ms, mfu 3.00%
+iter 2580: loss 1.0862, time 118.20ms, mfu 3.01%
+iter 2590: loss 1.0699, time 116.92ms, mfu 3.03%
+iter 2600: loss 1.0722, time 117.79ms, mfu 3.04%
+iter 2610: loss 1.0553, time 117.97ms, mfu 3.05%
+iter 2620: loss 1.0443, time 117.46ms, mfu 3.07%
+iter 2630: loss 1.0321, time 117.90ms, mfu 3.07%
+iter 2640: loss 1.0454, time 116.90ms, mfu 3.09%
+iter 2650: loss 1.0755, time 117.51ms, mfu 3.09%
+iter 2660: loss 1.0463, time 117.57ms, mfu 3.10%
+iter 2670: loss 1.0276, time 117.56ms, mfu 3.11%
+iter 2680: loss 1.0546, time 118.25ms, mfu 3.11%
+iter 2690: loss 1.0552, time 117.34ms, mfu 3.12%
+iter 2700: loss 1.0228, time 118.99ms, mfu 3.12%
+iter 2710: loss 1.0503, time 119.24ms, mfu 3.12%
+iter 2720: loss 1.0514, time 119.39ms, mfu 3.12%
+iter 2730: loss 1.0606, time 117.77ms, mfu 3.13%
+iter 2740: loss 1.0288, time 118.11ms, mfu 3.13%
+step 2750: train loss 0.9179, val loss 1.5218
+iter 2750: loss 1.0439, time 11525.49ms, mfu 2.82%
+iter 2760: loss 1.0272, time 118.48ms, mfu 2.85%
+iter 2770: loss 1.0286, time 118.09ms, mfu 2.88%
+iter 2780: loss 1.0355, time 118.09ms, mfu 2.91%
+iter 2790: loss 1.0423, time 117.26ms, mfu 2.94%
+iter 2800: loss 1.0247, time 118.04ms, mfu 2.96%
+iter 2810: loss 1.0503, time 119.19ms, mfu 2.97%
+iter 2820: loss 1.0292, time 118.16ms, mfu 2.99%
+iter 2830: loss 1.0334, time 118.06ms, mfu 3.01%
+iter 2840: loss 1.0019, time 118.33ms, mfu 3.02%
+iter 2850: loss 1.0364, time 118.94ms, mfu 3.03%
+iter 2860: loss 1.0303, time 118.98ms, mfu 3.04%
+iter 2870: loss 1.0103, time 118.40ms, mfu 3.05%
+iter 2880: loss 1.0398, time 119.96ms, mfu 3.06%
+iter 2890: loss 1.0086, time 118.14ms, mfu 3.07%
+iter 2900: loss 1.0026, time 117.87ms, mfu 3.08%
+iter 2910: loss 1.0394, time 119.61ms, mfu 3.08%
+iter 2920: loss 1.0133, time 117.73ms, mfu 3.09%
+iter 2930: loss 0.9953, time 118.51ms, mfu 3.10%
+iter 2940: loss 0.9996, time 117.42ms, mfu 3.10%
+iter 2950: loss 1.0325, time 116.73ms, mfu 3.11%
+iter 2960: loss 1.0094, time 117.86ms, mfu 3.12%
+iter 2970: loss 0.9990, time 118.30ms, mfu 3.12%
+iter 2980: loss 0.9993, time 118.21ms, mfu 3.12%
+iter 2990: loss 0.9904, time 117.53ms, mfu 3.13%
+step 3000: train loss 0.8726, val loss 1.5215
+iter 3000: loss 0.9893, time 11517.75ms, mfu 2.82%
+iter 3010: loss 1.0015, time 117.72ms, mfu 2.85%
+iter 3020: loss 1.0050, time 118.51ms, mfu 2.88%
+iter 3030: loss 1.0047, time 118.59ms, mfu 2.91%
+iter 3040: loss 1.0318, time 117.72ms, mfu 2.93%
+iter 3050: loss 0.9819, time 118.17ms, mfu 2.96%
+iter 3060: loss 1.0043, time 117.69ms, mfu 2.98%
+iter 3070: loss 1.0205, time 119.37ms, mfu 2.99%
+iter 3080: loss 1.0017, time 118.03ms, mfu 3.01%
+iter 3090: loss 0.9822, time 117.83ms, mfu 3.02%
+iter 3100: loss 1.0025, time 121.04ms, mfu 3.03%
+iter 3110: loss 0.9765, time 118.05ms, mfu 3.04%
+iter 3120: loss 1.0044, time 116.65ms, mfu 3.06%
+iter 3130: loss 0.9760, time 117.59ms, mfu 3.07%
+iter 3140: loss 0.9897, time 117.61ms, mfu 3.08%
+iter 3150: loss 1.0045, time 118.16ms, mfu 3.09%
+iter 3160: loss 1.0181, time 118.04ms, mfu 3.09%
+iter 3170: loss 0.9678, time 117.88ms, mfu 3.10%
+iter 3180: loss 0.9846, time 117.63ms, mfu 3.11%
+iter 3190: loss 0.9978, time 118.01ms, mfu 3.11%
+iter 3200: loss 0.9710, time 118.62ms, mfu 3.11%
+iter 3210: loss 0.9771, time 117.79ms, mfu 3.12%
+iter 3220: loss 0.9637, time 118.85ms, mfu 3.12%
+iter 3230: loss 0.9543, time 118.21ms, mfu 3.12%
+iter 3240: loss 0.9639, time 119.06ms, mfu 3.12%
+step 3250: train loss 0.8288, val loss 1.5598
+iter 3250: loss 0.9761, time 11531.19ms, mfu 2.82%
+iter 3260: loss 0.9685, time 118.10ms, mfu 2.85%
+iter 3270: loss 0.9894, time 119.44ms, mfu 2.88%
+iter 3280: loss 0.9475, time 118.66ms, mfu 2.90%
+iter 3290: loss 0.9476, time 117.62ms, mfu 2.93%
+iter 3300: loss 0.9436, time 118.14ms, mfu 2.95%
+iter 3310: loss 0.9628, time 117.25ms, mfu 2.97%
+iter 3320: loss 0.9746, time 117.65ms, mfu 2.99%
+iter 3330: loss 0.9678, time 118.10ms, mfu 3.01%
+iter 3340: loss 0.9647, time 118.99ms, mfu 3.02%
+iter 3350: loss 0.9652, time 118.39ms, mfu 3.03%
+iter 3360: loss 0.9315, time 118.48ms, mfu 3.05%
+iter 3370: loss 0.9672, time 118.32ms, mfu 3.06%
+iter 3380: loss 0.9502, time 118.09ms, mfu 3.07%
+iter 3390: loss 0.9564, time 117.63ms, mfu 3.08%
+iter 3400: loss 0.9584, time 117.15ms, mfu 3.09%
+iter 3410: loss 0.9542, time 118.03ms, mfu 3.09%
+iter 3420: loss 0.9524, time 119.74ms, mfu 3.10%
+iter 3430: loss 0.9506, time 117.99ms, mfu 3.10%
+iter 3440: loss 0.9726, time 119.73ms, mfu 3.10%
+iter 3450: loss 0.9584, time 117.22ms, mfu 3.11%
+iter 3460: loss 0.9528, time 117.57ms, mfu 3.12%
+iter 3470: loss 0.9431, time 118.52ms, mfu 3.12%
+iter 3480: loss 0.9579, time 117.22ms, mfu 3.13%
+iter 3490: loss 0.9185, time 117.36ms, mfu 3.13%
+step 3500: train loss 0.7841, val loss 1.5790
+iter 3500: loss 0.9124, time 11536.24ms, mfu 2.82%
+iter 3510: loss 0.9192, time 117.64ms, mfu 2.85%
+iter 3520: loss 0.9288, time 118.11ms, mfu 2.88%
+iter 3530: loss 0.9618, time 119.12ms, mfu 2.91%
+iter 3540: loss 0.9365, time 117.74ms, mfu 2.93%
+iter 3550: loss 0.9271, time 119.34ms, mfu 2.95%
+iter 3560: loss 0.9566, time 118.31ms, mfu 2.97%
+iter 3570: loss 0.9421, time 117.99ms, mfu 2.99%
+iter 3580: loss 0.9393, time 120.68ms, mfu 3.00%
+iter 3590: loss 0.9363, time 117.90ms, mfu 3.02%
+iter 3600: loss 0.9414, time 117.51ms, mfu 3.03%
+iter 3610: loss 0.9119, time 118.23ms, mfu 3.04%
+iter 3620: loss 0.9183, time 119.74ms, mfu 3.05%
+iter 3630: loss 0.9337, time 117.68ms, mfu 3.06%
+iter 3640: loss 0.9236, time 117.89ms, mfu 3.07%
+iter 3650: loss 0.9230, time 118.24ms, mfu 3.08%
+iter 3660: loss 0.9367, time 118.74ms, mfu 3.09%
+iter 3670: loss 0.9328, time 118.36ms, mfu 3.09%
+iter 3680: loss 0.9116, time 117.72ms, mfu 3.10%
+iter 3690: loss 0.9453, time 118.13ms, mfu 3.11%
+iter 3700: loss 0.8789, time 117.67ms, mfu 3.11%
+iter 3710: loss 0.8844, time 118.70ms, mfu 3.11%
+iter 3720: loss 0.9087, time 117.42ms, mfu 3.12%
+iter 3730: loss 0.9066, time 118.60ms, mfu 3.12%
+iter 3740: loss 0.9099, time 118.35ms, mfu 3.12%
+step 3750: train loss 0.7458, val loss 1.6041
+iter 3750: loss 0.9085, time 11539.47ms, mfu 2.82%
+iter 3760: loss 0.9402, time 117.65ms, mfu 2.85%
+iter 3770: loss 0.9314, time 119.39ms, mfu 2.88%
+iter 3780: loss 0.9234, time 117.85ms, mfu 2.91%
+iter 3790: loss 0.9099, time 116.93ms, mfu 2.93%
+iter 3800: loss 0.9155, time 118.26ms, mfu 2.96%
+iter 3810: loss 0.9261, time 119.20ms, mfu 2.97%
+iter 3820: loss 0.8940, time 117.32ms, mfu 2.99%
+iter 3830: loss 0.9084, time 117.61ms, mfu 3.01%
+iter 3840: loss 0.8902, time 118.67ms, mfu 3.02%
+iter 3850: loss 0.8935, time 118.07ms, mfu 3.04%
+iter 3860: loss 0.8779, time 116.13ms, mfu 3.05%
+iter 3870: loss 0.8995, time 118.35ms, mfu 3.06%
+iter 3880: loss 0.8879, time 117.64ms, mfu 3.07%
+iter 3890: loss 0.8977, time 120.19ms, mfu 3.08%
+iter 3900: loss 0.8955, time 118.19ms, mfu 3.08%
+iter 3910: loss 0.8916, time 119.11ms, mfu 3.09%
+iter 3920: loss 0.8687, time 118.04ms, mfu 3.10%
+iter 3930: loss 0.8973, time 117.42ms, mfu 3.10%
+iter 3940: loss 0.8796, time 119.03ms, mfu 3.11%
+iter 3950: loss 0.8840, time 118.28ms, mfu 3.11%
+iter 3960: loss 0.9116, time 116.77ms, mfu 3.12%
+iter 3970: loss 0.9032, time 118.26ms, mfu 3.12%
+iter 3980: loss 0.9049, time 118.02ms, mfu 3.13%
+iter 3990: loss 0.8861, time 119.33ms, mfu 3.13%
+step 4000: train loss 0.7133, val loss 1.6323
+iter 4000: loss 0.8708, time 11536.70ms, mfu 2.82%
+iter 4010: loss 0.8823, time 118.11ms, mfu 2.85%
+iter 4020: loss 0.8962, time 119.12ms, mfu 2.88%
+iter 4030: loss 0.8862, time 119.02ms, mfu 2.90%
+iter 4040: loss 0.8780, time 118.95ms, mfu 2.93%
+iter 4050: loss 0.8738, time 118.50ms, mfu 2.95%
+iter 4060: loss 0.8704, time 119.84ms, mfu 2.96%
+iter 4070: loss 0.8582, time 116.90ms, mfu 2.99%
+iter 4080: loss 0.8897, time 118.26ms, mfu 3.00%
+iter 4090: loss 0.8496, time 120.66ms, mfu 3.01%
+iter 4100: loss 0.9025, time 118.37ms, mfu 3.02%
+iter 4110: loss 0.8779, time 117.25ms, mfu 3.04%
+iter 4120: loss 0.8923, time 117.06ms, mfu 3.05%
+iter 4130: loss 0.8643, time 118.13ms, mfu 3.06%
+iter 4140: loss 0.8882, time 117.28ms, mfu 3.08%
+iter 4150: loss 0.8743, time 117.96ms, mfu 3.08%
+iter 4160: loss 0.8677, time 118.53ms, mfu 3.09%
+iter 4170: loss 0.8698, time 117.99ms, mfu 3.10%
+iter 4180: loss 0.8799, time 118.07ms, mfu 3.10%
+iter 4190: loss 0.8754, time 118.02ms, mfu 3.11%
+iter 4200: loss 0.8575, time 117.96ms, mfu 3.11%
+iter 4210: loss 0.8797, time 117.65ms, mfu 3.12%
+iter 4220: loss 0.8655, time 117.77ms, mfu 3.12%
+iter 4230: loss 0.8824, time 117.88ms, mfu 3.13%
+iter 4240: loss 0.8739, time 117.19ms, mfu 3.13%
+step 4250: train loss 0.6850, val loss 1.6469
+iter 4250: loss 0.8779, time 11526.44ms, mfu 2.82%
+iter 4260: loss 0.8677, time 118.54ms, mfu 2.85%
+iter 4270: loss 0.8628, time 117.53ms, mfu 2.89%
+iter 4280: loss 0.8609, time 117.25ms, mfu 2.92%
+iter 4290: loss 0.8347, time 118.57ms, mfu 2.94%
+iter 4300: loss 0.8303, time 117.75ms, mfu 2.96%
+iter 4310: loss 0.8563, time 120.25ms, mfu 2.97%
+iter 4320: loss 0.8456, time 117.40ms, mfu 2.99%
+iter 4330: loss 0.8652, time 118.78ms, mfu 3.01%
+iter 4340: loss 0.8419, time 118.45ms, mfu 3.02%
+iter 4350: loss 0.8425, time 118.01ms, mfu 3.04%
+iter 4360: loss 0.8656, time 118.96ms, mfu 3.05%
+iter 4370: loss 0.8567, time 117.08ms, mfu 3.06%
+iter 4380: loss 0.8434, time 120.00ms, mfu 3.06%
+iter 4390: loss 0.8701, time 118.73ms, mfu 3.07%
+iter 4400: loss 0.8529, time 117.99ms, mfu 3.08%
+iter 4410: loss 0.8806, time 118.28ms, mfu 3.09%
+iter 4420: loss 0.8639, time 119.90ms, mfu 3.09%
+iter 4430: loss 0.8572, time 118.17ms, mfu 3.10%
+iter 4440: loss 0.8492, time 118.18ms, mfu 3.10%
+iter 4450: loss 0.8513, time 117.47ms, mfu 3.11%
+iter 4460: loss 0.8386, time 118.40ms, mfu 3.11%
+iter 4470: loss 0.8646, time 118.46ms, mfu 3.12%
+iter 4480: loss 0.8259, time 117.79ms, mfu 3.12%
+iter 4490: loss 0.8466, time 119.38ms, mfu 3.12%
+step 4500: train loss 0.6592, val loss 1.6741
+iter 4500: loss 0.8629, time 11526.01ms, mfu 2.81%
+iter 4510: loss 0.8540, time 117.86ms, mfu 2.85%
+iter 4520: loss 0.8399, time 118.14ms, mfu 2.88%
+iter 4530: loss 0.8561, time 117.75ms, mfu 2.91%
+iter 4540: loss 0.8476, time 116.89ms, mfu 2.93%
+iter 4550: loss 0.8757, time 116.64ms, mfu 2.96%
+iter 4560: loss 0.8503, time 118.11ms, mfu 2.98%
+iter 4570: loss 0.8437, time 117.50ms, mfu 3.00%
+iter 4580: loss 0.8623, time 117.97ms, mfu 3.01%
+iter 4590: loss 0.8611, time 119.04ms, mfu 3.03%
+iter 4600: loss 0.8291, time 117.96ms, mfu 3.04%
+iter 4610: loss 0.8740, time 118.04ms, mfu 3.05%
+iter 4620: loss 0.8400, time 118.80ms, mfu 3.06%
+iter 4630: loss 0.8288, time 119.49ms, mfu 3.07%
+iter 4640: loss 0.8543, time 116.69ms, mfu 3.08%
+iter 4650: loss 0.8669, time 119.02ms, mfu 3.08%
+iter 4660: loss 0.8544, time 117.81ms, mfu 3.09%
+iter 4670: loss 0.8409, time 118.14ms, mfu 3.10%
+iter 4680: loss 0.8580, time 118.05ms, mfu 3.10%
+iter 4690: loss 0.8480, time 118.86ms, mfu 3.11%
+iter 4700: loss 0.8288, time 117.36ms, mfu 3.11%
+iter 4710: loss 0.7978, time 118.32ms, mfu 3.12%
+iter 4720: loss 0.8392, time 118.61ms, mfu 3.12%
+iter 4730: loss 0.8312, time 118.36ms, mfu 3.12%
+iter 4740: loss 0.8320, time 118.02ms, mfu 3.13%
+step 4750: train loss 0.6424, val loss 1.6845
+iter 4750: loss 0.8103, time 11507.77ms, mfu 2.82%
+iter 4760: loss 0.8332, time 117.61ms, mfu 2.85%
+iter 4770: loss 0.8060, time 119.41ms, mfu 2.88%
+iter 4780: loss 0.8134, time 117.86ms, mfu 2.91%
+iter 4790: loss 0.8407, time 116.97ms, mfu 2.93%
+iter 4800: loss 0.8304, time 117.10ms, mfu 2.96%
+iter 4810: loss 0.8392, time 117.23ms, mfu 2.98%
+iter 4820: loss 0.8273, time 118.73ms, mfu 3.00%
+iter 4830: loss 0.8263, time 118.13ms, mfu 3.01%
+iter 4840: loss 0.8333, time 118.47ms, mfu 3.03%
+iter 4850: loss 0.8270, time 119.48ms, mfu 3.04%
+iter 4860: loss 0.8271, time 117.50ms, mfu 3.05%
+iter 4870: loss 0.8065, time 118.40ms, mfu 3.06%
+iter 4880: loss 0.8402, time 117.41ms, mfu 3.07%
+iter 4890: loss 0.8176, time 118.83ms, mfu 3.08%
+iter 4900: loss 0.8064, time 118.74ms, mfu 3.08%
+iter 4910: loss 0.8388, time 117.25ms, mfu 3.09%
+iter 4920: loss 0.8212, time 117.99ms, mfu 3.10%
+iter 4930: loss 0.8083, time 117.01ms, mfu 3.11%
+iter 4940: loss 0.8115, time 117.06ms, mfu 3.12%
+iter 4950: loss 0.8434, time 116.53ms, mfu 3.12%
+iter 4960: loss 0.8399, time 117.46ms, mfu 3.13%
+iter 4970: loss 0.8043, time 117.08ms, mfu 3.13%
+iter 4980: loss 0.7971, time 117.69ms, mfu 3.14%
+iter 4990: loss 0.8353, time 116.73ms, mfu 3.14%
+step 5000: train loss 0.6277, val loss 1.7027
+iter 5000: loss 0.8253, time 11508.13ms, mfu 2.83%
\ No newline at end of file
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/requirements.txt b/wandb/run-20230518_192958-edbxtn7u/files/requirements.txt
new file mode 100644
index 0000000..46c7602
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/requirements.txt
@@ -0,0 +1,103 @@
+appdirs==1.4.4
+asttokens==2.2.1
+backcall==0.2.0
+backports.functools-lru-cache==1.6.4
+boto3==1.26.133
+boto==2.49.0
+botocore==1.29.133
+certifi==2023.5.7
+charset-normalizer==3.1.0
+click==8.1.3
+cmake==3.26.3
+contourpy==1.0.7
+cycler==0.11.0
+debugpy==1.6.7
+decorator==5.1.1
+dnspython==2.3.0
+docker-pycreds==0.4.0
+executing==1.2.0
+filelock==3.12.0
+fonttools==4.39.4
+gitdb==4.0.10
+gitpython==3.1.31
+greenlet==2.0.2
+idna==3.4
+importlib-metadata==6.6.0
+importlib-resources==5.12.0
+influxdb-client==1.36.1
+ipykernel==6.14.0
+ipython==8.4.0
+jedi==0.18.2
+jinja2==3.1.2
+jmespath==1.0.1
+jupyter-client==8.2.0
+jupyter-core==5.3.0
+kiwisolver==1.4.4
+lit==16.0.3
+markupsafe==2.1.2
+matplotlib-inline==0.1.6
+matplotlib==3.7.1
+mpmath==1.3.0
+nest-asyncio==1.5.6
+networkx==3.1
+numpy==1.24.3
+nvidia-cublas-cu11==11.10.3.66
+nvidia-cuda-cupti-cu11==11.7.101
+nvidia-cuda-nvrtc-cu11==11.7.99
+nvidia-cuda-runtime-cu11==11.7.99
+nvidia-cudnn-cu11==8.5.0.96
+nvidia-cufft-cu11==10.9.0.58
+nvidia-curand-cu11==10.2.10.91
+nvidia-cusolver-cu11==11.4.0.1
+nvidia-cusparse-cu11==11.7.4.91
+nvidia-nccl-cu11==2.14.3
+nvidia-nvtx-cu11==11.7.91
+packaging==23.1
+pandas==2.0.1
+parso==0.8.3
+pathtools==0.1.2
+pexpect==4.8.0
+pickleshare==0.7.5
+pillow==9.5.0
+pip==23.1.2
+platformdirs==3.5.1
+prompt-toolkit==3.0.38
+protobuf==4.23.0
+psutil==5.9.5
+psycopg2-binary==2.9.6
+ptyprocess==0.7.0
+pure-eval==0.2.2
+pygments==2.15.1
+pymongo==4.3.3
+pyparsing==3.0.9
+python-dateutil==2.8.2
+pytz==2023.3
+pyyaml==6.0
+pyzmq==25.0.2
+reactivex==4.0.4
+regex==2023.5.5
+requests==2.30.0
+s3transfer==0.6.1
+sentry-sdk==1.22.2
+setproctitle==1.3.2
+setuptools==67.7.2
+six==1.16.0
+smmap==5.0.0
+sqlalchemy==2.0.13
+stack-data==0.6.2
+sympy==1.12
+tiktoken==0.4.0
+torch==2.0.1
+torchaudio==2.0.2
+torchvision==0.15.2
+tornado==6.3
+tqdm==4.65.0
+traitlets==5.9.0
+triton==2.0.0
+typing-extensions==4.5.0
+tzdata==2023.3
+urllib3==1.26.15
+wandb==0.15.2
+wcwidth==0.2.6
+wheel==0.40.0
+zipp==3.15.0
\ No newline at end of file
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/wandb-metadata.json b/wandb/run-20230518_192958-edbxtn7u/files/wandb-metadata.json
new file mode 100644
index 0000000..21477f9
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/wandb-metadata.json
@@ -0,0 +1,128 @@
+{
+    "os": "Linux-5.4.0-1066-aws-x86_64-with-glibc2.27",
+    "python": "3.9.16",
+    "heartbeatAt": "2023-05-18T19:29:59.247878",
+    "startedAt": "2023-05-18T19:29:58.912843",
+    "docker": null,
+    "cuda": "11.0.228",
+    "args": [
+        "config/train_shakespeare_char.py",
+        "--dtype=float16"
+    ],
+    "state": "running",
+    "program": "/home/ubuntu/abhi_workspace/NDnanoGPT/train.py",
+    "codePath": "train.py",
+    "git": {
+        "remote": "https://github.com/abhik-nd/NDnanoGPT.git",
+        "commit": "7fe4a099ad2a4654f96a51c0736ecf347149c34c"
+    },
+    "email": "michael.laielli@netradyne.com",
+    "root": "/home/ubuntu/abhi_workspace/NDnanoGPT",
+    "host": "ip-10-200-10-3",
+    "username": "ubuntu",
+    "executable": "/home/ubuntu/anaconda3/envs/gpt/bin/python3",
+    "cpu_count": 8,
+    "cpu_count_logical": 16,
+    "cpu_freq": {
+        "current": 3108.2267500000007,
+        "min": 0.0,
+        "max": 0.0
+    },
+    "cpu_freq_per_core": [
+        {
+            "current": 3104.164,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3087.251,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3104.087,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3110.488,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3100.731,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3111.546,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3105.145,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3102.908,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3136.849,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3100.06,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3109.185,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3099.345,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3114.622,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3105.298,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3101.951,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3137.998,
+            "min": 0.0,
+            "max": 0.0
+        }
+    ],
+    "disk": {
+        "total": 125.96025466918945,
+        "used": 107.00549697875977
+    },
+    "gpu": "Tesla T4",
+    "gpu_count": 1,
+    "gpu_devices": [
+        {
+            "name": "Tesla T4",
+            "memory_total": 16106127360
+        }
+    ],
+    "memory": {
+        "total": 62.03021240234375
+    }
+}
diff --git a/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json b/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
new file mode 100644
index 0000000..5e13f96
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
@@ -0,0 +1 @@
+{"iter": 5000, "train/loss": 0.6276986598968506, "val/loss": 1.7026879787445068, "lr": 0.0001, "mfu": 3.1425015880217346, "_timestamp": 1684439053.6303701, "_runtime": 854.711837053299, "_step": 20, "_wandb": {"runtime": 854}}
\ No newline at end of file
diff --git a/wandb/run-20230518_192958-edbxtn7u/logs/debug-internal.log b/wandb/run-20230518_192958-edbxtn7u/logs/debug-internal.log
new file mode 100644
index 0000000..1314390
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/logs/debug-internal.log
@@ -0,0 +1,899 @@
+2023-05-18 19:29:58,918 INFO    StreamThr :6140 [internal.py:wandb_internal():86] W&B internal server running at pid: 6140, started at: 2023-05-18 19:29:58.918209
+2023-05-18 19:29:58,919 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status
+2023-05-18 19:29:58,921 INFO    WriterThread:6140 [datastore.py:open_for_write():85] open: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/run-edbxtn7u.wandb
+2023-05-18 19:29:58,923 DEBUG   SenderThread:6140 [sender.py:send():375] send: header
+2023-05-18 19:29:58,946 DEBUG   SenderThread:6140 [sender.py:send():375] send: run
+2023-05-18 19:29:59,067 INFO    SenderThread:6140 [dir_watcher.py:__init__():219] watching files in: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files
+2023-05-18 19:29:59,067 INFO    SenderThread:6140 [sender.py:_start_run_threads():1124] run started: edbxtn7u with start time 1684438198.918533
+2023-05-18 19:29:59,067 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:29:59,067 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:29:59,069 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: check_version
+2023-05-18 19:29:59,069 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: check_version
+2023-05-18 19:29:59,154 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: run_start
+2023-05-18 19:29:59,222 DEBUG   HandlerThread:6140 [system_info.py:__init__():31] System info init
+2023-05-18 19:29:59,222 DEBUG   HandlerThread:6140 [system_info.py:__init__():46] System info init done
+2023-05-18 19:29:59,222 INFO    HandlerThread:6140 [system_monitor.py:start():181] Starting system monitor
+2023-05-18 19:29:59,222 INFO    SystemMonitor:6140 [system_monitor.py:_start():145] Starting system asset monitoring threads
+2023-05-18 19:29:59,222 INFO    HandlerThread:6140 [system_monitor.py:probe():201] Collecting system info
+2023-05-18 19:29:59,223 INFO    SystemMonitor:6140 [interfaces.py:start():190] Started cpu monitoring
+2023-05-18 19:29:59,223 INFO    SystemMonitor:6140 [interfaces.py:start():190] Started disk monitoring
+2023-05-18 19:29:59,224 INFO    SystemMonitor:6140 [interfaces.py:start():190] Started gpu monitoring
+2023-05-18 19:29:59,224 INFO    SystemMonitor:6140 [interfaces.py:start():190] Started memory monitoring
+2023-05-18 19:29:59,225 INFO    SystemMonitor:6140 [interfaces.py:start():190] Started network monitoring
+2023-05-18 19:29:59,247 DEBUG   HandlerThread:6140 [system_info.py:probe():195] Probing system
+2023-05-18 19:29:59,251 DEBUG   HandlerThread:6140 [system_info.py:_probe_git():180] Probing git
+2023-05-18 19:29:59,262 DEBUG   HandlerThread:6140 [system_info.py:_probe_git():188] Probing git done
+2023-05-18 19:29:59,262 DEBUG   HandlerThread:6140 [system_info.py:probe():240] Probing system done
+2023-05-18 19:29:59,262 DEBUG   HandlerThread:6140 [system_monitor.py:probe():210] {'os': 'Linux-5.4.0-1066-aws-x86_64-with-glibc2.27', 'python': '3.9.16', 'heartbeatAt': '2023-05-18T19:29:59.247878', 'startedAt': '2023-05-18T19:29:58.912843', 'docker': None, 'cuda': '11.0.228', 'args': ('config/train_shakespeare_char.py', '--dtype=float16'), 'state': 'running', 'program': '/home/ubuntu/abhi_workspace/NDnanoGPT/train.py', 'codePath': 'train.py', 'git': {'remote': 'https://github.com/abhik-nd/NDnanoGPT.git', 'commit': '7fe4a099ad2a4654f96a51c0736ecf347149c34c'}, 'email': 'michael.laielli@netradyne.com', 'root': '/home/ubuntu/abhi_workspace/NDnanoGPT', 'host': 'ip-10-200-10-3', 'username': 'ubuntu', 'executable': '/home/ubuntu/anaconda3/envs/gpt/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 16, 'cpu_freq': {'current': 3108.2267500000007, 'min': 0.0, 'max': 0.0}, 'cpu_freq_per_core': [{'current': 3104.164, 'min': 0.0, 'max': 0.0}, {'current': 3087.251, 'min': 0.0, 'max': 0.0}, {'current': 3104.087, 'min': 0.0, 'max': 0.0}, {'current': 3110.488, 'min': 0.0, 'max': 0.0}, {'current': 3100.731, 'min': 0.0, 'max': 0.0}, {'current': 3111.546, 'min': 0.0, 'max': 0.0}, {'current': 3105.145, 'min': 0.0, 'max': 0.0}, {'current': 3102.908, 'min': 0.0, 'max': 0.0}, {'current': 3136.849, 'min': 0.0, 'max': 0.0}, {'current': 3100.06, 'min': 0.0, 'max': 0.0}, {'current': 3109.185, 'min': 0.0, 'max': 0.0}, {'current': 3099.345, 'min': 0.0, 'max': 0.0}, {'current': 3114.622, 'min': 0.0, 'max': 0.0}, {'current': 3105.298, 'min': 0.0, 'max': 0.0}, {'current': 3101.951, 'min': 0.0, 'max': 0.0}, {'current': 3137.998, 'min': 0.0, 'max': 0.0}], 'disk': {'total': 125.96025466918945, 'used': 107.00549697875977}, 'gpu': 'Tesla T4', 'gpu_count': 1, 'gpu_devices': [{'name': 'Tesla T4', 'memory_total': 16106127360}], 'memory': {'total': 62.03021240234375}}
+2023-05-18 19:29:59,262 INFO    HandlerThread:6140 [system_monitor.py:probe():211] Finished collecting system info
+2023-05-18 19:29:59,262 INFO    HandlerThread:6140 [system_monitor.py:probe():214] Publishing system info
+2023-05-18 19:29:59,262 DEBUG   HandlerThread:6140 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
+2023-05-18 19:29:59,262 DEBUG   HandlerThread:6140 [system_info.py:_save_pip():67] Saving pip packages done
+2023-05-18 19:29:59,262 DEBUG   HandlerThread:6140 [system_info.py:_save_conda():74] Saving list of conda packages installed into the current environment
+2023-05-18 19:30:00,069 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/requirements.txt
+2023-05-18 19:30:00,069 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:30:00,069 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/conda-environment.yaml
+2023-05-18 19:30:03,418 DEBUG   HandlerThread:6140 [system_info.py:_save_conda():86] Saving conda packages done
+2023-05-18 19:30:03,418 DEBUG   HandlerThread:6140 [system_info.py:_save_code():89] Saving code
+2023-05-18 19:30:03,423 DEBUG   HandlerThread:6140 [system_info.py:_save_code():110] Saving code done
+2023-05-18 19:30:03,423 DEBUG   HandlerThread:6140 [system_info.py:_save_patches():127] Saving git patches
+2023-05-18 19:30:03,458 DEBUG   HandlerThread:6140 [system_info.py:_save_patches():169] Saving git patches done
+2023-05-18 19:30:03,459 INFO    HandlerThread:6140 [system_monitor.py:probe():216] Finished publishing system info
+2023-05-18 19:30:03,464 DEBUG   SenderThread:6140 [sender.py:send():375] send: files
+2023-05-18 19:30:03,464 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-metadata.json with policy now
+2023-05-18 19:30:03,465 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file code/train.py with policy now
+2023-05-18 19:30:03,465 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file diff.patch with policy now
+2023-05-18 19:30:03,471 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:30:03,472 DEBUG   SenderThread:6140 [sender.py:send():375] send: telemetry
+2023-05-18 19:30:03,472 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:30:03,620 INFO    wandb-upload_0:6140 [upload_job.py:push():137] Uploaded file /tmp/tmp5ca6dc69wandb/38ibhnlz-wandb-metadata.json
+2023-05-18 19:30:03,633 INFO    wandb-upload_2:6140 [upload_job.py:push():137] Uploaded file /tmp/tmp5ca6dc69wandb/d2ef1dnw-diff.patch
+2023-05-18 19:30:03,635 INFO    wandb-upload_1:6140 [upload_job.py:push():137] Uploaded file /tmp/tmp5ca6dc69wandb/1xnvkaq1-code/train.py
+2023-05-18 19:30:04,070 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/conda-environment.yaml
+2023-05-18 19:30:04,071 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/code/train.py
+2023-05-18 19:30:04,071 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/diff.patch
+2023-05-18 19:30:04,071 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-metadata.json
+2023-05-18 19:30:04,071 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/code
+2023-05-18 19:30:04,525 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:09,526 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:14,527 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:18,475 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:30:18,475 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:30:20,495 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:25,139 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:30:25,141 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:30:25,141 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:30:25,142 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:30:26,076 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:30:26,077 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:26,143 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:28,077 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:29,077 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:31,078 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:31,891 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:32,078 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/config.yaml
+2023-05-18 19:30:33,079 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:33,502 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:30:33,502 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:30:36,080 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:37,900 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:38,080 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:40,081 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:42,082 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:43,403 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:44,082 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:46,083 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:48,084 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:48,478 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:30:48,479 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:30:48,499 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:50,084 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:52,085 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:54,086 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:54,462 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:30:56,086 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:58,087 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:30:59,226 DEBUG   SystemMonitor:6140 [system_monitor.py:_start():159] Starting system metrics aggregation loop
+2023-05-18 19:30:59,227 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:31:00,088 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:00,148 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:02,088 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:03,483 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:31:03,483 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:31:05,503 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:10,503 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:14,834 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:31:14,835 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:31:14,836 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:31:14,836 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:31:15,092 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:31:16,092 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:16,255 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:18,093 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:18,479 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:31:18,480 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:31:20,094 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:21,876 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:22,094 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:24,095 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:26,096 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:27,493 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:28,096 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:29,227 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:31:30,097 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:32,098 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:33,144 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:33,479 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:31:33,480 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:31:34,098 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:36,099 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:38,099 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:38,813 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:40,100 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:42,101 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:44,101 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:44,373 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:48,480 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:31:48,480 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:31:49,508 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:54,409 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:31:54,410 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:31:54,411 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:31:54,411 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:31:54,846 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:31:55,104 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:31:56,105 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:58,105 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:31:59,228 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:32:00,106 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:00,441 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:02,107 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:03,480 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:32:03,480 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:32:04,107 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:06,108 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:06,187 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:08,109 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:10,109 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:11,951 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:12,110 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:14,111 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:16,111 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:17,739 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:18,112 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:18,480 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:32:18,480 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:32:20,113 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:22,113 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:23,538 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:24,114 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:28,538 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:29,229 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:32:33,484 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:32:33,485 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:32:34,515 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:34,918 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:32:34,919 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:32:34,919 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:32:34,921 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:32:35,117 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:32:38,118 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:39,835 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:40,119 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:42,119 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:44,120 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:45,691 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:46,121 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:48,121 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:48,484 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:32:48,485 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:32:50,122 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:51,554 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:52,123 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:54,123 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:56,124 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:57,427 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:32:58,124 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:32:59,229 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:33:00,125 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:02,126 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:03,295 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:03,485 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:33:03,485 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:33:04,126 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:06,127 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:08,515 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:13,516 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:16,030 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:33:16,031 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:33:16,031 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:33:16,032 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:33:16,130 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:33:18,131 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:18,485 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:33:18,485 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:33:18,821 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:20,131 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:22,132 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:24,133 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:24,561 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:26,133 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:28,134 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:29,230 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:33:30,135 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:30,502 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:32,135 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:33,485 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:33:33,485 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:33:34,136 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:36,137 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:36,464 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:38,137 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:40,138 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:42,139 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:42,425 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:44,139 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:46,140 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:33:47,998 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:48,505 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:33:48,505 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:33:53,534 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:57,566 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:33:57,567 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:33:57,567 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:33:57,568 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:33:58,143 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:33:58,996 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:33:59,230 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:34:00,144 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:02,145 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:03,505 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:34:03,505 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:34:04,014 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:04,145 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:06,146 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:08,147 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:09,762 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:10,147 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:12,148 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:14,149 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:15,738 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:16,149 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:18,150 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:18,505 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:34:18,513 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:34:20,151 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:20,755 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:22,151 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:24,152 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:26,152 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:26,561 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:28,153 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:29,231 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:34:32,232 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:33,505 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:34:33,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:34:37,536 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:39,434 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:34:39,435 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:34:39,435 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:34:39,435 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:34:40,156 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:40,157 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:34:42,157 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:43,205 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:44,158 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:46,158 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:48,159 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:48,505 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:34:48,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:34:48,526 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:50,159 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:52,160 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:53,919 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:34:54,161 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:56,161 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:58,162 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:34:59,231 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:34:59,232 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:00,163 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:02,163 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:03,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:35:03,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:35:04,164 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:04,642 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:06,165 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:08,165 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:10,166 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:10,339 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:15,339 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:18,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:35:18,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:35:20,535 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:20,818 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:35:20,819 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:35:20,819 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:35:20,821 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:35:21,169 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:35:22,169 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:24,169 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:25,800 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:26,170 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:28,171 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:29,232 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:35:30,171 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:31,715 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:32,172 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:33,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:35:33,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:35:34,172 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:36,173 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:37,637 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:38,173 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:40,174 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:42,175 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:43,554 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:44,175 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:46,176 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:48,177 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:48,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:35:48,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:35:49,535 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:50,177 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:52,178 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:35:54,650 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:35:59,233 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:36:00,233 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:02,127 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:36:02,128 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:36:02,128 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:36:02,128 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:36:02,180 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:36:03,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:36:03,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:36:04,181 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:05,662 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:06,181 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:08,182 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:10,183 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:11,534 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:12,183 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:14,184 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:16,185 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:17,451 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:18,185 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:18,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:36:18,506 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:36:20,186 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:22,186 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:23,366 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:24,187 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:26,188 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:28,188 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:29,233 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:36:29,234 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:30,189 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:32,190 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:33,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:36:33,507 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:36:34,536 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:39,536 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:43,158 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:36:43,158 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:36:43,159 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:36:43,159 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:36:43,193 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:36:44,193 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:45,421 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:46,193 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:48,194 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:48,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:36:48,507 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:36:50,195 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:51,336 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:52,195 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:54,196 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:56,196 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:57,256 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:36:58,197 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:36:59,234 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:37:00,198 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:02,198 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:03,179 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:03,506 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:37:03,507 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:37:04,199 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:06,200 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:08,200 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:09,087 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:10,201 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:12,202 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:14,632 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:18,514 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:37:18,515 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:37:20,544 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:24,107 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:37:24,108 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:37:24,108 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:37:24,109 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:37:24,205 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:37:26,205 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:26,415 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:28,206 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:29,234 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:37:30,207 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:32,207 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:32,332 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:33,515 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:37:33,515 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:37:34,208 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:36,209 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:38,209 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:38,242 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:40,210 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:42,211 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:44,152 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:44,211 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:46,212 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:48,212 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:48,515 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:37:48,515 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:37:50,066 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:50,213 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:52,214 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:54,214 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:37:55,621 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:37:59,235 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:38:01,236 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:03,520 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:38:03,521 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:38:05,130 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:38:05,130 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:38:05,131 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:38:05,131 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:38:05,217 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:38:06,218 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:06,395 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:08,218 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:10,219 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:12,124 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:12,220 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:14,220 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:16,221 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:18,034 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:18,222 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:18,520 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:38:18,521 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:38:20,222 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:22,223 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:23,951 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:24,224 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:26,224 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:28,225 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:29,235 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:38:29,237 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:30,226 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:32,226 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:33,520 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:38:33,521 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:38:34,227 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:34,634 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:39,635 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:44,635 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:46,050 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:38:46,051 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:38:46,051 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:38:46,051 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:38:46,230 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:38:48,231 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:48,521 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:38:48,521 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:38:49,722 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:50,231 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:52,232 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:54,232 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:55,453 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:38:56,233 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:58,234 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:38:59,236 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:39:00,234 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:01,369 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:02,235 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:03,521 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:39:03,521 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:39:04,236 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:06,236 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:07,285 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:08,237 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:10,238 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:12,238 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:13,200 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:14,239 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:16,239 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:18,536 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:39:18,536 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:39:18,556 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:23,566 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:27,037 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:39:27,038 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:39:27,038 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:39:27,038 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:39:27,242 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:39:28,243 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:29,237 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:39:29,238 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:30,243 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:32,244 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:33,536 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:39:33,536 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:39:34,244 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:34,252 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:36,245 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:38,246 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:39,985 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:40,246 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:42,247 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:44,247 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:45,892 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:46,248 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:48,249 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:48,536 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:39:48,536 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:39:50,249 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:51,819 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:52,250 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:54,251 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:56,251 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:39:57,543 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:39:59,237 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:40:03,238 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:03,538 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:40:03,538 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:40:08,058 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:40:08,058 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:40:08,059 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:40:08,059 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:40:08,255 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:40:09,144 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:10,255 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:12,256 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:14,257 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:15,055 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:16,257 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:18,258 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:18,538 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:40:18,538 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:40:20,259 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:20,963 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:22,259 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:24,260 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:26,261 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:26,881 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:28,261 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:29,238 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:40:30,262 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:32,262 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:32,783 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:33,538 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:40:33,538 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:40:34,263 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:36,264 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:38,264 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:38,517 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:43,518 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:48,518 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:48,540 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:40:48,540 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:40:48,997 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:40:48,998 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:40:48,998 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:40:48,998 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:40:49,267 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:40:50,268 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:52,268 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:53,668 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:40:54,269 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:56,269 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:58,270 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:40:59,238 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:40:59,240 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:00,271 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:02,271 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:03,540 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:41:03,540 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:41:04,272 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:04,495 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:06,273 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:08,273 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:10,226 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:10,274 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:12,275 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:14,275 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:16,135 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:16,276 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:18,277 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:18,540 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:41:18,540 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:41:21,588 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:26,589 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:29,239 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:41:29,976 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:41:29,977 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:41:29,977 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:41:29,978 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:41:30,280 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:41:32,280 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:32,285 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:33,540 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:41:33,540 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:41:34,281 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:36,282 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:38,197 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:38,282 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:40,283 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:42,284 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:44,108 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:44,284 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:46,285 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:48,286 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:48,540 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:41:48,540 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:41:50,014 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:50,286 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:52,287 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:54,288 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:55,928 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:41:56,288 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:58,289 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:41:59,239 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:42:00,289 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:01,240 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:03,547 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:42:03,548 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:42:06,605 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:10,978 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:42:10,979 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:42:10,979 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:42:10,979 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:42:11,293 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:42:12,061 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:12,293 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:14,294 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:16,294 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:17,959 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:18,295 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:18,547 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:42:18,548 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:42:20,295 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:22,296 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:23,876 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:24,297 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:26,297 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:28,298 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:29,240 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:42:29,241 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:30,299 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:32,299 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:33,547 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:42:33,548 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:42:34,300 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:34,605 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:36,301 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:38,301 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:40,302 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:40,410 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:45,410 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:48,562 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:42:48,563 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:42:50,620 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:51,875 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:42:51,876 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:42:51,876 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:42:51,876 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:42:52,305 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:52,306 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:42:54,306 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:56,307 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:56,540 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:42:58,307 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:42:59,240 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:43:00,308 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:02,309 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:02,435 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:03,562 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:43:03,563 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:43:04,309 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:06,310 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:08,311 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:08,330 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:10,311 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:12,312 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:14,235 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:14,312 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:16,313 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:18,314 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:18,562 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:43:18,563 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:43:20,129 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:20,314 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:22,315 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:25,310 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:29,241 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:43:31,242 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:32,756 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:43:32,756 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:43:32,756 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:43:32,757 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:43:33,318 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:43:33,563 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:43:33,563 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:43:34,318 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:36,245 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:36,319 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:38,320 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:40,320 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:42,144 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:42,321 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:44,322 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:46,322 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:48,041 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:48,323 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:48,563 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:43:48,563 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:43:50,324 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:52,324 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:53,935 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:43:54,325 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:56,326 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:58,326 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:43:59,242 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:43:59,243 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:44:00,327 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:44:02,328 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:44:03,576 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-18 19:44:03,577 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: stop_status
+2023-05-18 19:44:04,635 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:44:09,636 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:44:13,674 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-18 19:44:13,675 DEBUG   SenderThread:6140 [sender.py:send():375] send: history
+2023-05-18 19:44:13,675 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: summary_record
+2023-05-18 19:44:13,675 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:44:13,788 DEBUG   SenderThread:6140 [sender.py:send():375] send: exit
+2023-05-18 19:44:13,789 INFO    SenderThread:6140 [sender.py:send_exit():598] handling exit code: 0
+2023-05-18 19:44:13,789 INFO    SenderThread:6140 [sender.py:send_exit():600] handling runtime: 854
+2023-05-18 19:44:13,789 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:44:13,789 INFO    SenderThread:6140 [sender.py:send_exit():606] send defer
+2023-05-18 19:44:13,789 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,789 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 0
+2023-05-18 19:44:13,790 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,790 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 0
+2023-05-18 19:44:13,790 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 1
+2023-05-18 19:44:13,790 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,790 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 1
+2023-05-18 19:44:13,790 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,790 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 1
+2023-05-18 19:44:13,790 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 2
+2023-05-18 19:44:13,790 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,790 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 2
+2023-05-18 19:44:13,790 INFO    HandlerThread:6140 [system_monitor.py:finish():190] Stopping system monitor
+2023-05-18 19:44:13,790 DEBUG   SystemMonitor:6140 [system_monitor.py:_start():166] Finished system metrics aggregation loop
+2023-05-18 19:44:13,791 DEBUG   SystemMonitor:6140 [system_monitor.py:_start():170] Publishing last batch of metrics
+2023-05-18 19:44:13,791 INFO    HandlerThread:6140 [interfaces.py:finish():202] Joined cpu monitor
+2023-05-18 19:44:13,791 INFO    HandlerThread:6140 [interfaces.py:finish():202] Joined disk monitor
+2023-05-18 19:44:13,817 INFO    HandlerThread:6140 [interfaces.py:finish():202] Joined gpu monitor
+2023-05-18 19:44:13,818 INFO    HandlerThread:6140 [interfaces.py:finish():202] Joined memory monitor
+2023-05-18 19:44:13,818 INFO    HandlerThread:6140 [interfaces.py:finish():202] Joined network monitor
+2023-05-18 19:44:13,818 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,818 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 2
+2023-05-18 19:44:13,818 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 3
+2023-05-18 19:44:13,818 DEBUG   SenderThread:6140 [sender.py:send():375] send: stats
+2023-05-18 19:44:13,818 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,819 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 3
+2023-05-18 19:44:13,819 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,819 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 3
+2023-05-18 19:44:13,819 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 4
+2023-05-18 19:44:13,819 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,819 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 4
+2023-05-18 19:44:13,819 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,819 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 4
+2023-05-18 19:44:13,819 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 5
+2023-05-18 19:44:13,819 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,819 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 5
+2023-05-18 19:44:13,820 DEBUG   SenderThread:6140 [sender.py:send():375] send: summary
+2023-05-18 19:44:13,820 INFO    SenderThread:6140 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-18 19:44:13,820 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,820 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 5
+2023-05-18 19:44:13,820 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 6
+2023-05-18 19:44:13,820 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,820 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 6
+2023-05-18 19:44:13,820 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,820 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 6
+2023-05-18 19:44:13,820 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 7
+2023-05-18 19:44:13,820 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: status_report
+2023-05-18 19:44:13,821 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:13,821 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 7
+2023-05-18 19:44:13,821 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:13,821 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 7
+2023-05-18 19:44:14,331 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:44:14,331 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:44:14,789 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-18 19:44:15,188 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 8
+2023-05-18 19:44:15,188 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: poll_exit
+2023-05-18 19:44:15,188 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:15,189 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 8
+2023-05-18 19:44:15,189 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:15,189 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 8
+2023-05-18 19:44:15,196 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 9
+2023-05-18 19:44:15,196 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:15,196 DEBUG   SenderThread:6140 [sender.py:send():375] send: artifact
+2023-05-18 19:44:15,196 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 9
+2023-05-18 19:44:15,332 INFO    Thread-12 :6140 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:44:15,565 INFO    wandb-upload_1:6140 [upload_job.py:push():95] Uploaded file /home/ubuntu/.local/share/wandb/artifacts/staging/tmpgpjfkc55
+2023-05-18 19:44:15,565 INFO    wandb-upload_0:6140 [upload_job.py:push():95] Uploaded file /home/ubuntu/.local/share/wandb/artifacts/staging/tmp781gou7f
+2023-05-18 19:44:15,565 INFO    wandb-upload_2:6140 [upload_job.py:push():95] Uploaded file /home/ubuntu/.local/share/wandb/artifacts/staging/tmp4llpmmua
+2023-05-18 19:44:15,789 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-18 19:44:15,906 INFO    SenderThread:6140 [sender.py:send_artifact():1474] sent artifact job-https___github.com_abhik-nd_NDnanoGPT.git_train.py - {'id': 'QXJ0aWZhY3Q6MTE1ODU=', 'digest': 'd2fa25145231a5a1b1478c2c041c2e1a', 'state': 'PENDING', 'aliases': [], 'artifactSequence': {'id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjY4OTk=', 'latestArtifact': None}, 'version': 'latest'}
+2023-05-18 19:44:15,906 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:15,906 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 9
+2023-05-18 19:44:15,906 INFO    SenderThread:6140 [dir_watcher.py:finish():365] shutting down directory watcher
+2023-05-18 19:44:16,332 INFO    SenderThread:6140 [dir_watcher.py:finish():395] scan: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files
+2023-05-18 19:44:16,332 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-metadata.json wandb-metadata.json
+2023-05-18 19:44:16,332 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/config.yaml config.yaml
+2023-05-18 19:44:16,333 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json wandb-summary.json
+2023-05-18 19:44:16,333 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log output.log
+2023-05-18 19:44:16,333 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/requirements.txt requirements.txt
+2023-05-18 19:44:16,337 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/diff.patch diff.patch
+2023-05-18 19:44:16,340 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/conda-environment.yaml conda-environment.yaml
+2023-05-18 19:44:16,343 INFO    SenderThread:6140 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/code/train.py code/train.py
+2023-05-18 19:44:16,343 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 10
+2023-05-18 19:44:16,345 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: poll_exit
+2023-05-18 19:44:16,345 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:16,346 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 10
+2023-05-18 19:44:16,346 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:16,346 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 10
+2023-05-18 19:44:16,346 INFO    SenderThread:6140 [file_pusher.py:finish():167] shutting down file pusher
+2023-05-18 19:44:16,397 INFO    wandb-upload_1:6140 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/config.yaml
+2023-05-18 19:44:16,432 INFO    wandb-upload_0:6140 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/wandb-summary.json
+2023-05-18 19:44:16,465 INFO    wandb-upload_4:6140 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/conda-environment.yaml
+2023-05-18 19:44:16,492 INFO    wandb-upload_3:6140 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/requirements.txt
+2023-05-18 19:44:16,495 INFO    wandb-upload_2:6140 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/files/output.log
+2023-05-18 19:44:16,695 INFO    Thread-11 :6140 [sender.py:transition_state():626] send defer: 11
+2023-05-18 19:44:16,695 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:16,695 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 11
+2023-05-18 19:44:16,696 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:16,696 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 11
+2023-05-18 19:44:16,696 INFO    SenderThread:6140 [file_pusher.py:join():172] waiting for file pusher
+2023-05-18 19:44:16,696 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 12
+2023-05-18 19:44:16,696 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:16,696 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 12
+2023-05-18 19:44:16,696 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:16,696 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 12
+2023-05-18 19:44:16,784 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 13
+2023-05-18 19:44:16,784 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:16,784 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 13
+2023-05-18 19:44:16,784 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:16,784 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 13
+2023-05-18 19:44:16,784 INFO    SenderThread:6140 [sender.py:transition_state():626] send defer: 14
+2023-05-18 19:44:16,784 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: defer
+2023-05-18 19:44:16,784 INFO    HandlerThread:6140 [handler.py:handle_request_defer():170] handle defer: 14
+2023-05-18 19:44:16,785 DEBUG   SenderThread:6140 [sender.py:send():375] send: final
+2023-05-18 19:44:16,785 DEBUG   SenderThread:6140 [sender.py:send():375] send: footer
+2023-05-18 19:44:16,785 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: defer
+2023-05-18 19:44:16,785 INFO    SenderThread:6140 [sender.py:send_request_defer():622] handle sender defer: 14
+2023-05-18 19:44:16,785 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-18 19:44:16,786 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: poll_exit
+2023-05-18 19:44:16,786 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-18 19:44:16,786 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: poll_exit
+2023-05-18 19:44:16,786 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: server_info
+2023-05-18 19:44:16,787 DEBUG   SenderThread:6140 [sender.py:send_request():402] send_request: server_info
+2023-05-18 19:44:16,789 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: get_summary
+2023-05-18 19:44:16,789 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: sampled_history
+2023-05-18 19:44:16,801 INFO    MainThread:6140 [wandb_run.py:_footer_history_summary_info():3469] rendering history
+2023-05-18 19:44:16,801 INFO    MainThread:6140 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
+2023-05-18 19:44:16,802 INFO    MainThread:6140 [wandb_run.py:_footer_sync_info():3428] logging synced files
+2023-05-18 19:44:16,802 DEBUG   HandlerThread:6140 [handler.py:handle_request():144] handle_request: shutdown
+2023-05-18 19:44:16,802 INFO    HandlerThread:6140 [handler.py:finish():845] shutting down handler
+2023-05-18 19:44:17,787 INFO    WriterThread:6140 [datastore.py:close():298] close: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/run-edbxtn7u.wandb
+2023-05-18 19:44:17,801 INFO    SenderThread:6140 [sender.py:finish():1550] shutting down sender
+2023-05-18 19:44:17,801 INFO    SenderThread:6140 [file_pusher.py:finish():167] shutting down file pusher
+2023-05-18 19:44:17,801 INFO    SenderThread:6140 [file_pusher.py:join():172] waiting for file pusher
diff --git a/wandb/run-20230518_192958-edbxtn7u/logs/debug.log b/wandb/run-20230518_192958-edbxtn7u/logs/debug.log
new file mode 100644
index 0000000..6e15fc4
--- /dev/null
+++ b/wandb/run-20230518_192958-edbxtn7u/logs/debug.log
@@ -0,0 +1,28 @@
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_setup.py:_flush():76] Configure stats pid to 6092
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_setup.py:_flush():76] Loading settings from /home/ubuntu/.config/wandb/settings
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_setup.py:_flush():76] Loading settings from /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/settings
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program': '/home/ubuntu/abhi_workspace/NDnanoGPT/train.py'}
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_init.py:_log_setup():507] Logging user logs to /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/logs/debug.log
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_init.py:_log_setup():508] Logging internal logs to /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230518_192958-edbxtn7u/logs/debug-internal.log
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_init.py:init():547] calling init triggers
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
+config: {'out_dir': 'out-shakespeare-char', 'eval_interval': 250, 'log_interval': 10, 'eval_iters': 200, 'eval_only': False, 'always_save_checkpoint': False, 'init_from': 'scratch', 'wandb_log': True, 'wandb_project': 'shakespeare-char', 'wandb_run_name': 'mini-gpt', 'dataset': 'shakespeare_char', 'gradient_accumulation_steps': 1, 'batch_size': 64, 'block_size': 256, 'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'dropout': 0.2, 'bias': False, 'learning_rate': 0.001, 'max_iters': 5000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.99, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 100, 'lr_decay_iters': 5000, 'min_lr': 0.0001, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'float16', 'compile': True}
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_init.py:init():596] starting backend
+2023-05-18 19:29:58,914 INFO    MainThread:6092 [wandb_init.py:init():600] setting up manager
+2023-05-18 19:29:58,916 INFO    MainThread:6092 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
+2023-05-18 19:29:58,918 INFO    MainThread:6092 [wandb_init.py:init():606] backend started and connected
+2023-05-18 19:29:58,920 INFO    MainThread:6092 [wandb_init.py:init():700] updated telemetry
+2023-05-18 19:29:58,945 INFO    MainThread:6092 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
+2023-05-18 19:29:59,069 INFO    MainThread:6092 [wandb_run.py:_on_init():2177] communicating current version
+2023-05-18 19:29:59,108 INFO    MainThread:6092 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
+
+2023-05-18 19:29:59,108 INFO    MainThread:6092 [wandb_init.py:init():787] starting run threads in backend
+2023-05-18 19:30:03,469 INFO    MainThread:6092 [wandb_run.py:_console_start():2158] atexit reg
+2023-05-18 19:30:03,469 INFO    MainThread:6092 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
+2023-05-18 19:30:03,469 INFO    MainThread:6092 [wandb_run.py:_redirect():2078] Wrapping output streams.
+2023-05-18 19:30:03,469 INFO    MainThread:6092 [wandb_run.py:_redirect():2103] Redirects installed.
+2023-05-18 19:30:03,470 INFO    MainThread:6092 [wandb_init.py:init():829] run started, returning control to user process
+2023-05-18 19:44:17,933 WARNING MsgRouterThr:6092 [router.py:message_loop():77] message_loop has been closed
diff --git a/wandb/run-20230518_192958-edbxtn7u/run-edbxtn7u.wandb b/wandb/run-20230518_192958-edbxtn7u/run-edbxtn7u.wandb
new file mode 100644
index 0000000..4a066f3
Binary files /dev/null and b/wandb/run-20230518_192958-edbxtn7u/run-edbxtn7u.wandb differ
diff --git a/wandb/run-20230522_204356-t6ramng5/files/code/train.py b/wandb/run-20230522_204356-t6ramng5/files/code/train.py
new file mode 100644
index 0000000..a0cd539
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/code/train.py
@@ -0,0 +1,331 @@
+"""
+This training script can be run both on a single gpu in debug mode,
+and also in a larger training run with distributed data parallel (ddp).
+
+To run on a single GPU, example:
+$ python train.py --batch_size=32 --compile=False
+
+To run with DDP on 4 gpus on 1 node, example:
+$ torchrun --standalone --nproc_per_node=4 train.py
+
+To run with DDP on 4 gpus across 2 nodes, example:
+- Run on the first (master) node with example IP 123.456.123.456:
+$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
+- Run on the worker node:
+$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py
+(If your cluster does not have Infiniband interconnect prepend NCCL_IB_DISABLE=1)
+"""
+
+import os
+import time
+import math
+import pickle
+from contextlib import nullcontext
+
+import numpy as np
+import torch
+from torch.nn.parallel import DistributedDataParallel as DDP
+from torch.distributed import init_process_group, destroy_process_group
+
+from model import GPTConfig, GPT
+
+# -----------------------------------------------------------------------------
+# default config values designed to train a gpt2 (124M) on OpenWebText
+# I/O
+out_dir = 'out'
+eval_interval = 2000
+log_interval = 1
+eval_iters = 200
+eval_only = False # if True, script exits right after the first eval
+always_save_checkpoint = True # if True, always save a checkpoint after each eval
+init_from = 'scratch' # 'scratch' or 'resume' or 'gpt2*'
+# wandb logging
+wandb_log = False # disabled by default
+wandb_project = 'owt'
+wandb_run_name = 'gpt2' # 'run' + str(time.time())
+# data
+dataset = 'openwebtext'
+gradient_accumulation_steps = 5 * 8 # used to simulate larger batch sizes
+batch_size = 12 # if gradient_accumulation_steps > 1, this is the micro-batch size
+block_size = 1024
+# model
+n_layer = 12
+n_head = 12
+n_embd = 768
+dropout = 0.0 # for pretraining 0 is good, for finetuning try 0.1+
+bias = False # do we use bias inside LayerNorm and Linear layers?
+# adamw optimizer
+learning_rate = 6e-4 # max learning rate
+max_iters = 600000 # total number of training iterations
+weight_decay = 1e-1
+beta1 = 0.9
+beta2 = 0.95
+grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0
+# learning rate decay settings
+decay_lr = True # whether to decay the learning rate
+warmup_iters = 2000 # how many steps to warm up for
+lr_decay_iters = 600000 # should be ~= max_iters per Chinchilla
+min_lr = 6e-5 # minimum learning rate, should be ~= learning_rate/10 per Chinchilla
+# DDP settings
+backend = 'nccl' # 'nccl', 'gloo', etc.
+# system
+device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks
+dtype = 'bfloat16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler
+compile = True # use PyTorch 2.0 to compile the model to be faster
+# -----------------------------------------------------------------------------
+config_keys = [k for k,v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))]
+exec(open('configurator.py').read()) # overrides from command line or config file
+config = {k: globals()[k] for k in config_keys} # will be useful for logging
+# -----------------------------------------------------------------------------
+
+# various inits, derived attributes, I/O setup
+ddp = int(os.environ.get('RANK', -1)) != -1 # is this a ddp run?
+if ddp:
+    init_process_group(backend=backend)
+    ddp_rank = int(os.environ['RANK'])
+    ddp_local_rank = int(os.environ['LOCAL_RANK'])
+    ddp_world_size = int(os.environ['WORLD_SIZE'])
+    device = f'cuda:{ddp_local_rank}'
+    torch.cuda.set_device(device)
+    master_process = ddp_rank == 0 # this process will do logging, checkpointing etc.
+    seed_offset = ddp_rank # each process gets a different seed
+    assert gradient_accumulation_steps % torch.cuda.device_count() == 0
+    gradient_accumulation_steps //= torch.cuda.device_count()
+else:
+    # if not ddp, we are running on a single gpu, and one process
+    master_process = True
+    seed_offset = 0
+    ddp_world_size = 1
+tokens_per_iter = gradient_accumulation_steps * ddp_world_size * batch_size * block_size
+print(f"tokens per iteration will be: {tokens_per_iter:,}")
+
+if master_process:
+    os.makedirs(out_dir, exist_ok=True)
+torch.manual_seed(1337 + seed_offset)
+torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul
+torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn
+device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast
+# note: float16 data type will automatically use a GradScaler
+ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]
+ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)
+
+# poor man's data loader
+data_dir = os.path.join('data', dataset)
+train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')
+val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')
+def get_batch(split):
+    data = train_data if split == 'train' else val_data
+    ix = torch.randint(len(data) - block_size, (batch_size,))
+    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])
+    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])
+    if device_type == 'cuda':
+        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)
+        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)
+    else:
+        x, y = x.to(device), y.to(device)
+    return x, y
+
+# init these up here, can override if init_from='resume' (i.e. from a checkpoint)
+iter_num = 0
+best_val_loss = 1e9
+
+# attempt to derive vocab_size from the dataset
+meta_path = os.path.join(data_dir, 'meta.pkl')
+meta_vocab_size = None
+if os.path.exists(meta_path):
+    with open(meta_path, 'rb') as f:
+        meta = pickle.load(f)
+    meta_vocab_size = meta['vocab_size']
+    print(f"found vocab_size = {meta_vocab_size} (inside {meta_path})")
+
+# model init
+model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,
+                  bias=bias, vocab_size=None, dropout=dropout) # start with model_args from command line
+if init_from == 'scratch':
+    # init a new model from scratch
+    print("Initializing a new model from scratch")
+    # determine the vocab size we'll use for from-scratch training
+    if meta_vocab_size is None:
+        print("defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)")
+    model_args['vocab_size'] = meta_vocab_size if meta_vocab_size is not None else 50304
+    gptconf = GPTConfig(**model_args)
+    model = GPT(gptconf)
+elif init_from == 'resume':
+    print(f"Resuming training from {out_dir}")
+    # resume training from a checkpoint.
+    ckpt_path = os.path.join(out_dir, 'ckpt.pt')
+    checkpoint = torch.load(ckpt_path, map_location=device)
+    checkpoint_model_args = checkpoint['model_args']
+    # force these config attributes to be equal otherwise we can't even resume training
+    # the rest of the attributes (e.g. dropout) can stay as desired from command line
+    for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:
+        model_args[k] = checkpoint_model_args[k]
+    # create the model
+    gptconf = GPTConfig(**model_args)
+    model = GPT(gptconf)
+    state_dict = checkpoint['model']
+    # fix the keys of the state dictionary :(
+    # honestly no idea how checkpoints sometimes get this prefix, have to debug more
+    unwanted_prefix = '_orig_mod.'
+    for k,v in list(state_dict.items()):
+        if k.startswith(unwanted_prefix):
+            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)
+    model.load_state_dict(state_dict)
+    iter_num = checkpoint['iter_num']
+    best_val_loss = checkpoint['best_val_loss']
+elif init_from.startswith('gpt2'):
+    print(f"Initializing from OpenAI GPT-2 weights: {init_from}")
+    # initialize from OpenAI GPT-2 weights
+    override_args = dict(dropout=dropout)
+    model = GPT.from_pretrained(init_from, override_args)
+    # read off the created config params, so we can store them into checkpoint correctly
+    for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:
+        model_args[k] = getattr(model.config, k)
+# crop down the model block size if desired, using model surgery
+if block_size < model.config.block_size:
+    model.crop_block_size(block_size)
+    model_args['block_size'] = block_size # so that the checkpoint will have the right value
+model.to(device)
+
+# initialize a GradScaler. If enabled=False scaler is a no-op
+scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
+
+# optimizer
+optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)
+if init_from == 'resume':
+    optimizer.load_state_dict(checkpoint['optimizer'])
+checkpoint = None # free up memory
+
+# compile the model
+if compile:
+    print("compiling the model... (takes a ~minute)")
+    unoptimized_model = model
+    model = torch.compile(model) # requires PyTorch 2.0
+
+# wrap model into DDP container
+if ddp:
+    model = DDP(model, device_ids=[ddp_local_rank])
+
+# helps estimate an arbitrarily accurate loss over either split using many batches
+@torch.no_grad()
+def estimate_loss():
+    out = {}
+    model.eval()
+    for split in ['train', 'val']:
+        losses = torch.zeros(eval_iters)
+        for k in range(eval_iters):
+            X, Y = get_batch(split)
+            with ctx:
+                logits, loss = model(X, Y)
+            losses[k] = loss.item()
+        out[split] = losses.mean()
+    model.train()
+    return out
+
+# learning rate decay scheduler (cosine with warmup)
+def get_lr(it):
+    # 1) linear warmup for warmup_iters steps
+    if it < warmup_iters:
+        return learning_rate * it / warmup_iters
+    # 2) if it > lr_decay_iters, return min learning rate
+    if it > lr_decay_iters:
+        return min_lr
+    # 3) in between, use cosine decay down to min learning rate
+    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)
+    assert 0 <= decay_ratio <= 1
+    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1
+    return min_lr + coeff * (learning_rate - min_lr)
+
+# logging
+if wandb_log and master_process:
+    import wandb
+    wandb.init(project=wandb_project, name=wandb_run_name, config=config)
+
+# training loop
+X, Y = get_batch('train') # fetch the very first batch
+t0 = time.time()
+local_iter_num = 0 # number of iterations in the lifetime of this process
+raw_model = model.module if ddp else model # unwrap DDP container if needed
+running_mfu = -1.0
+while True:
+
+    # determine and set the learning rate for this iteration
+    lr = get_lr(iter_num) if decay_lr else learning_rate
+    for param_group in optimizer.param_groups:
+        param_group['lr'] = lr
+
+    # evaluate the loss on train/val sets and write checkpoints
+    if iter_num % eval_interval == 0 and master_process:
+        losses = estimate_loss()
+        print(f"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")
+        if wandb_log:
+            wandb.log({
+                "iter": iter_num,
+                "train/loss": losses['train'],
+                "val/loss": losses['val'],
+                "lr": lr,
+                "mfu": running_mfu*100, # convert to percentage
+            })
+        if losses['val'] < best_val_loss or always_save_checkpoint:
+            best_val_loss = losses['val']
+            if iter_num > 0:
+                checkpoint = {
+                    'model': raw_model.state_dict(),
+                    'optimizer': optimizer.state_dict(),
+                    'model_args': model_args,
+                    'iter_num': iter_num,
+                    'best_val_loss': best_val_loss,
+                    'config': config,
+                }
+                print(f"saving checkpoint to {out_dir}")
+                torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))
+    if iter_num == 0 and eval_only:
+        break
+
+    # forward backward update, with optional gradient accumulation to simulate larger batch size
+    # and using the GradScaler if data type is float16
+    for micro_step in range(gradient_accumulation_steps):
+        if ddp:
+            # in DDP training we only need to sync gradients at the last micro step.
+            # the official way to do this is with model.no_sync() context manager, but
+            # I really dislike that this bloats the code and forces us to repeat code
+            # looking at the source of that context manager, it just toggles this variable
+            model.require_backward_grad_sync = (micro_step == gradient_accumulation_steps - 1)
+        with ctx:
+            logits, loss = model(X, Y)
+            loss = loss / gradient_accumulation_steps # scale the loss to account for gradient accumulation
+        # immediately async prefetch next batch while model is doing the forward pass on the GPU
+        X, Y = get_batch('train')
+        # backward pass, with gradient scaling if training in fp16
+        scaler.scale(loss).backward()
+    # clip the gradient
+    if grad_clip != 0.0:
+        scaler.unscale_(optimizer)
+        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
+    # step the optimizer and scaler if training in fp16
+    scaler.step(optimizer)
+    scaler.update()
+    # flush the gradients as soon as we can, no need for this memory anymore
+    optimizer.zero_grad(set_to_none=True)
+
+    # timing and logging
+    t1 = time.time()
+    dt = t1 - t0
+    t0 = t1
+    if iter_num % log_interval == 0 and master_process:
+        # get loss as float. note: this is a CPU-GPU sync point
+        # scale up to undo the division above, approximating the true total loss (exact would have been a sum)
+        lossf = loss.item() * gradient_accumulation_steps
+        if local_iter_num >= 5: # let the training loop settle a bit
+            mfu = raw_model.estimate_mfu(batch_size * gradient_accumulation_steps, dt)
+            running_mfu = mfu if running_mfu == -1.0 else 0.9*running_mfu + 0.1*mfu
+        print(f"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, mfu {running_mfu*100:.2f}%")
+    iter_num += 1
+    local_iter_num += 1
+
+    # termination conditions
+    if iter_num > max_iters:
+        break
+
+if ddp:
+    destroy_process_group()
diff --git a/wandb/run-20230522_204356-t6ramng5/files/conda-environment.yaml b/wandb/run-20230522_204356-t6ramng5/files/conda-environment.yaml
new file mode 100644
index 0000000..6712918
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/conda-environment.yaml
@@ -0,0 +1,152 @@
+name: gpt
+channels:
+  - conda-forge
+  - defaults
+dependencies:
+  - _libgcc_mutex=0.1=conda_forge
+  - _openmp_mutex=4.5=2_gnu
+  - asttokens=2.2.1=pyhd8ed1ab_0
+  - backcall=0.2.0=pyh9f0ad1d_0
+  - backports=1.0=pyhd8ed1ab_3
+  - backports.functools_lru_cache=1.6.4=pyhd8ed1ab_0
+  - bzip2=1.0.8=h7f98852_4
+  - ca-certificates=2023.5.7=hbcca054_0
+  - debugpy=1.6.7=py39h227be39_0
+  - decorator=5.1.1=pyhd8ed1ab_0
+  - executing=1.2.0=pyhd8ed1ab_0
+  - importlib-metadata=6.6.0=pyha770c72_0
+  - importlib_metadata=6.6.0=hd8ed1ab_0
+  - ipykernel=6.14.0=py39hef51801_0
+  - ipython=8.4.0=py39hf3d152e_0
+  - jedi=0.18.2=pyhd8ed1ab_0
+  - jupyter_client=8.2.0=pyhd8ed1ab_0
+  - jupyter_core=5.3.0=py39hf3d152e_0
+  - ld_impl_linux-64=2.40=h41732ed_0
+  - libffi=3.4.2=h7f98852_5
+  - libgcc-ng=12.2.0=h65d4601_19
+  - libgomp=12.2.0=h65d4601_19
+  - libnsl=2.0.0=h7f98852_0
+  - libsodium=1.0.18=h36c2ea0_1
+  - libsqlite=3.41.2=h2797004_1
+  - libstdcxx-ng=12.2.0=h46fd767_19
+  - libuuid=2.38.1=h0b41bf4_0
+  - libzlib=1.2.13=h166bdaf_4
+  - matplotlib-inline=0.1.6=pyhd8ed1ab_0
+  - ncurses=6.3=h27087fc_1
+  - nest-asyncio=1.5.6=pyhd8ed1ab_0
+  - openssl=3.1.0=hd590300_3
+  - packaging=23.1=pyhd8ed1ab_0
+  - parso=0.8.3=pyhd8ed1ab_0
+  - pexpect=4.8.0=pyh1a96a4e_2
+  - pickleshare=0.7.5=py_1003
+  - pip=23.1.2=pyhd8ed1ab_0
+  - platformdirs=3.5.1=pyhd8ed1ab_0
+  - prompt-toolkit=3.0.38=pyha770c72_0
+  - psutil=5.9.5=py39h72bdee0_0
+  - ptyprocess=0.7.0=pyhd3deb0d_0
+  - pure_eval=0.2.2=pyhd8ed1ab_0
+  - pygments=2.15.1=pyhd8ed1ab_0
+  - python=3.9.16=h2782a2a_0_cpython
+  - python-dateutil=2.8.2=pyhd8ed1ab_0
+  - python_abi=3.9=3_cp39
+  - pyzmq=25.0.2=py39h0be026e_0
+  - readline=8.2=h8228510_1
+  - setuptools=67.7.2=pyhd8ed1ab_0
+  - six=1.16.0=pyh6c4a22f_0
+  - stack_data=0.6.2=pyhd8ed1ab_0
+  - tk=8.6.12=h27826a3_0
+  - tornado=6.3=py39h72bdee0_0
+  - traitlets=5.9.0=pyhd8ed1ab_0
+  - typing-extensions=4.5.0=hd8ed1ab_0
+  - typing_extensions=4.5.0=pyha770c72_0
+  - wcwidth=0.2.6=pyhd8ed1ab_0
+  - wheel=0.40.0=pyhd8ed1ab_0
+  - xz=5.2.6=h166bdaf_0
+  - zeromq=4.3.4=h9c3ff4c_1
+  - zipp=3.15.0=pyhd8ed1ab_0
+  - pip:
+    - aiohttp==3.8.4
+    - aiosignal==1.3.1
+    - appdirs==1.4.4
+    - async-timeout==4.0.2
+    - attrs==23.1.0
+    - boto==2.49.0
+    - boto3==1.26.133
+    - botocore==1.29.133
+    - certifi==2023.5.7
+    - charset-normalizer==3.1.0
+    - click==8.1.3
+    - cmake==3.26.3
+    - contourpy==1.0.7
+    - cycler==0.11.0
+    - datasets==2.12.0
+    - dill==0.3.6
+    - dnspython==2.3.0
+    - docker-pycreds==0.4.0
+    - filelock==3.12.0
+    - fonttools==4.39.4
+    - frozenlist==1.3.3
+    - fsspec==2023.5.0
+    - gitdb==4.0.10
+    - gitpython==3.1.31
+    - greenlet==2.0.2
+    - huggingface-hub==0.14.1
+    - idna==3.4
+    - importlib-resources==5.12.0
+    - influxdb-client==1.36.1
+    - jinja2==3.1.2
+    - jmespath==1.0.1
+    - kiwisolver==1.4.4
+    - lit==16.0.3
+    - markupsafe==2.1.2
+    - matplotlib==3.7.1
+    - mpmath==1.3.0
+    - multidict==6.0.4
+    - multiprocess==0.70.14
+    - networkx==3.1
+    - numpy==1.24.3
+    - nvidia-cublas-cu11==11.10.3.66
+    - nvidia-cuda-cupti-cu11==11.7.101
+    - nvidia-cuda-nvrtc-cu11==11.7.99
+    - nvidia-cuda-runtime-cu11==11.7.99
+    - nvidia-cudnn-cu11==8.5.0.96
+    - nvidia-cufft-cu11==10.9.0.58
+    - nvidia-curand-cu11==10.2.10.91
+    - nvidia-cusolver-cu11==11.4.0.1
+    - nvidia-cusparse-cu11==11.7.4.91
+    - nvidia-nccl-cu11==2.14.3
+    - nvidia-nvtx-cu11==11.7.91
+    - pandas==2.0.1
+    - pathtools==0.1.2
+    - pillow==9.5.0
+    - protobuf==4.23.0
+    - psycopg2-binary==2.9.6
+    - pyarrow==12.0.0
+    - pymongo==4.3.3
+    - pyparsing==3.0.9
+    - pytz==2023.3
+    - pyyaml==6.0
+    - reactivex==4.0.4
+    - regex==2023.5.5
+    - requests==2.30.0
+    - responses==0.18.0
+    - s3transfer==0.6.1
+    - sentry-sdk==1.22.2
+    - setproctitle==1.3.2
+    - smmap==5.0.0
+    - sqlalchemy==2.0.13
+    - sympy==1.12
+    - tiktoken==0.4.0
+    - tokenizers==0.13.3
+    - torch==2.0.1
+    - torchaudio==2.0.2
+    - torchvision==0.15.2
+    - tqdm==4.65.0
+    - transformers==4.29.2
+    - triton==2.0.0
+    - tzdata==2023.3
+    - urllib3==1.26.15
+    - wandb==0.15.2
+    - xxhash==3.2.0
+    - yarl==1.9.2
+prefix: /home/ubuntu/anaconda3/envs/gpt
diff --git a/wandb/run-20230522_204356-t6ramng5/files/config.yaml b/wandb/run-20230522_204356-t6ramng5/files/config.yaml
new file mode 100644
index 0000000..fb01e81
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/config.yaml
@@ -0,0 +1,132 @@
+wandb_version: 1
+
+out_dir:
+  desc: null
+  value: out-nd-accel
+eval_interval:
+  desc: null
+  value: 250
+log_interval:
+  desc: null
+  value: 10
+eval_iters:
+  desc: null
+  value: 200
+eval_only:
+  desc: null
+  value: false
+always_save_checkpoint:
+  desc: null
+  value: false
+init_from:
+  desc: null
+  value: scratch
+wandb_log:
+  desc: null
+  value: true
+wandb_project:
+  desc: null
+  value: nd-accel
+wandb_run_name:
+  desc: null
+  value: mini-gpt-1
+dataset:
+  desc: null
+  value: nd_accel
+gradient_accumulation_steps:
+  desc: null
+  value: 1
+batch_size:
+  desc: null
+  value: 64
+block_size:
+  desc: null
+  value: 256
+n_layer:
+  desc: null
+  value: 6
+n_head:
+  desc: null
+  value: 6
+n_embd:
+  desc: null
+  value: 384
+dropout:
+  desc: null
+  value: 0.2
+bias:
+  desc: null
+  value: false
+learning_rate:
+  desc: null
+  value: 0.001
+max_iters:
+  desc: null
+  value: 5000
+weight_decay:
+  desc: null
+  value: 0.1
+beta1:
+  desc: null
+  value: 0.9
+beta2:
+  desc: null
+  value: 0.99
+grad_clip:
+  desc: null
+  value: 1.0
+decay_lr:
+  desc: null
+  value: true
+warmup_iters:
+  desc: null
+  value: 100
+lr_decay_iters:
+  desc: null
+  value: 5000
+min_lr:
+  desc: null
+  value: 0.0001
+backend:
+  desc: null
+  value: nccl
+device:
+  desc: null
+  value: cuda
+dtype:
+  desc: null
+  value: float16
+compile:
+  desc: null
+  value: true
+_wandb:
+  desc: null
+  value:
+    code_path: code/train.py
+    python_version: 3.9.16
+    cli_version: 0.15.2
+    framework: huggingface
+    huggingface_version: 4.29.2
+    is_jupyter_run: false
+    is_kaggle_kernel: false
+    start_time: 1684788236.604932
+    t:
+      1:
+      - 1
+      - 11
+      - 49
+      - 55
+      2:
+      - 1
+      - 11
+      - 49
+      - 55
+      3:
+      - 13
+      - 16
+      - 23
+      4: 3.9.16
+      5: 0.15.2
+      6: 4.29.2
+      8:
+      - 5
diff --git a/wandb/run-20230522_204356-t6ramng5/files/diff.patch b/wandb/run-20230522_204356-t6ramng5/files/diff.patch
new file mode 100644
index 0000000..fc7d3cc
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/diff.patch
@@ -0,0 +1,278 @@
+diff --git a/config/train_shakespeare_char.py b/config/train_shakespeare_char.py
+index 41c81df..13063a6 100644
+--- a/config/train_shakespeare_char.py
++++ b/config/train_shakespeare_char.py
+@@ -1,5 +1,7 @@
+ # train a miniature character-level shakespeare model
+ # good for debugging and playing on macbooks and such
++# python train.py config/train_shakespeare_char.py --dtype=float16
++# python sample.py --out_dir=out-shakespeare-char --dtype=float16 
+ 
+ out_dir = 'out-shakespeare-char'
+ eval_interval = 250 # keep frequent because we'll overfit
+@@ -9,7 +11,7 @@ log_interval = 10 # don't print too too often
+ # we expect to overfit on this small dataset, so only save when val improves
+ always_save_checkpoint = False
+ 
+-wandb_log = False # override via command line if you like
++wandb_log = True # override via command line if you like
+ wandb_project = 'shakespeare-char'
+ wandb_run_name = 'mini-gpt'
+ 
+diff --git a/data/openwebtext/prepare.py b/data/openwebtext/prepare.py
+deleted file mode 100644
+index 8dc30e1..0000000
+--- a/data/openwebtext/prepare.py
++++ /dev/null
+@@ -1,74 +0,0 @@
+-# saves the openwebtext dataset to a binary file for training. following was helpful:
+-# https://github.com/HazyResearch/flash-attention/blob/main/training/src/datamodules/language_modeling_hf.py
+-
+-import os
+-from tqdm import tqdm
+-import numpy as np
+-import tiktoken
+-from datasets import load_dataset # huggingface datasets
+-
+-# number of workers in .map() call
+-# good number to use is ~order number of cpu cores // 2
+-num_proc = 8
+-
+-# takes 54GB in huggingface .cache dir, about 8M documents (8,013,769)
+-dataset = load_dataset("openwebtext")
+-
+-# owt by default only contains the 'train' split, so create a test split
+-split_dataset = dataset["train"].train_test_split(test_size=0.0005, seed=2357, shuffle=True)
+-split_dataset['val'] = split_dataset.pop('test') # rename the test split to val
+-
+-# this results in:
+-# >>> split_dataset
+-# DatasetDict({
+-#     train: Dataset({
+-#         features: ['text'],
+-#         num_rows: 8009762
+-#     })
+-#     val: Dataset({
+-#         features: ['text'],
+-#         num_rows: 4007
+-#     })
+-# })
+-
+-# we now want to tokenize the dataset. first define the encoding function (gpt2 bpe)
+-enc = tiktoken.get_encoding("gpt2")
+-def process(example):
+-    ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens
+-    ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe
+-    # note: I think eot should be prepended not appended... hmm. it's called "eot" though...
+-    out = {'ids': ids, 'len': len(ids)}
+-    return out
+-
+-# tokenize the dataset
+-tokenized = split_dataset.map(
+-    process,
+-    remove_columns=['text'],
+-    desc="tokenizing the splits",
+-    num_proc=num_proc,
+-)
+-
+-# concatenate all the ids in each dataset into one large file we can use for training
+-for split, dset in tokenized.items():
+-    arr_len = np.sum(dset['len'])
+-    filename = os.path.join(os.path.dirname(__file__), f'{split}.bin')
+-    dtype = np.uint16 # (can do since enc.max_token_value == 50256 is < 2**16)
+-    arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))
+-    total_batches = 1024
+-
+-    idx = 0
+-    for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):
+-        # Batch together samples for faster write
+-        batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')
+-        arr_batch = np.concatenate(batch['ids'])
+-        # Write into mmap
+-        arr[idx : idx + len(arr_batch)] = arr_batch
+-        idx += len(arr_batch)
+-    arr.flush()
+-
+-# train.bin is ~17GB, val.bin ~8.5MB
+-# train has ~9B tokens (9,035,582,198)
+-# val has ~4M tokens (4,434,897)
+-
+-# to read the bin files later, e.g. with numpy:
+-# m = np.memmap('train.bin', dtype=np.uint16, mode='r')
+diff --git a/data/openwebtext/readme.md b/data/openwebtext/readme.md
+deleted file mode 100644
+index 95eb1bf..0000000
+--- a/data/openwebtext/readme.md
++++ /dev/null
+@@ -1,15 +0,0 @@
+-
+-## openwebtext dataset
+-
+-after running `prepare.py` (preprocess) we get:
+-
+-- train.bin is ~17GB, val.bin ~8.5MB
+-- train has ~9B tokens (9,035,582,198)
+-- val has ~4M tokens (4,434,897)
+-
+-this came from 8,013,769 documents in total.
+-
+-references:
+-
+-- OpenAI's WebText dataset is discussed in [GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
+-- [OpenWebText](https://skylion007.github.io/OpenWebTextCorpus/) dataset
+diff --git a/data/shakespeare/prepare.py b/data/shakespeare/prepare.py
+deleted file mode 100644
+index 71c88da..0000000
+--- a/data/shakespeare/prepare.py
++++ /dev/null
+@@ -1,33 +0,0 @@
+-import os
+-import requests
+-import tiktoken
+-import numpy as np
+-
+-# download the tiny shakespeare dataset
+-input_file_path = os.path.join(os.path.dirname(__file__), 'input.txt')
+-if not os.path.exists(input_file_path):
+-    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'
+-    with open(input_file_path, 'w') as f:
+-        f.write(requests.get(data_url).text)
+-
+-with open(input_file_path, 'r') as f:
+-    data = f.read()
+-n = len(data)
+-train_data = data[:int(n*0.9)]
+-val_data = data[int(n*0.9):]
+-
+-# encode with tiktoken gpt2 bpe
+-enc = tiktoken.get_encoding("gpt2")
+-train_ids = enc.encode_ordinary(train_data)
+-val_ids = enc.encode_ordinary(val_data)
+-print(f"train has {len(train_ids):,} tokens")
+-print(f"val has {len(val_ids):,} tokens")
+-
+-# export to bin files
+-train_ids = np.array(train_ids, dtype=np.uint16)
+-val_ids = np.array(val_ids, dtype=np.uint16)
+-train_ids.tofile(os.path.join(os.path.dirname(__file__), 'train.bin'))
+-val_ids.tofile(os.path.join(os.path.dirname(__file__), 'val.bin'))
+-
+-# train.bin has 301,966 tokens
+-# val.bin has 36,059 tokens
+diff --git a/data/shakespeare/readme.md b/data/shakespeare/readme.md
+deleted file mode 100644
+index 1e6c457..0000000
+--- a/data/shakespeare/readme.md
++++ /dev/null
+@@ -1,9 +0,0 @@
+-
+-# tiny shakespeare
+-
+-Tiny shakespeare, of the good old char-rnn fame :)
+-
+-After running `prepare.py`:
+-
+-- train.bin has 301,966 tokens
+-- val.bin has 36,059 tokens
+diff --git a/data/shakespeare_char/prepare.py b/data/shakespeare_char/prepare.py
+deleted file mode 100644
+index 9fd1621..0000000
+--- a/data/shakespeare_char/prepare.py
++++ /dev/null
+@@ -1,68 +0,0 @@
+-"""
+-Prepare the Shakespeare dataset for character-level language modeling.
+-So instead of encoding with GPT-2 BPE tokens, we just map characters to ints.
+-Will save train.bin, val.bin containing the ids, and meta.pkl containing the
+-encoder and decoder and some other related info.
+-"""
+-import os
+-import pickle
+-import requests
+-import numpy as np
+-
+-# download the tiny shakespeare dataset
+-input_file_path = os.path.join(os.path.dirname(__file__), 'input.txt')
+-if not os.path.exists(input_file_path):
+-    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'
+-    with open(input_file_path, 'w') as f:
+-        f.write(requests.get(data_url).text)
+-
+-with open(input_file_path, 'r') as f:
+-    data = f.read()
+-print(f"length of dataset in characters: {len(data):,}")
+-
+-# get all the unique characters that occur in this text
+-chars = sorted(list(set(data)))
+-vocab_size = len(chars)
+-print("all the unique characters:", ''.join(chars))
+-print(f"vocab size: {vocab_size:,}")
+-
+-# create a mapping from characters to integers
+-stoi = { ch:i for i,ch in enumerate(chars) }
+-itos = { i:ch for i,ch in enumerate(chars) }
+-def encode(s):
+-    return [stoi[c] for c in s] # encoder: take a string, output a list of integers
+-def decode(l):
+-    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string
+-
+-# create the train and test splits
+-n = len(data)
+-train_data = data[:int(n*0.9)]
+-val_data = data[int(n*0.9):]
+-
+-# encode both to integers
+-train_ids = encode(train_data)
+-val_ids = encode(val_data)
+-print(f"train has {len(train_ids):,} tokens")
+-print(f"val has {len(val_ids):,} tokens")
+-
+-# export to bin files
+-train_ids = np.array(train_ids, dtype=np.uint16)
+-val_ids = np.array(val_ids, dtype=np.uint16)
+-train_ids.tofile(os.path.join(os.path.dirname(__file__), 'train.bin'))
+-val_ids.tofile(os.path.join(os.path.dirname(__file__), 'val.bin'))
+-
+-# save the meta information as well, to help us encode/decode later
+-meta = {
+-    'vocab_size': vocab_size,
+-    'itos': itos,
+-    'stoi': stoi,
+-}
+-with open(os.path.join(os.path.dirname(__file__), 'meta.pkl'), 'wb') as f:
+-    pickle.dump(meta, f)
+-
+-# length of dataset in characters:  1115394
+-# all the unique characters:
+-#  !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
+-# vocab size: 65
+-# train has 1003854 tokens
+-# val has 111540 tokens
+diff --git a/data/shakespeare_char/readme.md b/data/shakespeare_char/readme.md
+deleted file mode 100644
+index d597b79..0000000
+--- a/data/shakespeare_char/readme.md
++++ /dev/null
+@@ -1,9 +0,0 @@
+-
+-# tiny shakespeare, character-level
+-
+-Tiny shakespeare, of the good old char-rnn fame :) Treated on character-level.
+-
+-After running `prepare.py`:
+-
+-- train.bin has 1,003,854 tokens
+-- val.bin has 111,540 tokens
+diff --git a/sample.py b/sample.py
+index 670759b..483cf9b 100644
+--- a/sample.py
++++ b/sample.py
+@@ -11,7 +11,7 @@ from model import GPTConfig, GPT
+ # -----------------------------------------------------------------------------
+ init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')
+ out_dir = 'out' # ignored if init_from is not 'resume'
+-start = "\n" # or "<|endoftext|>" or etc. Can also specify a file, use as: "FILE:prompt.txt"
++start = "\n"#"FILE:data/nd_small/prompt.txt" #"{"#"\n" # or "<|endoftext|>" or etc. Can also specify a file, use as: "FILE:prompt.txt"
+ num_samples = 10 # number of samples to draw
+ max_new_tokens = 500 # number of tokens generated in each sample
+ temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions
diff --git a/wandb/run-20230522_204356-t6ramng5/files/output.log b/wandb/run-20230522_204356-t6ramng5/files/output.log
new file mode 100644
index 0000000..9ab8727
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/output.log
@@ -0,0 +1,555 @@
+
+step 0: train loss 3.1695, val loss 3.1715
+[2023-05-22 20:44:17,065] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:17,372] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:17,813] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:18,106] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:18,505] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:18,801] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:19,334] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:19,627] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:20,021] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:20,316] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:20,717] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+[2023-05-22 20:44:21,013] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
+iter 0: loss 3.1611, time 22314.16ms, mfu -100.00%
+iter 10: loss 2.1882, time 109.51ms, mfu 3.40%
+iter 20: loss 2.0300, time 110.42ms, mfu 3.40%
+iter 30: loss 1.9699, time 111.87ms, mfu 3.39%
+iter 40: loss 1.9432, time 108.73ms, mfu 3.39%
+iter 50: loss 1.9252, time 108.52ms, mfu 3.40%
+iter 60: loss 1.8629, time 108.40ms, mfu 3.40%
+iter 70: loss 1.8291, time 111.26ms, mfu 3.39%
+iter 80: loss 1.7850, time 110.54ms, mfu 3.39%
+iter 90: loss 1.7428, time 110.59ms, mfu 3.39%
+iter 100: loss 1.7301, time 111.06ms, mfu 3.38%
+iter 110: loss 1.6468, time 112.00ms, mfu 3.38%
+iter 120: loss 1.6112, time 112.01ms, mfu 3.37%
+iter 130: loss 1.5903, time 110.49ms, mfu 3.37%
+iter 140: loss 1.5329, time 109.89ms, mfu 3.37%
+iter 150: loss 1.5376, time 109.66ms, mfu 3.38%
+iter 160: loss 1.5095, time 110.57ms, mfu 3.37%
+iter 170: loss 1.4616, time 110.95ms, mfu 3.37%
+iter 180: loss 1.4712, time 108.58ms, mfu 3.38%
+iter 190: loss 1.4234, time 111.16ms, mfu 3.37%
+iter 200: loss 1.3987, time 108.87ms, mfu 3.38%
+iter 210: loss 1.3998, time 111.64ms, mfu 3.37%
+iter 220: loss 1.3865, time 111.87ms, mfu 3.37%
+iter 230: loss 1.3954, time 112.58ms, mfu 3.36%
+iter 240: loss 1.3625, time 111.52ms, mfu 3.36%
+step 250: train loss 1.3397, val loss 1.3413
+saving checkpoint to out-nd-accel
+iter 250: loss 1.3647, time 13982.25ms, mfu 3.03%
+iter 260: loss 1.3192, time 113.85ms, mfu 3.05%
+iter 270: loss 1.3271, time 111.55ms, mfu 3.08%
+iter 280: loss 1.2969, time 111.75ms, mfu 3.10%
+iter 290: loss 1.2997, time 111.19ms, mfu 3.13%
+iter 300: loss 1.3024, time 111.48ms, mfu 3.15%
+iter 310: loss 1.3157, time 111.70ms, mfu 3.17%
+iter 320: loss 1.2734, time 112.89ms, mfu 3.18%
+iter 330: loss 1.2473, time 110.78ms, mfu 3.20%
+iter 340: loss 1.2068, time 112.27ms, mfu 3.21%
+iter 350: loss 1.1876, time 111.31ms, mfu 3.22%
+iter 360: loss 1.1875, time 111.95ms, mfu 3.23%
+iter 370: loss 1.1402, time 111.96ms, mfu 3.24%
+iter 380: loss 1.0814, time 111.74ms, mfu 3.25%
+iter 390: loss 1.0702, time 112.70ms, mfu 3.26%
+iter 400: loss 1.0469, time 114.09ms, mfu 3.26%
+iter 410: loss 1.0554, time 113.47ms, mfu 3.26%
+iter 420: loss 1.0309, time 113.89ms, mfu 3.26%
+iter 430: loss 0.9874, time 112.76ms, mfu 3.26%
+iter 440: loss 0.9947, time 112.01ms, mfu 3.27%
+iter 450: loss 1.0088, time 113.17ms, mfu 3.27%
+iter 460: loss 1.0019, time 116.39ms, mfu 3.26%
+iter 470: loss 0.9770, time 113.81ms, mfu 3.26%
+iter 480: loss 0.9563, time 114.73ms, mfu 3.26%
+iter 490: loss 0.9822, time 112.31ms, mfu 3.27%
+step 500: train loss 0.8859, val loss 0.8841
+saving checkpoint to out-nd-accel
+iter 500: loss 0.9168, time 11381.80ms, mfu 2.94%
+iter 510: loss 0.9451, time 113.85ms, mfu 2.98%
+iter 520: loss 0.8991, time 114.87ms, mfu 3.00%
+iter 530: loss 0.9467, time 114.25ms, mfu 3.03%
+iter 540: loss 0.9553, time 114.25ms, mfu 3.05%
+iter 550: loss 0.9220, time 116.06ms, mfu 3.07%
+iter 560: loss 0.9361, time 116.37ms, mfu 3.08%
+iter 570: loss 0.9335, time 113.59ms, mfu 3.10%
+iter 580: loss 0.9427, time 116.07ms, mfu 3.11%
+iter 590: loss 0.9273, time 114.96ms, mfu 3.12%
+iter 600: loss 0.8971, time 114.96ms, mfu 3.13%
+iter 610: loss 0.9162, time 114.47ms, mfu 3.15%
+iter 620: loss 0.8778, time 116.63ms, mfu 3.15%
+iter 630: loss 0.9278, time 116.95ms, mfu 3.15%
+iter 640: loss 0.8960, time 115.61ms, mfu 3.16%
+iter 650: loss 0.9060, time 116.48ms, mfu 3.16%
+iter 660: loss 0.9226, time 116.21ms, mfu 3.17%
+iter 670: loss 0.8855, time 117.15ms, mfu 3.17%
+iter 680: loss 0.8707, time 115.23ms, mfu 3.17%
+iter 690: loss 0.8864, time 114.47ms, mfu 3.18%
+iter 700: loss 0.8944, time 114.38ms, mfu 3.19%
+iter 710: loss 0.8929, time 114.42ms, mfu 3.20%
+iter 720: loss 0.8514, time 116.55ms, mfu 3.20%
+iter 730: loss 0.9156, time 114.47ms, mfu 3.20%
+iter 740: loss 0.8566, time 114.04ms, mfu 3.21%
+step 750: train loss 0.8547, val loss 0.8547
+saving checkpoint to out-nd-accel
+iter 750: loss 0.9041, time 11583.23ms, mfu 2.89%
+iter 760: loss 0.8746, time 115.43ms, mfu 2.92%
+iter 770: loss 0.8864, time 115.66ms, mfu 2.95%
+iter 780: loss 0.9089, time 116.39ms, mfu 2.98%
+iter 790: loss 0.8875, time 117.95ms, mfu 2.99%
+iter 800: loss 0.8715, time 115.85ms, mfu 3.02%
+iter 810: loss 0.8941, time 116.19ms, mfu 3.03%
+iter 820: loss 0.8676, time 117.68ms, mfu 3.05%
+iter 830: loss 0.8748, time 115.61ms, mfu 3.06%
+iter 840: loss 0.8376, time 115.76ms, mfu 3.08%
+iter 850: loss 0.8397, time 117.10ms, mfu 3.09%
+iter 860: loss 0.8579, time 117.26ms, mfu 3.10%
+iter 870: loss 0.8411, time 116.63ms, mfu 3.11%
+iter 880: loss 0.8977, time 117.75ms, mfu 3.11%
+iter 890: loss 0.9204, time 116.13ms, mfu 3.12%
+iter 900: loss 0.8922, time 115.94ms, mfu 3.13%
+iter 910: loss 0.8519, time 117.56ms, mfu 3.13%
+iter 920: loss 0.8791, time 116.88ms, mfu 3.14%
+iter 930: loss 0.8792, time 118.07ms, mfu 3.14%
+iter 940: loss 0.8534, time 117.51ms, mfu 3.14%
+iter 950: loss 0.9205, time 117.47ms, mfu 3.15%
+iter 960: loss 0.8516, time 116.85ms, mfu 3.15%
+iter 970: loss 0.8751, time 117.65ms, mfu 3.15%
+iter 980: loss 0.8869, time 117.20ms, mfu 3.15%
+iter 990: loss 0.8810, time 118.60ms, mfu 3.15%
+step 1000: train loss 0.8382, val loss 0.8364
+saving checkpoint to out-nd-accel
+iter 1000: loss 0.8692, time 11775.95ms, mfu 2.84%
+iter 1010: loss 0.8440, time 116.98ms, mfu 2.87%
+iter 1020: loss 0.8743, time 119.06ms, mfu 2.90%
+iter 1030: loss 0.8449, time 119.22ms, mfu 2.92%
+iter 1040: loss 0.8428, time 118.72ms, mfu 2.94%
+iter 1050: loss 0.8349, time 118.79ms, mfu 2.96%
+iter 1060: loss 0.8173, time 117.43ms, mfu 2.98%
+iter 1070: loss 0.8665, time 117.05ms, mfu 3.00%
+iter 1080: loss 0.8646, time 117.46ms, mfu 3.02%
+iter 1090: loss 0.8304, time 117.15ms, mfu 3.03%
+iter 1100: loss 0.8679, time 117.52ms, mfu 3.05%
+iter 1110: loss 0.8391, time 119.92ms, mfu 3.05%
+iter 1120: loss 0.8470, time 118.14ms, mfu 3.06%
+iter 1130: loss 0.8323, time 118.52ms, mfu 3.07%
+iter 1140: loss 0.8422, time 118.29ms, mfu 3.08%
+iter 1150: loss 0.8489, time 119.87ms, mfu 3.08%
+iter 1160: loss 0.8173, time 117.59ms, mfu 3.09%
+iter 1170: loss 0.8513, time 118.60ms, mfu 3.09%
+iter 1180: loss 0.8017, time 119.20ms, mfu 3.10%
+iter 1190: loss 0.8547, time 120.45ms, mfu 3.10%
+iter 1200: loss 0.8389, time 118.04ms, mfu 3.10%
+iter 1210: loss 0.8343, time 119.07ms, mfu 3.10%
+iter 1220: loss 0.8345, time 118.37ms, mfu 3.11%
+iter 1230: loss 0.8354, time 118.04ms, mfu 3.11%
+iter 1240: loss 0.8318, time 118.50ms, mfu 3.12%
+step 1250: train loss 0.7852, val loss 0.7858
+saving checkpoint to out-nd-accel
+iter 1250: loss 0.8195, time 11950.40ms, mfu 2.81%
+iter 1260: loss 0.7862, time 118.13ms, mfu 2.84%
+iter 1270: loss 0.7802, time 119.51ms, mfu 2.87%
+iter 1280: loss 0.8145, time 118.32ms, mfu 2.90%
+iter 1290: loss 0.8048, time 118.54ms, mfu 2.92%
+iter 1300: loss 0.7988, time 117.84ms, mfu 2.94%
+iter 1310: loss 0.7821, time 119.41ms, mfu 2.96%
+iter 1320: loss 0.7729, time 117.19ms, mfu 2.98%
+iter 1330: loss 0.7941, time 117.41ms, mfu 3.00%
+iter 1340: loss 0.7827, time 119.30ms, mfu 3.01%
+iter 1350: loss 0.7714, time 117.25ms, mfu 3.03%
+iter 1360: loss 0.7959, time 119.87ms, mfu 3.04%
+iter 1370: loss 0.7443, time 117.61ms, mfu 3.05%
+iter 1380: loss 0.7232, time 117.01ms, mfu 3.06%
+iter 1390: loss 0.7405, time 118.19ms, mfu 3.07%
+iter 1400: loss 0.7204, time 117.16ms, mfu 3.08%
+iter 1410: loss 0.7061, time 117.20ms, mfu 3.09%
+iter 1420: loss 0.7044, time 118.84ms, mfu 3.09%
+iter 1430: loss 0.6967, time 119.90ms, mfu 3.10%
+iter 1440: loss 0.7310, time 119.01ms, mfu 3.10%
+iter 1450: loss 0.7211, time 117.85ms, mfu 3.10%
+iter 1460: loss 0.7141, time 118.08ms, mfu 3.11%
+iter 1470: loss 0.7108, time 118.28ms, mfu 3.11%
+iter 1480: loss 0.6892, time 118.44ms, mfu 3.12%
+iter 1490: loss 0.7055, time 118.04ms, mfu 3.12%
+step 1500: train loss 0.6386, val loss 0.6397
+saving checkpoint to out-nd-accel
+iter 1500: loss 0.6940, time 11758.40ms, mfu 2.81%
+iter 1510: loss 0.6634, time 117.05ms, mfu 2.85%
+iter 1520: loss 0.6734, time 117.75ms, mfu 2.88%
+iter 1530: loss 0.6405, time 116.62ms, mfu 2.91%
+iter 1540: loss 0.6731, time 116.97ms, mfu 2.94%
+iter 1550: loss 0.6533, time 117.86ms, mfu 2.96%
+iter 1560: loss 0.6222, time 117.36ms, mfu 2.98%
+iter 1570: loss 0.6461, time 116.80ms, mfu 3.00%
+iter 1580: loss 0.6680, time 117.95ms, mfu 3.02%
+iter 1590: loss 0.6210, time 117.60ms, mfu 3.03%
+iter 1600: loss 0.6204, time 117.04ms, mfu 3.05%
+iter 1610: loss 0.6391, time 117.93ms, mfu 3.06%
+iter 1620: loss 0.6252, time 116.48ms, mfu 3.07%
+iter 1630: loss 0.6140, time 117.21ms, mfu 3.08%
+iter 1640: loss 0.6244, time 117.62ms, mfu 3.09%
+iter 1650: loss 0.6327, time 118.26ms, mfu 3.10%
+iter 1660: loss 0.6318, time 116.96ms, mfu 3.10%
+iter 1670: loss 0.5943, time 115.83ms, mfu 3.11%
+iter 1680: loss 0.6172, time 114.74ms, mfu 3.13%
+iter 1690: loss 0.6115, time 115.92ms, mfu 3.14%
+iter 1700: loss 0.6218, time 117.01ms, mfu 3.14%
+iter 1710: loss 0.6154, time 116.99ms, mfu 3.14%
+iter 1720: loss 0.6227, time 118.22ms, mfu 3.14%
+iter 1730: loss 0.6198, time 116.40ms, mfu 3.15%
+iter 1740: loss 0.5985, time 118.55ms, mfu 3.15%
+step 1750: train loss 0.5721, val loss 0.5725
+saving checkpoint to out-nd-accel
+iter 1750: loss 0.6021, time 11717.03ms, mfu 2.84%
+iter 1760: loss 0.5966, time 117.22ms, mfu 2.87%
+iter 1770: loss 0.6099, time 116.59ms, mfu 2.90%
+iter 1780: loss 0.6019, time 118.30ms, mfu 2.93%
+iter 1790: loss 0.6148, time 117.05ms, mfu 2.95%
+iter 1800: loss 0.6081, time 116.26ms, mfu 2.98%
+iter 1810: loss 0.6142, time 116.80ms, mfu 3.00%
+iter 1820: loss 0.5873, time 117.32ms, mfu 3.02%
+iter 1830: loss 0.5783, time 116.22ms, mfu 3.03%
+iter 1840: loss 0.5978, time 118.00ms, mfu 3.05%
+iter 1850: loss 0.6035, time 117.96ms, mfu 3.06%
+iter 1860: loss 0.5883, time 118.03ms, mfu 3.07%
+iter 1870: loss 0.5832, time 119.19ms, mfu 3.07%
+iter 1880: loss 0.6103, time 116.94ms, mfu 3.08%
+iter 1890: loss 0.5977, time 116.32ms, mfu 3.09%
+iter 1900: loss 0.5924, time 118.16ms, mfu 3.10%
+iter 1910: loss 0.5914, time 118.67ms, mfu 3.10%
+iter 1920: loss 0.5831, time 116.91ms, mfu 3.11%
+iter 1930: loss 0.5890, time 118.58ms, mfu 3.11%
+iter 1940: loss 0.5987, time 117.58ms, mfu 3.12%
+iter 1950: loss 0.5911, time 117.17ms, mfu 3.12%
+iter 1960: loss 0.5872, time 118.01ms, mfu 3.13%
+iter 1970: loss 0.5902, time 117.97ms, mfu 3.13%
+iter 1980: loss 0.5719, time 116.37ms, mfu 3.14%
+iter 1990: loss 0.5919, time 117.06ms, mfu 3.14%
+step 2000: train loss 0.5602, val loss 0.5604
+saving checkpoint to out-nd-accel
+iter 2000: loss 0.5821, time 11883.16ms, mfu 2.83%
+iter 2010: loss 0.5739, time 118.78ms, mfu 2.86%
+iter 2020: loss 0.5653, time 117.83ms, mfu 2.89%
+iter 2030: loss 0.5799, time 116.45ms, mfu 2.92%
+iter 2040: loss 0.6056, time 117.73ms, mfu 2.94%
+iter 2050: loss 0.5818, time 119.95ms, mfu 2.96%
+iter 2060: loss 0.5892, time 118.17ms, mfu 2.98%
+iter 2070: loss 0.5682, time 121.49ms, mfu 2.99%
+iter 2080: loss 0.5844, time 119.89ms, mfu 3.00%
+iter 2090: loss 0.5769, time 118.65ms, mfu 3.01%
+iter 2100: loss 0.5859, time 117.39ms, mfu 3.03%
+iter 2110: loss 0.5884, time 120.05ms, mfu 3.04%
+iter 2120: loss 0.5668, time 120.59ms, mfu 3.04%
+iter 2130: loss 0.5823, time 119.35ms, mfu 3.05%
+iter 2140: loss 0.6052, time 118.45ms, mfu 3.06%
+iter 2150: loss 0.5542, time 119.61ms, mfu 3.06%
+iter 2160: loss 0.5636, time 117.03ms, mfu 3.07%
+iter 2170: loss 0.5567, time 118.88ms, mfu 3.08%
+iter 2180: loss 0.6025, time 119.08ms, mfu 3.08%
+iter 2190: loss 0.5786, time 119.07ms, mfu 3.09%
+iter 2200: loss 0.5660, time 118.06ms, mfu 3.10%
+iter 2210: loss 0.5698, time 116.73ms, mfu 3.10%
+iter 2220: loss 0.5418, time 118.31ms, mfu 3.11%
+iter 2230: loss 0.5796, time 118.45ms, mfu 3.11%
+iter 2240: loss 0.5776, time 119.86ms, mfu 3.11%
+step 2250: train loss 0.5512, val loss 0.5495
+saving checkpoint to out-nd-accel
+iter 2250: loss 0.5812, time 11898.98ms, mfu 2.80%
+iter 2260: loss 0.5903, time 118.81ms, mfu 2.84%
+iter 2270: loss 0.5581, time 117.58ms, mfu 2.87%
+iter 2280: loss 0.5612, time 119.88ms, mfu 2.89%
+iter 2290: loss 0.5759, time 117.71ms, mfu 2.92%
+iter 2300: loss 0.5587, time 119.26ms, mfu 2.94%
+iter 2310: loss 0.5838, time 118.38ms, mfu 2.96%
+iter 2320: loss 0.5687, time 119.33ms, mfu 2.98%
+iter 2330: loss 0.5818, time 117.35ms, mfu 3.00%
+iter 2340: loss 0.5553, time 117.29ms, mfu 3.01%
+iter 2350: loss 0.5861, time 117.78ms, mfu 3.03%
+iter 2360: loss 0.5865, time 117.31ms, mfu 3.04%
+iter 2370: loss 0.5458, time 119.49ms, mfu 3.05%
+iter 2380: loss 0.5471, time 117.48ms, mfu 3.06%
+iter 2390: loss 0.5530, time 117.82ms, mfu 3.07%
+iter 2400: loss 0.5781, time 119.65ms, mfu 3.07%
+iter 2410: loss 0.5448, time 118.89ms, mfu 3.08%
+iter 2420: loss 0.5988, time 118.92ms, mfu 3.09%
+iter 2430: loss 0.5866, time 116.49ms, mfu 3.10%
+iter 2440: loss 0.5747, time 120.18ms, mfu 3.10%
+iter 2450: loss 0.5602, time 119.18ms, mfu 3.10%
+iter 2460: loss 0.5545, time 118.31ms, mfu 3.10%
+iter 2470: loss 0.5617, time 118.90ms, mfu 3.11%
+iter 2480: loss 0.5632, time 117.84ms, mfu 3.11%
+iter 2490: loss 0.5859, time 119.63ms, mfu 3.11%
+step 2500: train loss 0.5479, val loss 0.5466
+saving checkpoint to out-nd-accel
+iter 2500: loss 0.5659, time 11952.47ms, mfu 2.80%
+iter 2510: loss 0.5289, time 117.19ms, mfu 2.84%
+iter 2520: loss 0.5483, time 118.87ms, mfu 2.87%
+iter 2530: loss 0.5561, time 118.59ms, mfu 2.90%
+iter 2540: loss 0.5731, time 118.12ms, mfu 2.92%
+iter 2550: loss 0.5564, time 119.64ms, mfu 2.94%
+iter 2560: loss 0.5778, time 117.43ms, mfu 2.96%
+iter 2570: loss 0.5659, time 118.23ms, mfu 2.98%
+iter 2580: loss 0.5722, time 118.28ms, mfu 3.00%
+iter 2590: loss 0.5592, time 117.13ms, mfu 3.02%
+iter 2600: loss 0.5612, time 117.68ms, mfu 3.03%
+iter 2610: loss 0.5533, time 118.35ms, mfu 3.04%
+iter 2620: loss 0.5459, time 118.63ms, mfu 3.05%
+iter 2630: loss 0.5709, time 117.91ms, mfu 3.06%
+iter 2640: loss 0.5591, time 118.32ms, mfu 3.07%
+iter 2650: loss 0.5633, time 116.91ms, mfu 3.08%
+iter 2660: loss 0.5559, time 119.09ms, mfu 3.09%
+iter 2670: loss 0.5612, time 118.27ms, mfu 3.09%
+iter 2680: loss 0.5601, time 117.66ms, mfu 3.10%
+iter 2690: loss 0.5624, time 119.97ms, mfu 3.10%
+iter 2700: loss 0.5522, time 119.20ms, mfu 3.10%
+iter 2710: loss 0.5508, time 118.70ms, mfu 3.10%
+iter 2720: loss 0.5678, time 120.08ms, mfu 3.10%
+iter 2730: loss 0.5598, time 117.84ms, mfu 3.11%
+iter 2740: loss 0.5539, time 118.90ms, mfu 3.11%
+step 2750: train loss 0.5421, val loss 0.5435
+saving checkpoint to out-nd-accel
+iter 2750: loss 0.5356, time 11897.76ms, mfu 2.80%
+iter 2760: loss 0.5476, time 117.24ms, mfu 2.84%
+iter 2770: loss 0.5706, time 118.26ms, mfu 2.87%
+iter 2780: loss 0.5743, time 118.01ms, mfu 2.90%
+iter 2790: loss 0.5596, time 119.45ms, mfu 2.92%
+iter 2800: loss 0.5498, time 117.30ms, mfu 2.95%
+iter 2810: loss 0.5408, time 117.70ms, mfu 2.97%
+iter 2820: loss 0.5471, time 118.86ms, mfu 2.98%
+iter 2830: loss 0.5654, time 118.05ms, mfu 3.00%
+iter 2840: loss 0.5497, time 118.79ms, mfu 3.01%
+iter 2850: loss 0.5616, time 120.65ms, mfu 3.02%
+iter 2860: loss 0.5482, time 118.38ms, mfu 3.03%
+iter 2870: loss 0.5525, time 119.18ms, mfu 3.04%
+iter 2880: loss 0.5624, time 118.97ms, mfu 3.05%
+iter 2890: loss 0.5300, time 117.96ms, mfu 3.06%
+iter 2900: loss 0.5628, time 116.60ms, mfu 3.07%
+iter 2910: loss 0.5483, time 117.82ms, mfu 3.08%
+iter 2920: loss 0.5570, time 118.13ms, mfu 3.09%
+iter 2930: loss 0.5766, time 117.85ms, mfu 3.10%
+iter 2940: loss 0.5794, time 117.56ms, mfu 3.10%
+iter 2950: loss 0.5524, time 118.43ms, mfu 3.11%
+iter 2960: loss 0.5423, time 118.17ms, mfu 3.11%
+iter 2970: loss 0.5543, time 118.46ms, mfu 3.11%
+iter 2980: loss 0.5659, time 118.06ms, mfu 3.12%
+iter 2990: loss 0.5567, time 118.46ms, mfu 3.12%
+step 3000: train loss 0.5402, val loss 0.5397
+saving checkpoint to out-nd-accel
+iter 3000: loss 0.5544, time 11897.97ms, mfu 2.81%
+iter 3010: loss 0.5619, time 117.95ms, mfu 2.85%
+iter 3020: loss 0.5513, time 117.52ms, mfu 2.88%
+iter 3030: loss 0.5683, time 117.09ms, mfu 2.91%
+iter 3040: loss 0.5520, time 119.07ms, mfu 2.93%
+iter 3050: loss 0.5629, time 117.95ms, mfu 2.95%
+iter 3060: loss 0.5509, time 117.69ms, mfu 2.97%
+iter 3070: loss 0.5819, time 117.36ms, mfu 2.99%
+iter 3080: loss 0.5511, time 119.40ms, mfu 3.01%
+iter 3090: loss 0.5434, time 117.86ms, mfu 3.02%
+iter 3100: loss 0.5731, time 120.25ms, mfu 3.03%
+iter 3110: loss 0.5463, time 119.08ms, mfu 3.04%
+iter 3120: loss 0.5443, time 117.36ms, mfu 3.05%
+iter 3130: loss 0.5616, time 118.37ms, mfu 3.06%
+iter 3140: loss 0.5509, time 120.01ms, mfu 3.06%
+iter 3150: loss 0.5449, time 118.86ms, mfu 3.07%
+iter 3160: loss 0.5683, time 117.70ms, mfu 3.08%
+iter 3170: loss 0.5541, time 118.05ms, mfu 3.09%
+iter 3180: loss 0.5499, time 117.52ms, mfu 3.10%
+iter 3190: loss 0.5483, time 119.19ms, mfu 3.10%
+iter 3200: loss 0.5509, time 118.58ms, mfu 3.10%
+iter 3210: loss 0.5461, time 117.69ms, mfu 3.11%
+iter 3220: loss 0.5238, time 119.44ms, mfu 3.11%
+iter 3230: loss 0.5507, time 118.05ms, mfu 3.11%
+iter 3240: loss 0.5444, time 118.02ms, mfu 3.12%
+step 3250: train loss 0.5350, val loss 0.5361
+saving checkpoint to out-nd-accel
+iter 3250: loss 0.5639, time 11865.23ms, mfu 2.81%
+iter 3260: loss 0.5524, time 118.37ms, mfu 2.84%
+iter 3270: loss 0.5539, time 117.39ms, mfu 2.87%
+iter 3280: loss 0.5591, time 117.84ms, mfu 2.90%
+iter 3290: loss 0.5498, time 119.24ms, mfu 2.92%
+iter 3300: loss 0.5504, time 117.74ms, mfu 2.95%
+iter 3310: loss 0.5537, time 119.06ms, mfu 2.97%
+iter 3320: loss 0.5476, time 118.66ms, mfu 2.98%
+iter 3330: loss 0.5388, time 119.18ms, mfu 3.00%
+iter 3340: loss 0.5575, time 117.53ms, mfu 3.01%
+iter 3350: loss 0.5491, time 119.16ms, mfu 3.02%
+iter 3360: loss 0.5394, time 119.19ms, mfu 3.03%
+iter 3370: loss 0.5453, time 118.04ms, mfu 3.05%
+iter 3380: loss 0.5463, time 117.00ms, mfu 3.06%
+iter 3390: loss 0.5462, time 117.85ms, mfu 3.07%
+iter 3400: loss 0.5583, time 118.00ms, mfu 3.08%
+iter 3410: loss 0.5708, time 118.66ms, mfu 3.08%
+iter 3420: loss 0.5403, time 117.59ms, mfu 3.09%
+iter 3430: loss 0.5523, time 117.88ms, mfu 3.10%
+iter 3440: loss 0.5381, time 117.49ms, mfu 3.11%
+iter 3450: loss 0.5441, time 117.65ms, mfu 3.11%
+iter 3460: loss 0.5388, time 119.77ms, mfu 3.11%
+iter 3470: loss 0.5451, time 117.62ms, mfu 3.12%
+iter 3480: loss 0.5338, time 118.53ms, mfu 3.12%
+iter 3490: loss 0.5529, time 118.23ms, mfu 3.12%
+step 3500: train loss 0.5336, val loss 0.5342
+saving checkpoint to out-nd-accel
+iter 3500: loss 0.5641, time 11863.66ms, mfu 2.81%
+iter 3510: loss 0.5412, time 118.47ms, mfu 2.85%
+iter 3520: loss 0.5518, time 116.70ms, mfu 2.88%
+iter 3530: loss 0.5372, time 116.24ms, mfu 2.91%
+iter 3540: loss 0.5250, time 118.74ms, mfu 2.93%
+iter 3550: loss 0.5564, time 118.41ms, mfu 2.95%
+iter 3560: loss 0.5369, time 119.12ms, mfu 2.97%
+iter 3570: loss 0.5299, time 118.86ms, mfu 2.99%
+iter 3580: loss 0.5536, time 118.51ms, mfu 3.00%
+iter 3590: loss 0.5379, time 118.05ms, mfu 3.02%
+iter 3600: loss 0.5456, time 118.63ms, mfu 3.03%
+iter 3610: loss 0.5482, time 118.89ms, mfu 3.04%
+iter 3620: loss 0.5669, time 119.24ms, mfu 3.05%
+iter 3630: loss 0.5360, time 117.69ms, mfu 3.06%
+iter 3640: loss 0.5482, time 118.30ms, mfu 3.07%
+iter 3650: loss 0.5399, time 118.62ms, mfu 3.07%
+iter 3660: loss 0.5391, time 118.05ms, mfu 3.08%
+iter 3670: loss 0.5416, time 117.43ms, mfu 3.09%
+iter 3680: loss 0.5178, time 118.11ms, mfu 3.10%
+iter 3690: loss 0.5431, time 118.01ms, mfu 3.10%
+iter 3700: loss 0.5340, time 118.95ms, mfu 3.11%
+iter 3710: loss 0.5151, time 118.30ms, mfu 3.11%
+iter 3720: loss 0.5439, time 116.95ms, mfu 3.12%
+iter 3730: loss 0.5404, time 117.40ms, mfu 3.12%
+iter 3740: loss 0.5379, time 118.32ms, mfu 3.12%
+step 3750: train loss 0.5322, val loss 0.5329
+saving checkpoint to out-nd-accel
+iter 3750: loss 0.5244, time 11854.56ms, mfu 2.81%
+iter 3760: loss 0.5421, time 117.32ms, mfu 2.85%
+iter 3770: loss 0.5284, time 119.01ms, mfu 2.88%
+iter 3780: loss 0.5367, time 118.22ms, mfu 2.91%
+iter 3790: loss 0.5510, time 119.18ms, mfu 2.93%
+iter 3800: loss 0.5419, time 117.52ms, mfu 2.95%
+iter 3810: loss 0.5552, time 116.57ms, mfu 2.97%
+iter 3820: loss 0.5397, time 120.59ms, mfu 2.99%
+iter 3830: loss 0.5629, time 117.67ms, mfu 3.00%
+iter 3840: loss 0.5637, time 117.17ms, mfu 3.02%
+iter 3850: loss 0.5434, time 117.05ms, mfu 3.04%
+iter 3860: loss 0.5435, time 117.07ms, mfu 3.05%
+iter 3870: loss 0.5425, time 117.80ms, mfu 3.06%
+iter 3880: loss 0.5477, time 118.92ms, mfu 3.07%
+iter 3890: loss 0.5214, time 117.29ms, mfu 3.08%
+iter 3900: loss 0.5244, time 118.34ms, mfu 3.09%
+iter 3910: loss 0.5640, time 118.78ms, mfu 3.09%
+iter 3920: loss 0.5412, time 118.52ms, mfu 3.10%
+iter 3930: loss 0.5397, time 118.74ms, mfu 3.10%
+iter 3940: loss 0.5450, time 118.67ms, mfu 3.10%
+iter 3950: loss 0.5220, time 117.99ms, mfu 3.11%
+iter 3960: loss 0.5393, time 119.43ms, mfu 3.11%
+iter 3970: loss 0.5465, time 117.24ms, mfu 3.12%
+iter 3980: loss 0.5469, time 117.44ms, mfu 3.12%
+iter 3990: loss 0.5372, time 118.68ms, mfu 3.12%
+step 4000: train loss 0.5304, val loss 0.5308
+saving checkpoint to out-nd-accel
+iter 4000: loss 0.5444, time 11853.06ms, mfu 2.81%
+iter 4010: loss 0.5185, time 117.42ms, mfu 2.85%
+iter 4020: loss 0.5334, time 119.93ms, mfu 2.87%
+iter 4030: loss 0.5386, time 117.26ms, mfu 2.90%
+iter 4040: loss 0.5307, time 119.76ms, mfu 2.92%
+iter 4050: loss 0.5465, time 118.60ms, mfu 2.95%
+iter 4060: loss 0.5714, time 117.32ms, mfu 2.97%
+iter 4070: loss 0.5303, time 118.32ms, mfu 2.99%
+iter 4080: loss 0.5378, time 117.45ms, mfu 3.00%
+iter 4090: loss 0.5233, time 116.78ms, mfu 3.02%
+iter 4100: loss 0.5725, time 118.70ms, mfu 3.03%
+iter 4110: loss 0.5365, time 116.80ms, mfu 3.05%
+iter 4120: loss 0.5359, time 117.72ms, mfu 3.06%
+iter 4130: loss 0.5435, time 118.78ms, mfu 3.07%
+iter 4140: loss 0.5342, time 117.67ms, mfu 3.08%
+iter 4150: loss 0.5385, time 117.54ms, mfu 3.09%
+iter 4160: loss 0.5417, time 116.49ms, mfu 3.10%
+iter 4170: loss 0.5524, time 118.49ms, mfu 3.10%
+iter 4180: loss 0.5440, time 117.94ms, mfu 3.11%
+iter 4190: loss 0.5303, time 118.19ms, mfu 3.11%
+iter 4200: loss 0.5386, time 118.48ms, mfu 3.11%
+iter 4210: loss 0.5290, time 117.90ms, mfu 3.12%
+iter 4220: loss 0.5460, time 118.12ms, mfu 3.12%
+iter 4230: loss 0.5405, time 119.54ms, mfu 3.12%
+iter 4240: loss 0.5526, time 117.83ms, mfu 3.12%
+step 4250: train loss 0.5277, val loss 0.5305
+saving checkpoint to out-nd-accel
+iter 4250: loss 0.5469, time 11862.06ms, mfu 2.81%
+iter 4260: loss 0.5174, time 117.72ms, mfu 2.85%
+iter 4270: loss 0.5396, time 117.64ms, mfu 2.88%
+iter 4280: loss 0.5455, time 118.79ms, mfu 2.91%
+iter 4290: loss 0.5394, time 117.31ms, mfu 2.93%
+iter 4300: loss 0.5355, time 117.89ms, mfu 2.95%
+iter 4310: loss 0.5344, time 117.93ms, mfu 2.98%
+iter 4320: loss 0.5174, time 119.50ms, mfu 2.99%
+iter 4330: loss 0.5433, time 118.24ms, mfu 3.00%
+iter 4340: loss 0.5273, time 119.06ms, mfu 3.02%
+iter 4350: loss 0.5314, time 118.97ms, mfu 3.03%
+iter 4360: loss 0.5301, time 118.88ms, mfu 3.04%
+iter 4370: loss 0.5356, time 118.96ms, mfu 3.05%
+iter 4380: loss 0.5359, time 118.82ms, mfu 3.06%
+iter 4390: loss 0.5121, time 117.10ms, mfu 3.07%
+iter 4400: loss 0.5452, time 118.15ms, mfu 3.08%
+iter 4410: loss 0.5409, time 118.78ms, mfu 3.08%
+iter 4420: loss 0.5444, time 120.54ms, mfu 3.08%
+iter 4430: loss 0.5383, time 117.20ms, mfu 3.09%
+iter 4440: loss 0.5413, time 117.63ms, mfu 3.10%
+iter 4450: loss 0.5334, time 117.23ms, mfu 3.11%
+iter 4460: loss 0.5351, time 119.37ms, mfu 3.11%
+iter 4470: loss 0.5513, time 117.38ms, mfu 3.11%
+iter 4480: loss 0.5277, time 118.50ms, mfu 3.12%
+iter 4490: loss 0.5271, time 118.61ms, mfu 3.12%
+step 4500: train loss 0.5277, val loss 0.5294
+saving checkpoint to out-nd-accel
+iter 4500: loss 0.5322, time 11880.73ms, mfu 2.81%
+iter 4510: loss 0.5478, time 118.86ms, mfu 2.84%
+iter 4520: loss 0.5453, time 118.69ms, mfu 2.87%
+iter 4530: loss 0.5425, time 116.72ms, mfu 2.90%
+iter 4540: loss 0.5438, time 118.18ms, mfu 2.93%
+iter 4550: loss 0.5444, time 117.63ms, mfu 2.95%
+iter 4560: loss 0.5241, time 118.04ms, mfu 2.97%
+iter 4570: loss 0.5280, time 118.78ms, mfu 2.99%
+iter 4580: loss 0.5386, time 119.61ms, mfu 3.00%
+iter 4590: loss 0.5370, time 118.23ms, mfu 3.01%
+iter 4600: loss 0.5483, time 120.10ms, mfu 3.02%
+iter 4610: loss 0.5440, time 119.37ms, mfu 3.03%
+iter 4620: loss 0.5408, time 118.99ms, mfu 3.04%
+iter 4630: loss 0.5408, time 117.64ms, mfu 3.05%
+iter 4640: loss 0.5266, time 119.24ms, mfu 3.06%
+iter 4650: loss 0.5453, time 117.61ms, mfu 3.07%
+iter 4660: loss 0.5348, time 117.94ms, mfu 3.08%
+iter 4670: loss 0.5482, time 118.50ms, mfu 3.09%
+iter 4680: loss 0.5372, time 121.10ms, mfu 3.08%
+iter 4690: loss 0.5164, time 118.81ms, mfu 3.09%
+iter 4700: loss 0.5264, time 117.89ms, mfu 3.10%
+iter 4710: loss 0.5333, time 117.62ms, mfu 3.10%
+iter 4720: loss 0.5264, time 118.64ms, mfu 3.11%
+iter 4730: loss 0.5267, time 117.82ms, mfu 3.11%
+iter 4740: loss 0.5297, time 118.78ms, mfu 3.11%
+step 4750: train loss 0.5277, val loss 0.5291
+saving checkpoint to out-nd-accel
+iter 4750: loss 0.5195, time 11873.09ms, mfu 2.81%
+iter 4760: loss 0.5312, time 119.30ms, mfu 2.84%
+iter 4770: loss 0.5301, time 119.57ms, mfu 2.86%
+iter 4780: loss 0.5368, time 118.49ms, mfu 2.89%
+iter 4790: loss 0.5184, time 119.28ms, mfu 2.91%
+iter 4800: loss 0.5279, time 117.89ms, mfu 2.94%
+iter 4810: loss 0.5398, time 119.01ms, mfu 2.96%
+iter 4820: loss 0.5284, time 117.81ms, mfu 2.98%
+iter 4830: loss 0.5451, time 119.26ms, mfu 2.99%
+iter 4840: loss 0.5161, time 117.82ms, mfu 3.01%
+iter 4850: loss 0.5290, time 119.48ms, mfu 3.02%
+iter 4860: loss 0.5345, time 116.67ms, mfu 3.04%
+iter 4870: loss 0.5309, time 119.20ms, mfu 3.04%
+iter 4880: loss 0.5312, time 119.34ms, mfu 3.05%
+iter 4890: loss 0.5387, time 117.67ms, mfu 3.06%
+iter 4900: loss 0.5398, time 117.09ms, mfu 3.07%
+iter 4910: loss 0.5367, time 118.86ms, mfu 3.08%
+iter 4920: loss 0.5488, time 118.27ms, mfu 3.09%
+iter 4930: loss 0.5302, time 119.86ms, mfu 3.09%
+iter 4940: loss 0.5200, time 118.39ms, mfu 3.09%
+iter 4950: loss 0.5324, time 118.99ms, mfu 3.10%
+iter 4960: loss 0.5180, time 118.82ms, mfu 3.10%
+iter 4970: loss 0.5322, time 118.93ms, mfu 3.10%
+iter 4980: loss 0.5331, time 119.78ms, mfu 3.10%
+iter 4990: loss 0.5169, time 116.62ms, mfu 3.11%
+step 5000: train loss 0.5263, val loss 0.5277
+saving checkpoint to out-nd-accel
+iter 5000: loss 0.5360, time 11880.87ms, mfu 2.80%
\ No newline at end of file
diff --git a/wandb/run-20230522_204356-t6ramng5/files/requirements.txt b/wandb/run-20230522_204356-t6ramng5/files/requirements.txt
new file mode 100644
index 0000000..08fe5aa
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/requirements.txt
@@ -0,0 +1,120 @@
+aiohttp==3.8.4
+aiosignal==1.3.1
+appdirs==1.4.4
+asttokens==2.2.1
+async-timeout==4.0.2
+attrs==23.1.0
+backcall==0.2.0
+backports.functools-lru-cache==1.6.4
+boto3==1.26.133
+boto==2.49.0
+botocore==1.29.133
+certifi==2023.5.7
+charset-normalizer==3.1.0
+click==8.1.3
+cmake==3.26.3
+contourpy==1.0.7
+cycler==0.11.0
+datasets==2.12.0
+debugpy==1.6.7
+decorator==5.1.1
+dill==0.3.6
+dnspython==2.3.0
+docker-pycreds==0.4.0
+executing==1.2.0
+filelock==3.12.0
+fonttools==4.39.4
+frozenlist==1.3.3
+fsspec==2023.5.0
+gitdb==4.0.10
+gitpython==3.1.31
+greenlet==2.0.2
+huggingface-hub==0.14.1
+idna==3.4
+importlib-metadata==6.6.0
+importlib-resources==5.12.0
+influxdb-client==1.36.1
+ipykernel==6.14.0
+ipython==8.4.0
+jedi==0.18.2
+jinja2==3.1.2
+jmespath==1.0.1
+jupyter-client==8.2.0
+jupyter-core==5.3.0
+kiwisolver==1.4.4
+lit==16.0.3
+markupsafe==2.1.2
+matplotlib-inline==0.1.6
+matplotlib==3.7.1
+mpmath==1.3.0
+multidict==6.0.4
+multiprocess==0.70.14
+nest-asyncio==1.5.6
+networkx==3.1
+numpy==1.24.3
+nvidia-cublas-cu11==11.10.3.66
+nvidia-cuda-cupti-cu11==11.7.101
+nvidia-cuda-nvrtc-cu11==11.7.99
+nvidia-cuda-runtime-cu11==11.7.99
+nvidia-cudnn-cu11==8.5.0.96
+nvidia-cufft-cu11==10.9.0.58
+nvidia-curand-cu11==10.2.10.91
+nvidia-cusolver-cu11==11.4.0.1
+nvidia-cusparse-cu11==11.7.4.91
+nvidia-nccl-cu11==2.14.3
+nvidia-nvtx-cu11==11.7.91
+packaging==23.1
+pandas==2.0.1
+parso==0.8.3
+pathtools==0.1.2
+pexpect==4.8.0
+pickleshare==0.7.5
+pillow==9.5.0
+pip==23.1.2
+platformdirs==3.5.1
+prompt-toolkit==3.0.38
+protobuf==4.23.0
+psutil==5.9.5
+psycopg2-binary==2.9.6
+ptyprocess==0.7.0
+pure-eval==0.2.2
+pyarrow==12.0.0
+pygments==2.15.1
+pymongo==4.3.3
+pyparsing==3.0.9
+python-dateutil==2.8.2
+pytz==2023.3
+pyyaml==6.0
+pyzmq==25.0.2
+reactivex==4.0.4
+regex==2023.5.5
+requests==2.30.0
+responses==0.18.0
+s3transfer==0.6.1
+sentry-sdk==1.22.2
+setproctitle==1.3.2
+setuptools==67.7.2
+six==1.16.0
+smmap==5.0.0
+sqlalchemy==2.0.13
+stack-data==0.6.2
+sympy==1.12
+tiktoken==0.4.0
+tokenizers==0.13.3
+torch==2.0.1
+torchaudio==2.0.2
+torchvision==0.15.2
+tornado==6.3
+tqdm==4.65.0
+traitlets==5.9.0
+transformers==4.29.2
+triton==2.0.0
+typing-extensions==4.5.0
+tzdata==2023.3
+urllib3==1.26.15
+wandb==0.15.2
+wcwidth==0.2.6
+wheel==0.40.0
+xxhash==3.2.0
+yarl==1.9.2
+zipp==3.15.0
\ No newline at end of file
diff --git a/wandb/run-20230522_204356-t6ramng5/files/wandb-metadata.json b/wandb/run-20230522_204356-t6ramng5/files/wandb-metadata.json
new file mode 100644
index 0000000..767a62e
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/wandb-metadata.json
@@ -0,0 +1,128 @@
+{
+    "os": "Linux-5.4.0-1066-aws-x86_64-with-glibc2.27",
+    "python": "3.9.16",
+    "heartbeatAt": "2023-05-22T20:43:56.967607",
+    "startedAt": "2023-05-22T20:43:56.599749",
+    "docker": null,
+    "cuda": "11.0.228",
+    "args": [
+        "config/train_nd_accel.py",
+        "--dtype=float16"
+    ],
+    "state": "running",
+    "program": "/home/ubuntu/abhi_workspace/NDnanoGPT/train.py",
+    "codePath": "train.py",
+    "git": {
+        "remote": "https://github.com/abhik-nd/NDnanoGPT.git",
+        "commit": "7fe4a099ad2a4654f96a51c0736ecf347149c34c"
+    },
+    "email": "michael.laielli@netradyne.com",
+    "root": "/home/ubuntu/abhi_workspace/NDnanoGPT",
+    "host": "ip-10-200-10-3",
+    "username": "ubuntu",
+    "executable": "/home/ubuntu/anaconda3/envs/gpt/bin/python3",
+    "cpu_count": 8,
+    "cpu_count_logical": 16,
+    "cpu_freq": {
+        "current": 3109.805125,
+        "min": 0.0,
+        "max": 0.0
+    },
+    "cpu_freq_per_core": [
+        {
+            "current": 3124.581,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3100.135,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3102.773,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3101.143,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3101.049,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3143.701,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3103.054,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3105.407,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3100.528,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3101.808,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3099.358,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3105.905,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3102.881,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3101.273,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3118.547,
+            "min": 0.0,
+            "max": 0.0
+        },
+        {
+            "current": 3144.739,
+            "min": 0.0,
+            "max": 0.0
+        }
+    ],
+    "disk": {
+        "total": 125.96025466918945,
+        "used": 119.774658203125
+    },
+    "gpu": "Tesla T4",
+    "gpu_count": 1,
+    "gpu_devices": [
+        {
+            "name": "Tesla T4",
+            "memory_total": 16106127360
+        }
+    ],
+    "memory": {
+        "total": 62.03021240234375
+    }
+}
diff --git a/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json b/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
new file mode 100644
index 0000000..142c2f7
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
@@ -0,0 +1 @@
+{"iter": 5000, "train/loss": 0.5262848138809204, "val/loss": 0.5277165770530701, "lr": 0.0001, "mfu": 3.112592099652417, "_timestamp": 1684789086.724331, "_runtime": 850.1193988323212, "_step": 20, "_wandb": {"runtime": 850}}
\ No newline at end of file
diff --git a/wandb/run-20230522_204356-t6ramng5/logs/debug-internal.log b/wandb/run-20230522_204356-t6ramng5/logs/debug-internal.log
new file mode 100644
index 0000000..d60511c
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/logs/debug-internal.log
@@ -0,0 +1,901 @@
+2023-05-22 20:43:56,605 INFO    StreamThr :6501 [internal.py:wandb_internal():86] W&B internal server running at pid: 6501, started at: 2023-05-22 20:43:56.605338
+2023-05-22 20:43:56,606 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status
+2023-05-22 20:43:56,608 INFO    WriterThread:6501 [datastore.py:open_for_write():85] open: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/run-t6ramng5.wandb
+2023-05-22 20:43:56,610 DEBUG   SenderThread:6501 [sender.py:send():375] send: header
+2023-05-22 20:43:56,652 DEBUG   SenderThread:6501 [sender.py:send():375] send: run
+2023-05-22 20:43:56,806 INFO    SenderThread:6501 [dir_watcher.py:__init__():219] watching files in: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files
+2023-05-22 20:43:56,806 INFO    SenderThread:6501 [sender.py:_start_run_threads():1124] run started: t6ramng5 with start time 1684788236.604932
+2023-05-22 20:43:56,807 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:43:56,807 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:43:56,809 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: check_version
+2023-05-22 20:43:56,809 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: check_version
+2023-05-22 20:43:56,893 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: run_start
+2023-05-22 20:43:56,943 DEBUG   HandlerThread:6501 [system_info.py:__init__():31] System info init
+2023-05-22 20:43:56,943 DEBUG   HandlerThread:6501 [system_info.py:__init__():46] System info init done
+2023-05-22 20:43:56,943 INFO    HandlerThread:6501 [system_monitor.py:start():181] Starting system monitor
+2023-05-22 20:43:56,943 INFO    SystemMonitor:6501 [system_monitor.py:_start():145] Starting system asset monitoring threads
+2023-05-22 20:43:56,943 INFO    HandlerThread:6501 [system_monitor.py:probe():201] Collecting system info
+2023-05-22 20:43:56,944 INFO    SystemMonitor:6501 [interfaces.py:start():190] Started cpu monitoring
+2023-05-22 20:43:56,944 INFO    SystemMonitor:6501 [interfaces.py:start():190] Started disk monitoring
+2023-05-22 20:43:56,945 INFO    SystemMonitor:6501 [interfaces.py:start():190] Started gpu monitoring
+2023-05-22 20:43:56,946 INFO    SystemMonitor:6501 [interfaces.py:start():190] Started memory monitoring
+2023-05-22 20:43:56,947 INFO    SystemMonitor:6501 [interfaces.py:start():190] Started network monitoring
+2023-05-22 20:43:56,967 DEBUG   HandlerThread:6501 [system_info.py:probe():195] Probing system
+2023-05-22 20:43:56,972 DEBUG   HandlerThread:6501 [system_info.py:_probe_git():180] Probing git
+2023-05-22 20:43:56,982 DEBUG   HandlerThread:6501 [system_info.py:_probe_git():188] Probing git done
+2023-05-22 20:43:56,982 DEBUG   HandlerThread:6501 [system_info.py:probe():240] Probing system done
+2023-05-22 20:43:56,982 DEBUG   HandlerThread:6501 [system_monitor.py:probe():210] {'os': 'Linux-5.4.0-1066-aws-x86_64-with-glibc2.27', 'python': '3.9.16', 'heartbeatAt': '2023-05-22T20:43:56.967607', 'startedAt': '2023-05-22T20:43:56.599749', 'docker': None, 'cuda': '11.0.228', 'args': ('config/train_nd_accel.py', '--dtype=float16'), 'state': 'running', 'program': '/home/ubuntu/abhi_workspace/NDnanoGPT/train.py', 'codePath': 'train.py', 'git': {'remote': 'https://github.com/abhik-nd/NDnanoGPT.git', 'commit': '7fe4a099ad2a4654f96a51c0736ecf347149c34c'}, 'email': 'michael.laielli@netradyne.com', 'root': '/home/ubuntu/abhi_workspace/NDnanoGPT', 'host': 'ip-10-200-10-3', 'username': 'ubuntu', 'executable': '/home/ubuntu/anaconda3/envs/gpt/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 16, 'cpu_freq': {'current': 3109.805125, 'min': 0.0, 'max': 0.0}, 'cpu_freq_per_core': [{'current': 3124.581, 'min': 0.0, 'max': 0.0}, {'current': 3100.135, 'min': 0.0, 'max': 0.0}, {'current': 3102.773, 'min': 0.0, 'max': 0.0}, {'current': 3101.143, 'min': 0.0, 'max': 0.0}, {'current': 3101.049, 'min': 0.0, 'max': 0.0}, {'current': 3143.701, 'min': 0.0, 'max': 0.0}, {'current': 3103.054, 'min': 0.0, 'max': 0.0}, {'current': 3105.407, 'min': 0.0, 'max': 0.0}, {'current': 3100.528, 'min': 0.0, 'max': 0.0}, {'current': 3101.808, 'min': 0.0, 'max': 0.0}, {'current': 3099.358, 'min': 0.0, 'max': 0.0}, {'current': 3105.905, 'min': 0.0, 'max': 0.0}, {'current': 3102.881, 'min': 0.0, 'max': 0.0}, {'current': 3101.273, 'min': 0.0, 'max': 0.0}, {'current': 3118.547, 'min': 0.0, 'max': 0.0}, {'current': 3144.739, 'min': 0.0, 'max': 0.0}], 'disk': {'total': 125.96025466918945, 'used': 119.774658203125}, 'gpu': 'Tesla T4', 'gpu_count': 1, 'gpu_devices': [{'name': 'Tesla T4', 'memory_total': 16106127360}], 'memory': {'total': 62.03021240234375}}
+2023-05-22 20:43:56,982 INFO    HandlerThread:6501 [system_monitor.py:probe():211] Finished collecting system info
+2023-05-22 20:43:56,982 INFO    HandlerThread:6501 [system_monitor.py:probe():214] Publishing system info
+2023-05-22 20:43:56,983 DEBUG   HandlerThread:6501 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
+2023-05-22 20:43:56,983 DEBUG   HandlerThread:6501 [system_info.py:_save_pip():67] Saving pip packages done
+2023-05-22 20:43:56,983 DEBUG   HandlerThread:6501 [system_info.py:_save_conda():74] Saving list of conda packages installed into the current environment
+2023-05-22 20:43:57,808 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/conda-environment.yaml
+2023-05-22 20:43:57,809 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:43:57,809 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/requirements.txt
+2023-05-22 20:44:01,300 DEBUG   HandlerThread:6501 [system_info.py:_save_conda():86] Saving conda packages done
+2023-05-22 20:44:01,300 DEBUG   HandlerThread:6501 [system_info.py:_save_code():89] Saving code
+2023-05-22 20:44:01,306 DEBUG   HandlerThread:6501 [system_info.py:_save_code():110] Saving code done
+2023-05-22 20:44:01,307 DEBUG   HandlerThread:6501 [system_info.py:_save_patches():127] Saving git patches
+2023-05-22 20:44:01,339 DEBUG   HandlerThread:6501 [system_info.py:_save_patches():169] Saving git patches done
+2023-05-22 20:44:01,340 INFO    HandlerThread:6501 [system_monitor.py:probe():216] Finished publishing system info
+2023-05-22 20:44:01,345 DEBUG   SenderThread:6501 [sender.py:send():375] send: files
+2023-05-22 20:44:01,345 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-metadata.json with policy now
+2023-05-22 20:44:01,346 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file code/train.py with policy now
+2023-05-22 20:44:01,346 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file diff.patch with policy now
+2023-05-22 20:44:01,353 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:44:01,353 DEBUG   SenderThread:6501 [sender.py:send():375] send: telemetry
+2023-05-22 20:44:01,354 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:44:01,521 INFO    wandb-upload_2:6501 [upload_job.py:push():137] Uploaded file /tmp/tmpd36ok1q8wandb/dcg15ijs-diff.patch
+2023-05-22 20:44:01,521 INFO    wandb-upload_0:6501 [upload_job.py:push():137] Uploaded file /tmp/tmpd36ok1q8wandb/10cmazr7-wandb-metadata.json
+2023-05-22 20:44:01,550 INFO    wandb-upload_1:6501 [upload_job.py:push():137] Uploaded file /tmp/tmpd36ok1q8wandb/z5b2s9gl-code/train.py
+2023-05-22 20:44:01,810 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/conda-environment.yaml
+2023-05-22 20:44:01,810 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/diff.patch
+2023-05-22 20:44:01,810 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/code/train.py
+2023-05-22 20:44:01,810 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-metadata.json
+2023-05-22 20:44:01,810 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/code
+2023-05-22 20:44:02,405 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:07,406 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:12,406 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:16,356 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:44:16,356 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:44:16,556 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:44:16,558 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:44:16,558 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:44:16,559 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:44:16,814 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:44:16,814 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_created():278] file/dir created: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:17,814 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:18,815 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:19,815 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:21,816 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:23,014 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:23,817 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:24,817 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:26,818 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:28,036 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:28,818 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/config.yaml
+2023-05-22 20:44:28,819 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:30,819 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:31,354 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:44:31,355 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:44:32,820 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:33,530 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:34,820 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:36,821 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:38,822 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:39,060 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:40,822 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:42,823 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:44,615 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:44,824 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:46,354 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:44:46,355 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:44:46,824 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:48,825 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:50,189 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:50,826 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:44:55,306 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:44:56,947 DEBUG   SystemMonitor:6501 [system_monitor.py:_start():159] Starting system metrics aggregation loop
+2023-05-22 20:44:56,948 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:45:00,949 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:01,355 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:45:01,355 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:45:05,016 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:45:05,016 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:45:05,017 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:45:05,018 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:45:05,830 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:45:06,294 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:06,831 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:08,831 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:10,832 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:11,892 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:12,833 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:14,833 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:16,355 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:45:16,355 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:45:16,834 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:17,478 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:18,835 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:20,835 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:22,836 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:23,108 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:24,837 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:26,837 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:26,949 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:45:28,777 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:28,838 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:30,839 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:31,354 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:45:31,355 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:45:32,839 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:34,366 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:39,366 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:44,344 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:45:44,344 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:45:44,345 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:45:44,345 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:45:44,729 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:44,843 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:45:44,843 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:46,355 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:45:46,355 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:45:46,843 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:48,844 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:50,324 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:50,845 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:52,845 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:54,846 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:56,092 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:45:56,847 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:45:56,950 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:45:58,847 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:00,848 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:01,355 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:46:01,355 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:46:01,375 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:02,849 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:04,849 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:06,512 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:06,850 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:08,851 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:10,851 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:12,306 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:12,852 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:16,361 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:46:16,361 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:46:17,380 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:22,381 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:24,753 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:46:24,755 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:46:24,755 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:46:24,755 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:46:24,855 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:46:24,855 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:26,856 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:26,950 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:46:27,430 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:28,856 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:30,857 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:31,360 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:46:31,360 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:46:32,858 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:33,108 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:34,858 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:36,859 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:38,860 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:38,948 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:40,860 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:42,861 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:44,791 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:44,861 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:46,361 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:46:46,361 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:46:46,862 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:48,863 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:50,651 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:50,863 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:52,864 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:54,865 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:46:56,177 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:46:56,951 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:47:01,377 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:47:01,378 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:47:01,399 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:05,665 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:47:05,667 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:47:05,667 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:47:05,668 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:47:05,868 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:47:06,868 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:07,009 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:08,869 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:10,869 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:12,870 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:12,916 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:14,870 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:16,377 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:47:16,377 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:47:16,871 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:18,823 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:18,872 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:20,872 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:22,873 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:24,746 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:24,874 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:26,874 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:26,952 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:47:28,875 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:30,659 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:30,876 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:31,377 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:47:31,377 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:47:32,876 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:34,877 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:36,417 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:41,417 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:46,389 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:47:46,389 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:47:47,056 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:47,097 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:47:47,098 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:47:47,099 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:47:47,099 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:47:47,881 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:47:48,881 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:50,882 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:52,200 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:52,882 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:54,883 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:56,883 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:47:56,952 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:47:57,953 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:47:58,884 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:00,885 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:01,389 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:48:01,389 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:48:02,885 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:03,868 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:04,886 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:06,887 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:08,887 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:09,790 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:10,888 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:12,888 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:14,889 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:15,687 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:16,388 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:48:16,389 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:48:16,890 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:21,408 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:26,409 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:26,953 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:48:28,302 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:48:28,303 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:48:28,303 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:48:28,303 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:48:28,893 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:48:28,893 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:30,893 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:31,389 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:48:31,389 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:48:32,206 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:32,894 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:34,895 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:36,896 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:37,904 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:39,897 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:41,898 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:43,753 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:43,898 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:45,899 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:46,389 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:48:46,390 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:48:47,900 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:49,611 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:49,900 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:51,901 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:53,902 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:55,452 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:48:55,902 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:48:56,953 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:48:57,903 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:00,954 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:01,401 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:49:01,401 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:49:06,420 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:09,174 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:49:09,175 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:49:09,175 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:49:09,176 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:49:09,906 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:49:11,737 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:11,907 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:13,907 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:15,908 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:16,400 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:49:16,400 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:49:17,638 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:17,909 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:19,909 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:21,910 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:23,474 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:23,910 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:25,911 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:26,954 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:49:27,912 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:29,359 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:29,912 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:31,400 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:49:31,400 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:49:31,913 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:33,914 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:35,256 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:35,914 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:37,915 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:39,915 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:40,796 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:45,796 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:46,416 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:49:46,416 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:49:50,364 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:49:50,365 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:49:50,365 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:49:50,367 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:49:50,918 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:49:51,744 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:51,919 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:53,919 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:55,920 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:56,955 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:49:56,956 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:49:57,920 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:49:59,921 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:01,414 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:50:01,415 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:50:01,922 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:02,502 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:03,922 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:05,923 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:07,924 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:08,399 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:09,924 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:11,925 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:13,925 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:14,327 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:15,926 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:16,414 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:50:16,415 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:50:17,927 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:19,927 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:20,249 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:21,928 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:25,250 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:26,956 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:50:30,956 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:31,432 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:50:31,432 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:50:31,834 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:50:31,835 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:50:31,835 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:50:31,836 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:50:31,931 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:50:33,932 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:35,932 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:36,776 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:37,933 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:39,933 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:41,934 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:42,703 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:43,935 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:45,935 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:46,441 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:50:46,441 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:50:47,936 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:48,666 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:49,936 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:51,937 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:53,938 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:54,557 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:50:55,938 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:56,956 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:50:57,939 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:50:59,940 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:00,482 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:01,440 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:51:01,441 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:51:01,940 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:06,460 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:11,461 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:13,251 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:51:13,252 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:51:13,252 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:51:13,252 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:51:13,943 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:51:15,944 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:16,440 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:51:16,441 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:51:17,248 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:17,945 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:19,945 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:21,946 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:22,992 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:23,947 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:25,947 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:26,956 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:51:27,948 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:28,909 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:29,948 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:31,440 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:51:31,441 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:51:31,949 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:33,950 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:34,832 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:35,950 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:37,951 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:39,952 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:40,759 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:41,952 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:43,953 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:46,124 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:46,464 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:51:46,464 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:51:51,483 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:54,696 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:51:54,696 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:51:54,697 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:51:54,699 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:51:54,956 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:51:55,956 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:56,957 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:51:56,958 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:51:57,957 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:51:59,957 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:01,463 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:52:01,463 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:52:01,958 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:02,193 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:03,959 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:05,959 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:07,935 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:07,960 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:09,961 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:11,961 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:13,863 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:13,962 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:15,963 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:16,463 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:52:16,463 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:52:17,963 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:19,782 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:19,964 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:21,965 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:23,965 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:25,514 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:25,966 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:26,958 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:52:30,959 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:31,465 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:52:31,466 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:52:36,095 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:36,095 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:52:36,096 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:52:36,097 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:52:36,097 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:52:36,969 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:52:37,969 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:39,970 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:41,226 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:41,970 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:43,971 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:45,972 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:46,464 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:52:46,465 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:52:46,483 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:47,972 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:49,973 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:51,698 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:51,974 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:53,974 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:55,975 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:56,958 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:52:56,959 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:52:57,975 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:52:59,976 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:01,465 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:53:01,466 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:53:01,977 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:02,484 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:03,977 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:05,978 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:07,898 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:12,899 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:16,470 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:53:16,471 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:53:17,447 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:53:17,448 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:53:17,448 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:53:17,448 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:53:17,981 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:53:18,827 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:19,982 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:21,983 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:23,983 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:24,743 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:25,984 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:26,959 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:53:27,985 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:29,985 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:30,666 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:31,469 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:53:31,469 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:53:31,986 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:33,986 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:35,987 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:36,579 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:37,988 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:39,988 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:41,989 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:42,480 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:43,989 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:45,990 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:46,469 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:53:46,469 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:53:47,490 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:47,991 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:53:52,490 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:56,959 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:53:57,960 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:53:58,798 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:53:58,798 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:53:58,799 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:53:58,799 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:53:58,994 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:53:59,994 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:01,469 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:54:01,470 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:54:01,995 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:03,682 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:03,995 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:05,996 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:07,996 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:09,592 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:09,997 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:11,998 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:13,998 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:15,503 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:15,999 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:16,469 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:54:16,470 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:54:18,000 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:20,000 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:21,413 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:22,001 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:24,001 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:26,002 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:26,960 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:54:26,961 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:28,003 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:30,003 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:31,487 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:54:31,487 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:54:32,506 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:37,507 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:40,082 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:54:40,082 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:54:40,083 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:54:40,083 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:54:41,006 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:54:42,007 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:42,610 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:44,007 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:46,008 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:46,486 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:54:46,487 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:54:48,009 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:48,516 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:50,009 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:52,010 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:54,010 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:54,426 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:54:56,011 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:54:56,960 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:54:58,012 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:00,012 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:00,335 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:01,486 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:55:01,487 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:55:02,013 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:04,014 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:06,014 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:06,247 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:08,015 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:10,015 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:11,786 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:16,503 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:55:16,504 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:55:17,523 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:21,365 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:55:21,366 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:55:21,366 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:55:21,367 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:55:22,019 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:55:22,019 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:22,707 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:24,019 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:26,020 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:26,961 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:55:28,021 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:28,619 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:30,021 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:31,502 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:55:31,503 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:55:32,022 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:34,022 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:34,536 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:36,023 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:38,024 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:40,024 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:40,444 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:42,025 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:44,025 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:46,026 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:46,361 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:46,503 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:55:46,503 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:55:48,027 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:50,027 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:52,028 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:55:52,095 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:55:56,961 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:55:57,962 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:01,519 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:56:01,520 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:56:02,681 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:56:02,682 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:56:02,682 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:56:02,683 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:56:03,023 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:03,031 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:56:04,031 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:06,032 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:08,032 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:08,756 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:10,033 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:12,034 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:14,034 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:14,671 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:16,035 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:16,518 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:56:16,519 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:56:18,036 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:20,036 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:20,584 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:22,037 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:24,037 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:26,038 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:26,496 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:26,962 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:56:28,039 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:30,039 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:31,519 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:56:31,519 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:31,520 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:56:32,040 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:36,540 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:41,540 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:43,976 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:56:43,977 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:56:43,977 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:56:43,977 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:56:44,043 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:56:46,044 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:46,519 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:56:46,519 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:56:46,728 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:48,044 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:50,045 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:52,046 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:52,460 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:56:54,046 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:56,047 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:56,962 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:56:58,047 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:56:58,381 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:00,048 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:01,519 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:57:01,520 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:57:02,049 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:04,049 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:04,298 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:06,050 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:08,051 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:10,051 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:10,222 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:12,052 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:14,052 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:15,774 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:16,530 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:57:16,530 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:57:21,550 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:25,333 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:57:25,334 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:57:25,334 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:57:25,334 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:57:26,056 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:57:26,056 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:26,710 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:26,963 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:57:28,056 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:30,057 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:31,530 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:57:31,530 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:57:32,058 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:32,678 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:34,058 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:36,059 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:38,060 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:38,561 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:40,060 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:42,061 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:44,061 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:44,485 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:46,062 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:46,530 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:57:46,530 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:57:48,063 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:50,063 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:50,417 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:52,064 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:54,065 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:56,065 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:57:56,159 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:57:56,964 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:58:01,544 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:58:01,545 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: stop_status
+2023-05-22 20:58:01,545 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: stop_status
+2023-05-22 20:58:06,564 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:58:06,724 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: partial_history
+2023-05-22 20:58:06,725 DEBUG   SenderThread:6501 [sender.py:send():375] send: history
+2023-05-22 20:58:06,725 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: summary_record
+2023-05-22 20:58:06,725 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:58:07,068 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:58:07,161 DEBUG   SenderThread:6501 [sender.py:send():375] send: exit
+2023-05-22 20:58:07,161 INFO    SenderThread:6501 [sender.py:send_exit():598] handling exit code: 0
+2023-05-22 20:58:07,161 INFO    SenderThread:6501 [sender.py:send_exit():600] handling runtime: 850
+2023-05-22 20:58:07,161 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:58:07,162 INFO    SenderThread:6501 [sender.py:send_exit():606] send defer
+2023-05-22 20:58:07,162 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,162 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 0
+2023-05-22 20:58:07,162 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,162 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 0
+2023-05-22 20:58:07,162 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 1
+2023-05-22 20:58:07,162 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,162 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 1
+2023-05-22 20:58:07,162 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,163 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 1
+2023-05-22 20:58:07,163 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 2
+2023-05-22 20:58:07,163 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,163 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 2
+2023-05-22 20:58:07,163 INFO    HandlerThread:6501 [system_monitor.py:finish():190] Stopping system monitor
+2023-05-22 20:58:07,163 DEBUG   SystemMonitor:6501 [system_monitor.py:_start():166] Finished system metrics aggregation loop
+2023-05-22 20:58:07,163 DEBUG   SystemMonitor:6501 [system_monitor.py:_start():170] Publishing last batch of metrics
+2023-05-22 20:58:07,163 INFO    HandlerThread:6501 [interfaces.py:finish():202] Joined cpu monitor
+2023-05-22 20:58:07,164 INFO    HandlerThread:6501 [interfaces.py:finish():202] Joined disk monitor
+2023-05-22 20:58:07,188 INFO    HandlerThread:6501 [interfaces.py:finish():202] Joined gpu monitor
+2023-05-22 20:58:07,188 INFO    HandlerThread:6501 [interfaces.py:finish():202] Joined memory monitor
+2023-05-22 20:58:07,188 INFO    HandlerThread:6501 [interfaces.py:finish():202] Joined network monitor
+2023-05-22 20:58:07,189 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,189 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 2
+2023-05-22 20:58:07,189 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 3
+2023-05-22 20:58:07,189 DEBUG   SenderThread:6501 [sender.py:send():375] send: stats
+2023-05-22 20:58:07,189 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,189 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 3
+2023-05-22 20:58:07,189 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,190 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 3
+2023-05-22 20:58:07,190 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 4
+2023-05-22 20:58:07,190 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,190 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 4
+2023-05-22 20:58:07,190 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,190 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 4
+2023-05-22 20:58:07,190 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 5
+2023-05-22 20:58:07,190 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,190 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 5
+2023-05-22 20:58:07,190 DEBUG   SenderThread:6501 [sender.py:send():375] send: summary
+2023-05-22 20:58:07,190 INFO    SenderThread:6501 [sender.py:_save_file():1378] saving file wandb-summary.json with policy end
+2023-05-22 20:58:07,191 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,191 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 5
+2023-05-22 20:58:07,191 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 6
+2023-05-22 20:58:07,191 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,191 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 6
+2023-05-22 20:58:07,191 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,191 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 6
+2023-05-22 20:58:07,191 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 7
+2023-05-22 20:58:07,191 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: status_report
+2023-05-22 20:58:07,191 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:07,191 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 7
+2023-05-22 20:58:07,191 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:07,191 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 7
+2023-05-22 20:58:08,006 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 8
+2023-05-22 20:58:08,006 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:08,006 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 8
+2023-05-22 20:58:08,007 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:08,007 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 8
+2023-05-22 20:58:08,015 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 9
+2023-05-22 20:58:08,015 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:08,015 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 9
+2023-05-22 20:58:08,015 DEBUG   SenderThread:6501 [sender.py:send():375] send: artifact
+2023-05-22 20:58:08,069 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:58:08,069 INFO    Thread-12 :6501 [dir_watcher.py:_on_file_modified():295] file/dir modified: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:58:08,161 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-22 20:58:08,426 INFO    wandb-upload_0:6501 [upload_job.py:push():95] Uploaded file /home/ubuntu/.local/share/wandb/artifacts/staging/tmpgr_dq47s
+2023-05-22 20:58:08,429 INFO    wandb-upload_2:6501 [upload_job.py:push():95] Uploaded file /home/ubuntu/.local/share/wandb/artifacts/staging/tmp8rm4oa7o
+2023-05-22 20:58:08,449 INFO    wandb-upload_1:6501 [upload_job.py:push():95] Uploaded file /home/ubuntu/.local/share/wandb/artifacts/staging/tmpbw98ry9_
+2023-05-22 20:58:08,787 INFO    SenderThread:6501 [sender.py:send_artifact():1474] sent artifact job-https___github.com_abhik-nd_NDnanoGPT.git_train.py - {'id': 'QXJ0aWZhY3Q6MTE1ODY=', 'digest': 'ed36ab0e9f2d51a0d81a3c04cb3c3a34', 'state': 'PENDING', 'aliases': [], 'artifactSequence': {'id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjY5MDA=', 'latestArtifact': None}, 'version': 'latest'}
+2023-05-22 20:58:08,787 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:08,787 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 9
+2023-05-22 20:58:08,787 INFO    SenderThread:6501 [dir_watcher.py:finish():365] shutting down directory watcher
+2023-05-22 20:58:09,069 INFO    SenderThread:6501 [dir_watcher.py:finish():395] scan: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files
+2023-05-22 20:58:09,069 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-metadata.json wandb-metadata.json
+2023-05-22 20:58:09,069 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/config.yaml config.yaml
+2023-05-22 20:58:09,070 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json wandb-summary.json
+2023-05-22 20:58:09,070 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log output.log
+2023-05-22 20:58:09,070 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/requirements.txt requirements.txt
+2023-05-22 20:58:09,072 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/diff.patch diff.patch
+2023-05-22 20:58:09,072 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/conda-environment.yaml conda-environment.yaml
+2023-05-22 20:58:09,077 INFO    SenderThread:6501 [dir_watcher.py:finish():409] scan save: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/code/train.py code/train.py
+2023-05-22 20:58:09,077 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 10
+2023-05-22 20:58:09,077 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: poll_exit
+2023-05-22 20:58:09,078 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:09,080 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 10
+2023-05-22 20:58:09,083 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:09,083 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 10
+2023-05-22 20:58:09,083 INFO    SenderThread:6501 [file_pusher.py:finish():167] shutting down file pusher
+2023-05-22 20:58:09,128 INFO    wandb-upload_0:6501 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/config.yaml
+2023-05-22 20:58:09,162 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-22 20:58:09,162 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: poll_exit
+2023-05-22 20:58:09,180 INFO    wandb-upload_2:6501 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/wandb-summary.json
+2023-05-22 20:58:09,188 INFO    wandb-upload_3:6501 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/requirements.txt
+2023-05-22 20:58:09,240 INFO    wandb-upload_1:6501 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/output.log
+2023-05-22 20:58:09,267 INFO    wandb-upload_4:6501 [upload_job.py:push():137] Uploaded file /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/files/conda-environment.yaml
+2023-05-22 20:58:09,467 INFO    Thread-11 :6501 [sender.py:transition_state():626] send defer: 11
+2023-05-22 20:58:09,467 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:09,467 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 11
+2023-05-22 20:58:09,468 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:09,468 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 11
+2023-05-22 20:58:09,468 INFO    SenderThread:6501 [file_pusher.py:join():172] waiting for file pusher
+2023-05-22 20:58:09,468 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 12
+2023-05-22 20:58:09,468 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:09,468 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 12
+2023-05-22 20:58:09,468 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:09,468 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 12
+2023-05-22 20:58:09,550 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 13
+2023-05-22 20:58:09,550 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:09,550 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 13
+2023-05-22 20:58:09,551 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:09,551 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 13
+2023-05-22 20:58:09,551 INFO    SenderThread:6501 [sender.py:transition_state():626] send defer: 14
+2023-05-22 20:58:09,551 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: defer
+2023-05-22 20:58:09,551 INFO    HandlerThread:6501 [handler.py:handle_request_defer():170] handle defer: 14
+2023-05-22 20:58:09,551 DEBUG   SenderThread:6501 [sender.py:send():375] send: final
+2023-05-22 20:58:09,551 DEBUG   SenderThread:6501 [sender.py:send():375] send: footer
+2023-05-22 20:58:09,551 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: defer
+2023-05-22 20:58:09,551 INFO    SenderThread:6501 [sender.py:send_request_defer():622] handle sender defer: 14
+2023-05-22 20:58:09,552 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-22 20:58:09,552 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: poll_exit
+2023-05-22 20:58:09,552 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: poll_exit
+2023-05-22 20:58:09,553 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: poll_exit
+2023-05-22 20:58:09,553 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: server_info
+2023-05-22 20:58:09,553 DEBUG   SenderThread:6501 [sender.py:send_request():402] send_request: server_info
+2023-05-22 20:58:09,555 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: get_summary
+2023-05-22 20:58:09,555 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: sampled_history
+2023-05-22 20:58:09,568 INFO    MainThread:6501 [wandb_run.py:_footer_history_summary_info():3469] rendering history
+2023-05-22 20:58:09,568 INFO    MainThread:6501 [wandb_run.py:_footer_history_summary_info():3501] rendering summary
+2023-05-22 20:58:09,568 INFO    MainThread:6501 [wandb_run.py:_footer_sync_info():3428] logging synced files
+2023-05-22 20:58:09,568 DEBUG   HandlerThread:6501 [handler.py:handle_request():144] handle_request: shutdown
+2023-05-22 20:58:09,568 INFO    HandlerThread:6501 [handler.py:finish():845] shutting down handler
+2023-05-22 20:58:10,553 INFO    WriterThread:6501 [datastore.py:close():298] close: /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/run-t6ramng5.wandb
+2023-05-22 20:58:10,568 INFO    SenderThread:6501 [sender.py:finish():1550] shutting down sender
+2023-05-22 20:58:10,568 INFO    SenderThread:6501 [file_pusher.py:finish():167] shutting down file pusher
+2023-05-22 20:58:10,568 INFO    SenderThread:6501 [file_pusher.py:join():172] waiting for file pusher
diff --git a/wandb/run-20230522_204356-t6ramng5/logs/debug.log b/wandb/run-20230522_204356-t6ramng5/logs/debug.log
new file mode 100644
index 0000000..1af71b7
--- /dev/null
+++ b/wandb/run-20230522_204356-t6ramng5/logs/debug.log
@@ -0,0 +1,28 @@
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_setup.py:_flush():76] Current SDK version is 0.15.2
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_setup.py:_flush():76] Configure stats pid to 6453
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_setup.py:_flush():76] Loading settings from /home/ubuntu/.config/wandb/settings
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_setup.py:_flush():76] Loading settings from /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/settings
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program': '/home/ubuntu/abhi_workspace/NDnanoGPT/train.py'}
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_init.py:_log_setup():507] Logging user logs to /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/logs/debug.log
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_init.py:_log_setup():508] Logging internal logs to /home/ubuntu/abhi_workspace/NDnanoGPT/wandb/run-20230522_204356-t6ramng5/logs/debug-internal.log
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_init.py:init():547] calling init triggers
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
+config: {'out_dir': 'out-nd-accel', 'eval_interval': 250, 'log_interval': 10, 'eval_iters': 200, 'eval_only': False, 'always_save_checkpoint': False, 'init_from': 'scratch', 'wandb_log': True, 'wandb_project': 'nd-accel', 'wandb_run_name': 'mini-gpt-1', 'dataset': 'nd_accel', 'gradient_accumulation_steps': 1, 'batch_size': 64, 'block_size': 256, 'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'dropout': 0.2, 'bias': False, 'learning_rate': 0.001, 'max_iters': 5000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.99, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 100, 'lr_decay_iters': 5000, 'min_lr': 0.0001, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'float16', 'compile': True}
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_init.py:init():596] starting backend
+2023-05-22 20:43:56,601 INFO    MainThread:6453 [wandb_init.py:init():600] setting up manager
+2023-05-22 20:43:56,602 INFO    MainThread:6453 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
+2023-05-22 20:43:56,604 INFO    MainThread:6453 [wandb_init.py:init():606] backend started and connected
+2023-05-22 20:43:56,607 INFO    MainThread:6453 [wandb_init.py:init():700] updated telemetry
+2023-05-22 20:43:56,651 INFO    MainThread:6453 [wandb_init.py:init():737] communicating run to backend with 60.0 second timeout
+2023-05-22 20:43:56,808 INFO    MainThread:6453 [wandb_run.py:_on_init():2177] communicating current version
+2023-05-22 20:43:56,847 INFO    MainThread:6453 [wandb_run.py:_on_init():2186] got version response upgrade_message: "wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
+
+2023-05-22 20:43:56,847 INFO    MainThread:6453 [wandb_init.py:init():787] starting run threads in backend
+2023-05-22 20:44:01,350 INFO    MainThread:6453 [wandb_run.py:_console_start():2158] atexit reg
+2023-05-22 20:44:01,350 INFO    MainThread:6453 [wandb_run.py:_redirect():2013] redirect: SettingsConsole.WRAP_RAW
+2023-05-22 20:44:01,350 INFO    MainThread:6453 [wandb_run.py:_redirect():2078] Wrapping output streams.
+2023-05-22 20:44:01,350 INFO    MainThread:6453 [wandb_run.py:_redirect():2103] Redirects installed.
+2023-05-22 20:44:01,351 INFO    MainThread:6453 [wandb_init.py:init():829] run started, returning control to user process
+2023-05-22 20:58:10,686 WARNING MsgRouterThr:6453 [router.py:message_loop():77] message_loop has been closed
diff --git a/wandb/run-20230522_204356-t6ramng5/run-t6ramng5.wandb b/wandb/run-20230522_204356-t6ramng5/run-t6ramng5.wandb
new file mode 100644
index 0000000..f7225e4
Binary files /dev/null and b/wandb/run-20230522_204356-t6ramng5/run-t6ramng5.wandb differ
