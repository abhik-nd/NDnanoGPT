
step 0: train loss 3.2354, val loss 3.2384
[2023-05-22 23:09:56,984] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-22 23:09:57,567] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-22 23:09:58,368] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-22 23:09:58,651] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-22 23:09:59,101] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
[2023-05-22 23:09:59,384] torch._inductor.utils: [WARNING] using triton random, expect difference from eager
Traceback (most recent call last):
  File "/home/ubuntu/abhi_workspace/NDnanoGPT/train.py", line 295, in <module>
    logits, loss = model(X, Y)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 82, in forward
    return self.dynamo_ctx(self._orig_mod.forward)(*args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/home/ubuntu/abhi_workspace/NDnanoGPT/model.py", line 188, in forward
    x = block(x)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/abhi_workspace/NDnanoGPT/model.py", line 111, in forward
    x = x + self.attn(self.ln_1(x))
  File "/home/ubuntu/abhi_workspace/NDnanoGPT/model.py", line 111, in <graph break in forward>
    x = x + self.attn(self.ln_1(x))
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 2836, in forward
    return compiled_fn(full_args)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1224, in g
    return f(*args)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 2403, in debug_compiled_function
    return compiled_function(*args)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1900, in runtime_wrapper
    all_outs = call_func_with_args(
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1249, in call_func_with_args
    out = normalize_as_list(f(args))
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1224, in g
    return f(*args)
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 2168, in forward
    fw_outs = call_func_with_args(
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1249, in call_func_with_args
    out = normalize_as_list(f(args))
  File "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 248, in run
    return model(new_inputs)
  File "/tmp/torchinductor_ubuntu/oa/coacn4dng4wven4kr6xzo25ayjh7opos266fdswgwrt7j74c7l4m.py", line 214, in call
    buf8 = empty_strided((64, 4096, 1536), (6291456, 1536, 1), device='cuda', dtype=torch.float32)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 14.56 GiB total capacity; 12.76 GiB already allocated; 1.00 GiB free; 12.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF